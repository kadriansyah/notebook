{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# import sys\n",
    "# !{sys.executable} -m pip install numpy pandas matplotlib sklearn seaborn\n",
    "# !{sys.executable} -m pip install --upgrade gensim\n",
    "# !{sys.executable} -m pip install nltk\n",
    "# import nltk\n",
    "# nltk.download('punkt')\n",
    "# !{sys.executable} -m pip install beautifulsoup4"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import re\n",
    "import gensim\n",
    "import multiprocessing\n",
    "import random\n",
    "import logging\n",
    "import numpy as np\n",
    "import zipfile\n",
    "import tensorflow as tf\n",
    "\n",
    "from urllib import request\n",
    "\n",
    "from pathlib import Path\n",
    "from os import listdir\n",
    "from os.path import isfile, join\n",
    "from nltk.tokenize import RegexpTokenizer\n",
    "from bs4 import BeautifulSoup\n",
    "\n",
    "from sklearn.cluster import KMeans\n",
    "from gensim.models.doc2vec import Doc2Vec, TaggedDocument"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "SKIP_FILES = \"\"\n",
    "NEWLINE = '\\n'\n",
    "\n",
    "def clean_str(string):\n",
    "    \"\"\"\n",
    "    Tokenization/string cleaning for all datasets except for SST.\n",
    "    Original taken from https://github.com/yoonkim/CNN_sentence/blob/master/process_data.py\n",
    "    \"\"\"\n",
    "    string = re.sub(r\"[^A-Za-z0-9(),!?\\'\\`]\", \" \", string)\n",
    "    string = re.sub(r\",\", \" \", string)\n",
    "    string = re.sub(r\"!\", \" ! \", string)\n",
    "    string = re.sub(r\"\\(\", \" ( \", string)\n",
    "    string = re.sub(r\"\\)\", \" ) \", string)\n",
    "    string = re.sub(r\"\\?\", \" ? \", string)\n",
    "    string = re.sub(r\"\\s{2,}\", \" \", string)\n",
    "    return string.strip().lower()\n",
    "\n",
    "\"\"\"\n",
    "read training files\n",
    "\"\"\"\n",
    "def read_files(path):\n",
    "    print(\"path: {}...\".format(path))\n",
    "    for root, dirnames, filenames in os.walk(path):\n",
    "        for dirname in dirnames:\n",
    "            read_files(os.path.join(root, dirname))\n",
    "        for filename in filenames:\n",
    "            if filename not in SKIP_FILES:\n",
    "                filepath = os.path.join(root, filename)\n",
    "                if os.path.isfile(filepath):\n",
    "                    lines = []\n",
    "                    f = open(filepath, encoding='latin-1')\n",
    "                    for line in f:\n",
    "                        lines.append(line)\n",
    "                    f.close()\n",
    "                    content = NEWLINE.join(lines)\n",
    "                    yield filename, content\n",
    "\n",
    "def download(url, filename):\n",
    "    \"\"\"Download a file if not present\"\"\"\n",
    "    if not os.path.exists(filename):\n",
    "        print(\"downloading {}...\".format(filename))\n",
    "        filename, _ = request.urlretrieve(url + filename, filename)\n",
    "\n",
    "        print(\"extracting {}...\".format(filename))\n",
    "        with zipfile.ZipFile(filename) as f:\n",
    "            f.extractall()\n",
    "\n",
    "    return filename"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_data(url, filename):\n",
    "    filename = download(url, filename)\n",
    "    data_path = filename.replace('.zip','')\n",
    "    documents = []\n",
    "    print(\"building documents...\")\n",
    "    for fname, text in read_files(data_path):\n",
    "        documents.append(clean_str(text).split(' '))\n",
    "    documents = [TaggedDocument(doc, [i]) for i, doc in enumerate(documents)]\n",
    "    print(\"building documents done\")\n",
    "    return documents"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "downloading data.zip...\n",
      "extracting data.zip...\n",
      "building documents...\n",
      "path: data...\n",
      "building documents done\n",
      "we have 7932 documents\n"
     ]
    }
   ],
   "source": [
    "# download data training\n",
    "documents = get_data(url='https://github.com/kadriansyah/notebook/raw/master/alodokter-doc2vec-article/', filename=\"data.zip\")\n",
    "print(\"we have {} documents\".format(len(documents)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "TaggedDocument(words=['penyebab', 'bayi', 'muntah', 'setelah', 'minum', 'asi', 'dan', 'cara', 'mengatasinya', 'bayi', 'muntah', 'setelah', 'minum', 'asi', '(', 'air', 'susu', 'ibu', ')', 'adalah', 'keluhan', 'yang', 'sering', 'terjadi', 'sebagian', 'bayi', 'bahkan', 'mengalaminya', 'hampir', 'setiap', 'kali', 'selesai', 'menyusu', 'meski', 'umumnya', 'normal', 'kondisi', 'ini', 'bisa', 'juga', 'disebabkan', 'oleh', 'gangguan', 'berbahaya', 'yang', 'harus', 'diwaspadai', 'bayi', 'muntah', 'setelah', 'minum', 'asi', 'dikenal', 'dengan', 'istilah', 'gumoh', 'gumoh', 'dikatakan', 'normal', 'apabila', 'tidak', 'menyebabkan', 'bayi', 'rewel', 'atau', 'sesak', 'napas', 'meskipun', 'dapat', 'dicegah', 'kondisi', 'tersebut', 'tidak', 'memerlukan', 'penanganan', 'khusus', 'dan', 'normal', 'terjadi', 'penyebab', 'bayi', 'muntah', 'setelah', 'minum', 'asi', 'gumoh', 'disebabkan', 'oleh', 'asi', 'atau', 'susu', 'yang', 'ditelan', 'bayi', 'kembali', 'ke', 'kerongkongan', 'karena', 'otot', 'di', 'saluran', 'pencernaan', 'bayi', 'yaitu', 'di', 'bagian', 'kerongkongan', 'dan', 'lambung', 'masih', 'lemah', 'kondisi', 'ini', 'disebut', 'sebagai', 'refluks', 'bayi', 'kemungkinan', 'mengalami', 'refluks', 'karena', 'ukuran', 'lambungnya', 'masih', 'sangat', 'kecil', 'sehingga', 'cepat', 'terisi', 'penuh', 'refluks', 'juga', 'terjadi', 'karena', 'katup', 'pada', 'kerongkongan', 'belum', 'sempurna', 'sehingga', 'belum', 'bekerja', 'secara', 'optimal', 'untuk', 'menahan', 'isi', 'lambung', 'umumnya', 'bayi', 'muntah', 'setelah', 'minum', 'asi', 'akan', 'berlangsung', 'hingga', 'usia', '4', '5', 'bulan', 'setelah', 'itu', 'gumoh', 'akan', 'berhenti', 'dengan', 'sendirinya', 'penyebab', 'lain', 'bayi', 'muntah', 'setelah', 'minum', 'asi', 'adalah', 'gastroenteritis', 'hanya', 'saja', 'infeksi', 'pada', 'saluran', 'cerna', 'bayi', 'ini', 'biasanya', 'disertai', 'dengan', 'diare', 'selain', 'gastoenteritis', 'ada', 'berbagai', 'penyebab', 'lain', 'bayi', 'muntah', 'setelah', 'minum', 'asi', 'mulai', 'dari', 'alergi', 'pilek', 'infeksi', 'telinga', 'infeksi', 'saluran', 'kemih', 'hingga', 'penyempitan', 'lambung', '(', 'stenosis', 'pilorus', ')', 'walaupun', 'bayi', 'muntah', 'setelah', 'minum', 'asi', 'sering', 'kali', 'disebabkan', 'oleh', 'gumoh', 'yang', 'normal', 'tapi', 'orang', 'tua', 'harus', 'tetap', 'mewaspadai', 'jika', 'bayi', 'muntah', 'disertai', 'dengan', 'gejala', 'lain', 'seperti', 'demam', 'kurang', 'mau', 'atau', 'tidak', 'mau', 'menyusu', 'sama', 'sekali', 'timbul', 'ruam', 'sulit', 'tidur', 'dan', 'rewel', 'ubun', 'ubun', 'tampak', 'menonjol', 'perut', 'bengkak', 'sesak', 'napas', 'muntah', 'disertai', 'darah', 'atau', 'cairan', 'hijau', 'muntah', 'terus', 'menerus', 'lebih', 'lebih', 'dari', 'satu', 'atau', 'dua', 'hari', 'mengalami', 'dehidrasi', 'yang', 'ditandai', 'dengan', 'bibir', 'kering', 'menangis', 'tanpa', 'air', 'mata', 'ubun', 'ubun', 'cekung', 'dan', 'jarang', 'buang', 'air', 'kecil', 'tips', 'meringankan', 'muntah', 'pada', 'bayi', 'bayi', 'gumoh', 'biasanya', 'tidak', 'perlu', 'dikhawatirkan', 'dan', 'akan', 'mereda', 'dengan', 'sendirinya', 'seiring', 'bertambahnya', 'usia', 'bayi', 'meski', 'demikian', 'ada', 'beberapa', 'cara', 'yang', 'dapat', 'dilakukan', 'untuk', 'meringankan', 'keluhan', 'bayi', 'muntah', 'setelah', 'minum', 'asi', 'upayakan', 'posisi', 'kepala', 'bayi', 'lebih', 'tinggi', 'dari', 'tubuhnya', 'saat', 'menyusu', 'posisikan', 'tubuhnya', 'tetap', 'tegak', 'setelah', 'menyusu', 'agar', 'bayi', 'dapat', 'lebih', 'mudah', 'bersendawa', 'biarkan', 'bayi', 'menyusu', 'dalam', 'keadaan', 'tenang', 'hal', 'ini', 'akan', 'mencegah', 'bayi', 'mengisap', 'terlalu', 'banyak', 'udara', 'bersamaan', 'dengan', 'asi', 'biasakan', 'bayi', 'menyusu', 'secukupnya', 'namun', 'lebih', 'sering', 'menyusu', 'terlalu', 'banyak', 'dapat', 'membuat', 'lambung', 'bayi', 'teregang', 'karena', 'penuh', 'sehingga', 'memicu', 'bayi', 'untuk', 'muntah', 'setelah', 'minum', 'asi', 'buat', 'bayi', 'sendawa', 'setiap', 'kali', 'habis', 'menyusu', 'biarkan', 'bayi', 'sendawa', 'terlebih', 'dulu', 'sebelum', 'berganti', 'payudara', 'pastikan', 'pakaian', 'atau', 'popok', 'bayi', 'tidak', 'terlalu', 'ketat', 'serta', 'hindari', 'menggendong', 'bayi', 'untuk', 'sendawa', 'dengan', 'posisi', 'perut', 'bayi', 'tepat', 'di', 'bahu', 'anda', 'hal', 'ini', 'untuk', 'mengurangi', 'tekanan', 'pada', 'perutnya', 'hindari', 'menggoyangkan', 'bayi', 'atau', 'membuat', 'bayi', 'aktif', 'segera', 'setelah', 'menyusu', 'sebaiknya', 'juga', 'jangan', 'bepergian', 'dengan', 'kendaraan', 'sesaat', 'setelah', 'bayi', 'menyusu', 'jika', 'bayi', 'sudah', 'cukup', 'besar', 'posisikan', 'agar', 'ia', 'duduk', 'sekitar', '30', 'menit', 'setelah', 'menyusu', 'posisikan', 'kepala', 'bayi', 'sedikit', 'lebih', 'tinggi', 'saat', 'tidur', 'anda', 'dapat', 'meletakkan', 'selimut', 'atau', 'handuk', 'yang', 'digulung', 'di', 'bawah', 'bahu', 'dan', 'kepalanya', 'sebaiknya', 'hindari', 'menggunakan', 'bantal', 'pada', 'bayi', 'teliti', 'kemungkinan', 'bayi', 'muntah', 'setelah', 'minum', 'asi', 'akibat', 'makanan', 'atau', 'minuman', 'yang', 'dikonsumsi', 'ibu', 'misalnya', 'susu', 'sapi', 'jika', 'bayi', 'muntah', 'setelah', 'minum', 'asi', 'disertai', 'tanda', 'tanda', 'bahaya', 'di', 'atas', 'atau', 'jika', 'anda', 'merasa', 'khawatir', 'akan', 'kondisi', 'ini', 'segeralah', 'konsultasikan', 'dengan', 'dokter', 'anak', 'catat', 'berapa', 'kali', 'atau', 'berapa', 'banyak', 'bayi', 'muntah', 'dan', 'apakah', 'terdapat', 'gejala', 'gejala', 'lainnya'], tags=[0])"
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "documents[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "def evaluate(model, documents, steps):\n",
    "    percentiles = np.zeros(steps)\n",
    "    for step in range(steps):\n",
    "        docid = np.random.randint(model.docvecs.count)\n",
    "        inferred_vector = model.infer_vector(documents[docid][0])\n",
    "        similars = model.docvecs.most_similar(positive=[inferred_vector], topn=10)\n",
    "        for idx,simdoc in enumerate(similars):\n",
    "            if simdoc[0] == docid:\n",
    "                print(\"found similar document with id {} in position {} with similarity score {}\".format(simdoc[0], idx, simdoc[1]))\n",
    "                percentiles[step] = ((len(similars) - idx) / len(similars)) * 100\n",
    "                break\n",
    "    return np.mean(percentiles)\n",
    "\n",
    "def train(documents=documents, model_name=\"model/alodokter-articles-doc2vec.model\", max_epochs=50, patience=3):\n",
    "    best_mean_percentiles = 0\n",
    "    logging.basicConfig(format='%(asctime)s : %(levelname)s : %(message)s', level=logging.INFO)\n",
    "    model = Doc2Vec(dm=1, vector_size=300, window=2, alpha=0.1, min_alpha=0.0001, min_count=5, epochs=1, workers=5)\n",
    "    model.build_vocab(documents)\n",
    "    for epoch in range(max_epochs):\n",
    "        print('training epoch {:d} ...'.format(epoch))\n",
    "        model.train(documents, total_examples=model.corpus_count,epochs=model.epochs)\n",
    "        mean_percentiles = evaluate(model,documents,10)\n",
    "        print('mean percentiles: {:.2f}'.format(mean_percentiles))\n",
    "        \n",
    "        if mean_percentiles < best_mean_percentiles:\n",
    "            print(\"current mean_percentiles: {:.2f}, best: {:.2f}\".format(mean_percentiles, best_mean_percentiles))\n",
    "            patience = patience-1\n",
    "        else:\n",
    "            best_mean_percentiles = mean_percentiles\n",
    "            print(\"========== Saving best model with mean_percentiles: {:.2f} ==========\".format(mean_percentiles))\n",
    "            model.save(model_name)\n",
    "            patience = patience+1\n",
    "        \n",
    "        if patience == 0:\n",
    "            print(\"early stop...\")\n",
    "            print(\"========== Saving best model with mean_percentiles: {:.2f} ==========\".format(best_mean_percentiles))\n",
    "            break\n",
    "    \n",
    "    return model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2020-02-23 08:41:29,648 : INFO : collecting all words and their counts\n",
      "2020-02-23 08:41:29,649 : INFO : PROGRESS: at example #0, processed 0 words (0/s), 0 word types, 0 tags\n",
      "2020-02-23 08:41:30,310 : INFO : collected 54008 word types and 7932 unique tags from a corpus of 7932 examples and 4866436 words\n",
      "2020-02-23 08:41:30,311 : INFO : Loading a fresh vocabulary\n",
      "2020-02-23 08:41:30,343 : INFO : effective_min_count=5 retains 15409 unique words (28% of original 54008, drops 38599)\n",
      "2020-02-23 08:41:30,343 : INFO : effective_min_count=5 leaves 4811064 word corpus (98% of original 4866436, drops 55372)\n",
      "2020-02-23 08:41:30,383 : INFO : deleting the raw counts dictionary of 54008 items\n",
      "2020-02-23 08:41:30,385 : INFO : sample=0.001 downsamples 51 most-common words\n",
      "2020-02-23 08:41:30,386 : INFO : downsampling leaves estimated 4105293 word corpus (85.3% of prior 4811064)\n",
      "2020-02-23 08:41:30,422 : INFO : estimated required memory for 15409 words and 300 dimensions: 54204500 bytes\n",
      "2020-02-23 08:41:30,423 : INFO : resetting layer weights\n",
      "2020-02-23 08:41:34,073 : INFO : training model with 5 workers on 15409 vocabulary and 300 features, using sg=0 hs=0 sample=0.001 negative=5 window=2\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "training epoch 0 ...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2020-02-23 08:41:35,088 : INFO : EPOCH 1 - PROGRESS: at 37.10% examples, 1515933 words/s, in_qsize 10, out_qsize 0\n",
      "2020-02-23 08:41:36,092 : INFO : EPOCH 1 - PROGRESS: at 75.08% examples, 1532878 words/s, in_qsize 9, out_qsize 0\n",
      "2020-02-23 08:41:36,818 : INFO : worker thread finished; awaiting finish of 4 more threads\n",
      "2020-02-23 08:41:36,821 : INFO : worker thread finished; awaiting finish of 3 more threads\n",
      "2020-02-23 08:41:36,822 : INFO : worker thread finished; awaiting finish of 2 more threads\n",
      "2020-02-23 08:41:36,825 : INFO : worker thread finished; awaiting finish of 1 more threads\n",
      "2020-02-23 08:41:36,827 : INFO : worker thread finished; awaiting finish of 0 more threads\n",
      "2020-02-23 08:41:36,827 : INFO : EPOCH - 1 : training on 4866436 raw words (4113463 effective words) took 2.7s, 1495929 effective words/s\n",
      "2020-02-23 08:41:36,828 : INFO : training on a 4866436 raw words (4113463 effective words) took 2.8s, 1493561 effective words/s\n",
      "2020-02-23 08:41:36,830 : INFO : precomputing L2-norms of doc weight vectors\n",
      "2020-02-23 08:41:36,892 : INFO : saving Doc2Vec object under model/alodokter-articles-doc2vec.model, separately None\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "found similar document with id 7771 in position 0 with similarity score 0.618470311164856\n",
      "found similar document with id 4449 in position 0 with similarity score 0.6838314533233643\n",
      "found similar document with id 7650 in position 0 with similarity score 0.6442806124687195\n",
      "found similar document with id 4448 in position 0 with similarity score 0.7068660259246826\n",
      "found similar document with id 960 in position 0 with similarity score 0.6356767416000366\n",
      "found similar document with id 4337 in position 0 with similarity score 0.6365523338317871\n",
      "found similar document with id 3311 in position 0 with similarity score 0.6094967126846313\n",
      "found similar document with id 7759 in position 0 with similarity score 0.5914686322212219\n",
      "mean percentiles: 80.00\n",
      "========== Saving best model with mean_percentiles: 80.00 ==========\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2020-02-23 08:41:37,407 : INFO : saved model/alodokter-articles-doc2vec.model\n",
      "2020-02-23 08:41:37,408 : WARNING : Effective 'alpha' higher than previous training cycles\n",
      "2020-02-23 08:41:37,408 : INFO : training model with 5 workers on 15409 vocabulary and 300 features, using sg=0 hs=0 sample=0.001 negative=5 window=2\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "training epoch 1 ...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2020-02-23 08:41:38,414 : INFO : EPOCH 1 - PROGRESS: at 32.22% examples, 1322448 words/s, in_qsize 9, out_qsize 0\n",
      "2020-02-23 08:41:39,416 : INFO : EPOCH 1 - PROGRESS: at 66.75% examples, 1373973 words/s, in_qsize 10, out_qsize 0\n",
      "2020-02-23 08:41:40,311 : INFO : worker thread finished; awaiting finish of 4 more threads\n",
      "2020-02-23 08:41:40,313 : INFO : worker thread finished; awaiting finish of 3 more threads\n",
      "2020-02-23 08:41:40,321 : INFO : worker thread finished; awaiting finish of 2 more threads\n",
      "2020-02-23 08:41:40,322 : INFO : worker thread finished; awaiting finish of 1 more threads\n",
      "2020-02-23 08:41:40,325 : INFO : worker thread finished; awaiting finish of 0 more threads\n",
      "2020-02-23 08:41:40,325 : INFO : EPOCH - 1 : training on 4866436 raw words (4113476 effective words) took 2.9s, 1412168 effective words/s\n",
      "2020-02-23 08:41:40,326 : INFO : training on a 4866436 raw words (4113476 effective words) took 2.9s, 1410178 effective words/s\n",
      "2020-02-23 08:41:40,359 : INFO : saving Doc2Vec object under model/alodokter-articles-doc2vec.model, separately None\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "found similar document with id 380 in position 1 with similarity score 0.5233646035194397\n",
      "found similar document with id 4849 in position 0 with similarity score 0.7199378609657288\n",
      "found similar document with id 2750 in position 0 with similarity score 0.6436284780502319\n",
      "found similar document with id 2805 in position 0 with similarity score 0.7999988198280334\n",
      "found similar document with id 2684 in position 0 with similarity score 0.7287818193435669\n",
      "found similar document with id 2196 in position 0 with similarity score 0.6625823974609375\n",
      "found similar document with id 710 in position 8 with similarity score 0.41550952196121216\n",
      "found similar document with id 664 in position 0 with similarity score 0.629470705986023\n",
      "found similar document with id 7719 in position 0 with similarity score 0.6686818599700928\n",
      "found similar document with id 4874 in position 0 with similarity score 0.6538910269737244\n",
      "mean percentiles: 91.00\n",
      "========== Saving best model with mean_percentiles: 91.00 ==========\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2020-02-23 08:41:40,780 : INFO : saved model/alodokter-articles-doc2vec.model\n",
      "2020-02-23 08:41:40,781 : WARNING : Effective 'alpha' higher than previous training cycles\n",
      "2020-02-23 08:41:40,781 : INFO : training model with 5 workers on 15409 vocabulary and 300 features, using sg=0 hs=0 sample=0.001 negative=5 window=2\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "training epoch 2 ...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2020-02-23 08:41:41,789 : INFO : EPOCH 1 - PROGRESS: at 32.03% examples, 1311347 words/s, in_qsize 10, out_qsize 0\n",
      "2020-02-23 08:41:42,797 : INFO : EPOCH 1 - PROGRESS: at 66.16% examples, 1356705 words/s, in_qsize 9, out_qsize 0\n",
      "2020-02-23 08:41:43,720 : INFO : worker thread finished; awaiting finish of 4 more threads\n",
      "2020-02-23 08:41:43,721 : INFO : worker thread finished; awaiting finish of 3 more threads\n",
      "2020-02-23 08:41:43,721 : INFO : worker thread finished; awaiting finish of 2 more threads\n",
      "2020-02-23 08:41:43,722 : INFO : worker thread finished; awaiting finish of 1 more threads\n",
      "2020-02-23 08:41:43,723 : INFO : worker thread finished; awaiting finish of 0 more threads\n",
      "2020-02-23 08:41:43,724 : INFO : EPOCH - 1 : training on 4866436 raw words (4113264 effective words) took 2.9s, 1399904 effective words/s\n",
      "2020-02-23 08:41:43,724 : INFO : training on a 4866436 raw words (4113264 effective words) took 2.9s, 1397843 effective words/s\n",
      "2020-02-23 08:41:43,753 : INFO : saving Doc2Vec object under model/alodokter-articles-doc2vec.model, separately None\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "found similar document with id 2343 in position 0 with similarity score 0.6491297483444214\n",
      "found similar document with id 6264 in position 0 with similarity score 0.6432464122772217\n",
      "found similar document with id 5264 in position 0 with similarity score 0.7168463468551636\n",
      "found similar document with id 315 in position 0 with similarity score 0.5046045780181885\n",
      "found similar document with id 4661 in position 0 with similarity score 0.6944633722305298\n",
      "found similar document with id 6456 in position 0 with similarity score 0.7050161361694336\n",
      "found similar document with id 4388 in position 0 with similarity score 0.6985473036766052\n",
      "found similar document with id 6606 in position 0 with similarity score 0.7297171354293823\n",
      "found similar document with id 6508 in position 0 with similarity score 0.7628588676452637\n",
      "found similar document with id 4372 in position 0 with similarity score 0.6826696395874023\n",
      "mean percentiles: 100.00\n",
      "========== Saving best model with mean_percentiles: 100.00 ==========\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2020-02-23 08:41:44,164 : INFO : saved model/alodokter-articles-doc2vec.model\n",
      "2020-02-23 08:41:44,165 : WARNING : Effective 'alpha' higher than previous training cycles\n",
      "2020-02-23 08:41:44,165 : INFO : training model with 5 workers on 15409 vocabulary and 300 features, using sg=0 hs=0 sample=0.001 negative=5 window=2\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "training epoch 3 ...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2020-02-23 08:41:45,171 : INFO : EPOCH 1 - PROGRESS: at 33.55% examples, 1379413 words/s, in_qsize 10, out_qsize 0\n",
      "2020-02-23 08:41:46,173 : INFO : EPOCH 1 - PROGRESS: at 69.59% examples, 1431320 words/s, in_qsize 9, out_qsize 0\n",
      "2020-02-23 08:41:46,954 : INFO : worker thread finished; awaiting finish of 4 more threads\n",
      "2020-02-23 08:41:46,960 : INFO : worker thread finished; awaiting finish of 3 more threads\n",
      "2020-02-23 08:41:46,962 : INFO : worker thread finished; awaiting finish of 2 more threads\n",
      "2020-02-23 08:41:46,963 : INFO : worker thread finished; awaiting finish of 1 more threads\n",
      "2020-02-23 08:41:46,968 : INFO : worker thread finished; awaiting finish of 0 more threads\n",
      "2020-02-23 08:41:46,969 : INFO : EPOCH - 1 : training on 4866436 raw words (4112892 effective words) took 2.8s, 1469352 effective words/s\n",
      "2020-02-23 08:41:46,969 : INFO : training on a 4866436 raw words (4112892 effective words) took 2.8s, 1467204 effective words/s\n",
      "2020-02-23 08:41:47,000 : INFO : saving Doc2Vec object under model/alodokter-articles-doc2vec.model, separately None\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "found similar document with id 2353 in position 0 with similarity score 0.5704185366630554\n",
      "found similar document with id 7312 in position 0 with similarity score 0.6147781610488892\n",
      "found similar document with id 4404 in position 0 with similarity score 0.6751293540000916\n",
      "found similar document with id 6989 in position 0 with similarity score 0.630764365196228\n",
      "found similar document with id 6862 in position 0 with similarity score 0.6600054502487183\n",
      "found similar document with id 2847 in position 0 with similarity score 0.4859165847301483\n",
      "found similar document with id 5461 in position 0 with similarity score 0.6169723272323608\n",
      "found similar document with id 7024 in position 0 with similarity score 0.6728838682174683\n",
      "found similar document with id 4956 in position 0 with similarity score 0.6004559993743896\n",
      "found similar document with id 1795 in position 0 with similarity score 0.6219866871833801\n",
      "mean percentiles: 100.00\n",
      "========== Saving best model with mean_percentiles: 100.00 ==========\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2020-02-23 08:41:47,417 : INFO : saved model/alodokter-articles-doc2vec.model\n",
      "2020-02-23 08:41:47,418 : WARNING : Effective 'alpha' higher than previous training cycles\n",
      "2020-02-23 08:41:47,419 : INFO : training model with 5 workers on 15409 vocabulary and 300 features, using sg=0 hs=0 sample=0.001 negative=5 window=2\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "training epoch 4 ...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2020-02-23 08:41:48,424 : INFO : EPOCH 1 - PROGRESS: at 33.93% examples, 1393621 words/s, in_qsize 10, out_qsize 1\n",
      "2020-02-23 08:41:49,439 : INFO : EPOCH 1 - PROGRESS: at 69.77% examples, 1424979 words/s, in_qsize 10, out_qsize 0\n",
      "2020-02-23 08:41:50,274 : INFO : worker thread finished; awaiting finish of 4 more threads\n",
      "2020-02-23 08:41:50,276 : INFO : worker thread finished; awaiting finish of 3 more threads\n",
      "2020-02-23 08:41:50,277 : INFO : worker thread finished; awaiting finish of 2 more threads\n",
      "2020-02-23 08:41:50,278 : INFO : worker thread finished; awaiting finish of 1 more threads\n",
      "2020-02-23 08:41:50,284 : INFO : worker thread finished; awaiting finish of 0 more threads\n",
      "2020-02-23 08:41:50,285 : INFO : EPOCH - 1 : training on 4866436 raw words (4112857 effective words) took 2.9s, 1436213 effective words/s\n",
      "2020-02-23 08:41:50,285 : INFO : training on a 4866436 raw words (4112857 effective words) took 2.9s, 1435016 effective words/s\n",
      "2020-02-23 08:41:50,312 : WARNING : Effective 'alpha' higher than previous training cycles\n",
      "2020-02-23 08:41:50,313 : INFO : training model with 5 workers on 15409 vocabulary and 300 features, using sg=0 hs=0 sample=0.001 negative=5 window=2\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "found similar document with id 4416 in position 0 with similarity score 0.539395809173584\n",
      "found similar document with id 4446 in position 0 with similarity score 0.4877135753631592\n",
      "found similar document with id 7717 in position 0 with similarity score 0.5399603843688965\n",
      "found similar document with id 2272 in position 1 with similarity score 0.49606576561927795\n",
      "found similar document with id 2121 in position 0 with similarity score 0.4883211851119995\n",
      "found similar document with id 2137 in position 0 with similarity score 0.610095739364624\n",
      "found similar document with id 2303 in position 0 with similarity score 0.4863532781600952\n",
      "found similar document with id 2613 in position 0 with similarity score 0.5358152389526367\n",
      "found similar document with id 7425 in position 0 with similarity score 0.5046092867851257\n",
      "mean percentiles: 89.00\n",
      "current mean_percentiles: 89.00, best: 100.00\n",
      "training epoch 5 ...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2020-02-23 08:41:51,325 : INFO : EPOCH 1 - PROGRESS: at 35.26% examples, 1441089 words/s, in_qsize 9, out_qsize 0\n",
      "2020-02-23 08:41:52,327 : INFO : EPOCH 1 - PROGRESS: at 71.60% examples, 1466438 words/s, in_qsize 9, out_qsize 0\n",
      "2020-02-23 08:41:53,031 : INFO : worker thread finished; awaiting finish of 4 more threads\n",
      "2020-02-23 08:41:53,040 : INFO : worker thread finished; awaiting finish of 3 more threads\n",
      "2020-02-23 08:41:53,041 : INFO : worker thread finished; awaiting finish of 2 more threads\n",
      "2020-02-23 08:41:53,042 : INFO : worker thread finished; awaiting finish of 1 more threads\n",
      "2020-02-23 08:41:53,049 : INFO : worker thread finished; awaiting finish of 0 more threads\n",
      "2020-02-23 08:41:53,050 : INFO : EPOCH - 1 : training on 4866436 raw words (4112984 effective words) took 2.7s, 1504796 effective words/s\n",
      "2020-02-23 08:41:53,050 : INFO : training on a 4866436 raw words (4112984 effective words) took 2.7s, 1502751 effective words/s\n",
      "2020-02-23 08:41:53,074 : WARNING : Effective 'alpha' higher than previous training cycles\n",
      "2020-02-23 08:41:53,075 : INFO : training model with 5 workers on 15409 vocabulary and 300 features, using sg=0 hs=0 sample=0.001 negative=5 window=2\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "found similar document with id 5169 in position 0 with similarity score 0.6398381590843201\n",
      "found similar document with id 4191 in position 0 with similarity score 0.6157698035240173\n",
      "found similar document with id 6475 in position 0 with similarity score 0.6017863154411316\n",
      "found similar document with id 4073 in position 0 with similarity score 0.6039165258407593\n",
      "found similar document with id 7805 in position 0 with similarity score 0.6157862544059753\n",
      "found similar document with id 2025 in position 0 with similarity score 0.6671191453933716\n",
      "found similar document with id 5544 in position 0 with similarity score 0.5649850368499756\n",
      "found similar document with id 5414 in position 0 with similarity score 0.5075386762619019\n",
      "mean percentiles: 80.00\n",
      "current mean_percentiles: 80.00, best: 100.00\n",
      "training epoch 6 ...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2020-02-23 08:41:54,085 : INFO : EPOCH 1 - PROGRESS: at 36.28% examples, 1482031 words/s, in_qsize 9, out_qsize 0\n",
      "2020-02-23 08:41:55,091 : INFO : EPOCH 1 - PROGRESS: at 75.44% examples, 1542107 words/s, in_qsize 9, out_qsize 0\n",
      "2020-02-23 08:41:55,698 : INFO : worker thread finished; awaiting finish of 4 more threads\n",
      "2020-02-23 08:41:55,701 : INFO : worker thread finished; awaiting finish of 3 more threads\n",
      "2020-02-23 08:41:55,702 : INFO : worker thread finished; awaiting finish of 2 more threads\n",
      "2020-02-23 08:41:55,703 : INFO : worker thread finished; awaiting finish of 1 more threads\n",
      "2020-02-23 08:41:55,705 : INFO : worker thread finished; awaiting finish of 0 more threads\n",
      "2020-02-23 08:41:55,706 : INFO : EPOCH - 1 : training on 4866436 raw words (4112831 effective words) took 2.6s, 1565129 effective words/s\n",
      "2020-02-23 08:41:55,706 : INFO : training on a 4866436 raw words (4112831 effective words) took 2.6s, 1563089 effective words/s\n",
      "2020-02-23 08:41:55,731 : WARNING : Effective 'alpha' higher than previous training cycles\n",
      "2020-02-23 08:41:55,731 : INFO : training model with 5 workers on 15409 vocabulary and 300 features, using sg=0 hs=0 sample=0.001 negative=5 window=2\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "found similar document with id 5987 in position 0 with similarity score 0.6235440969467163\n",
      "found similar document with id 7579 in position 0 with similarity score 0.5886069536209106\n",
      "found similar document with id 5081 in position 0 with similarity score 0.5626044273376465\n",
      "found similar document with id 6315 in position 0 with similarity score 0.5298286080360413\n",
      "found similar document with id 4279 in position 0 with similarity score 0.5991606116294861\n",
      "found similar document with id 535 in position 0 with similarity score 0.42960047721862793\n",
      "found similar document with id 7027 in position 0 with similarity score 0.549343466758728\n",
      "found similar document with id 5610 in position 0 with similarity score 0.569473385810852\n",
      "found similar document with id 6295 in position 0 with similarity score 0.5916352868080139\n",
      "mean percentiles: 90.00\n",
      "current mean_percentiles: 90.00, best: 100.00\n",
      "training epoch 7 ...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2020-02-23 08:41:56,735 : INFO : EPOCH 1 - PROGRESS: at 37.90% examples, 1562272 words/s, in_qsize 9, out_qsize 0\n",
      "2020-02-23 08:41:57,737 : INFO : EPOCH 1 - PROGRESS: at 77.05% examples, 1582388 words/s, in_qsize 9, out_qsize 0\n",
      "2020-02-23 08:41:58,310 : INFO : worker thread finished; awaiting finish of 4 more threads\n",
      "2020-02-23 08:41:58,318 : INFO : worker thread finished; awaiting finish of 3 more threads\n",
      "2020-02-23 08:41:58,321 : INFO : worker thread finished; awaiting finish of 2 more threads\n",
      "2020-02-23 08:41:58,322 : INFO : worker thread finished; awaiting finish of 1 more threads\n",
      "2020-02-23 08:41:58,323 : INFO : worker thread finished; awaiting finish of 0 more threads\n",
      "2020-02-23 08:41:58,324 : INFO : EPOCH - 1 : training on 4866436 raw words (4113355 effective words) took 2.6s, 1588614 effective words/s\n",
      "2020-02-23 08:41:58,324 : INFO : training on a 4866436 raw words (4113355 effective words) took 2.6s, 1586686 effective words/s\n",
      "2020-02-23 08:41:58,346 : WARNING : Effective 'alpha' higher than previous training cycles\n",
      "2020-02-23 08:41:58,346 : INFO : training model with 5 workers on 15409 vocabulary and 300 features, using sg=0 hs=0 sample=0.001 negative=5 window=2\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "found similar document with id 991 in position 0 with similarity score 0.5198101997375488\n",
      "found similar document with id 3045 in position 0 with similarity score 0.6133900880813599\n",
      "found similar document with id 7699 in position 0 with similarity score 0.5554860830307007\n",
      "found similar document with id 5714 in position 0 with similarity score 0.5412174463272095\n",
      "found similar document with id 6919 in position 0 with similarity score 0.520093560218811\n",
      "found similar document with id 5699 in position 0 with similarity score 0.5821018218994141\n",
      "found similar document with id 2839 in position 0 with similarity score 0.5411393046379089\n",
      "found similar document with id 3437 in position 0 with similarity score 0.47233492136001587\n",
      "found similar document with id 6512 in position 0 with similarity score 0.5540144443511963\n",
      "mean percentiles: 90.00\n",
      "current mean_percentiles: 90.00, best: 100.00\n",
      "training epoch 8 ...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2020-02-23 08:41:59,354 : INFO : EPOCH 1 - PROGRESS: at 37.90% examples, 1557353 words/s, in_qsize 10, out_qsize 0\n",
      "2020-02-23 08:42:00,356 : INFO : EPOCH 1 - PROGRESS: at 73.39% examples, 1506569 words/s, in_qsize 9, out_qsize 0\n",
      "2020-02-23 08:42:01,094 : INFO : worker thread finished; awaiting finish of 4 more threads\n",
      "2020-02-23 08:42:01,099 : INFO : worker thread finished; awaiting finish of 3 more threads\n",
      "2020-02-23 08:42:01,101 : INFO : worker thread finished; awaiting finish of 2 more threads\n",
      "2020-02-23 08:42:01,107 : INFO : worker thread finished; awaiting finish of 1 more threads\n",
      "2020-02-23 08:42:01,108 : INFO : worker thread finished; awaiting finish of 0 more threads\n",
      "2020-02-23 08:42:01,108 : INFO : EPOCH - 1 : training on 4866436 raw words (4112987 effective words) took 2.8s, 1491274 effective words/s\n",
      "2020-02-23 08:42:01,108 : INFO : training on a 4866436 raw words (4112987 effective words) took 2.8s, 1489491 effective words/s\n",
      "2020-02-23 08:42:01,140 : WARNING : Effective 'alpha' higher than previous training cycles\n",
      "2020-02-23 08:42:01,140 : INFO : training model with 5 workers on 15409 vocabulary and 300 features, using sg=0 hs=0 sample=0.001 negative=5 window=2\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "found similar document with id 7512 in position 0 with similarity score 0.5821084976196289\n",
      "found similar document with id 3810 in position 0 with similarity score 0.5245790481567383\n",
      "found similar document with id 5674 in position 0 with similarity score 0.582007884979248\n",
      "found similar document with id 1349 in position 7 with similarity score 0.4493425786495209\n",
      "found similar document with id 1311 in position 4 with similarity score 0.4602513909339905\n",
      "found similar document with id 3572 in position 0 with similarity score 0.4742148518562317\n",
      "found similar document with id 2951 in position 0 with similarity score 0.4879973530769348\n",
      "found similar document with id 6860 in position 0 with similarity score 0.4633292257785797\n",
      "mean percentiles: 69.00\n",
      "current mean_percentiles: 69.00, best: 100.00\n",
      "training epoch 9 ...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2020-02-23 08:42:02,147 : INFO : EPOCH 1 - PROGRESS: at 36.54% examples, 1502694 words/s, in_qsize 10, out_qsize 0\n",
      "2020-02-23 08:42:03,149 : INFO : EPOCH 1 - PROGRESS: at 73.84% examples, 1515827 words/s, in_qsize 10, out_qsize 1\n",
      "2020-02-23 08:42:03,782 : INFO : worker thread finished; awaiting finish of 4 more threads\n",
      "2020-02-23 08:42:03,789 : INFO : worker thread finished; awaiting finish of 3 more threads\n",
      "2020-02-23 08:42:03,790 : INFO : worker thread finished; awaiting finish of 2 more threads\n",
      "2020-02-23 08:42:03,791 : INFO : worker thread finished; awaiting finish of 1 more threads\n",
      "2020-02-23 08:42:03,794 : INFO : worker thread finished; awaiting finish of 0 more threads\n",
      "2020-02-23 08:42:03,795 : INFO : EPOCH - 1 : training on 4866436 raw words (4113005 effective words) took 2.7s, 1551364 effective words/s\n",
      "2020-02-23 08:42:03,795 : INFO : training on a 4866436 raw words (4113005 effective words) took 2.7s, 1549290 effective words/s\n",
      "2020-02-23 08:42:03,817 : WARNING : Effective 'alpha' higher than previous training cycles\n",
      "2020-02-23 08:42:03,817 : INFO : training model with 5 workers on 15409 vocabulary and 300 features, using sg=0 hs=0 sample=0.001 negative=5 window=2\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "found similar document with id 402 in position 1 with similarity score 0.39155665040016174\n",
      "found similar document with id 4305 in position 0 with similarity score 0.4275767207145691\n",
      "found similar document with id 4799 in position 0 with similarity score 0.4248434901237488\n",
      "found similar document with id 775 in position 4 with similarity score 0.3866235017776489\n",
      "found similar document with id 2293 in position 9 with similarity score 0.3794844448566437\n",
      "found similar document with id 6129 in position 0 with similarity score 0.5287708640098572\n",
      "found similar document with id 694 in position 7 with similarity score 0.3622402250766754\n",
      "found similar document with id 3377 in position 0 with similarity score 0.46711117029190063\n",
      "found similar document with id 6086 in position 0 with similarity score 0.4845796227455139\n",
      "mean percentiles: 69.00\n",
      "current mean_percentiles: 69.00, best: 100.00\n",
      "training epoch 10 ...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2020-02-23 08:42:04,827 : INFO : EPOCH 1 - PROGRESS: at 35.70% examples, 1461237 words/s, in_qsize 10, out_qsize 1\n",
      "2020-02-23 08:42:05,829 : INFO : EPOCH 1 - PROGRESS: at 75.47% examples, 1546078 words/s, in_qsize 9, out_qsize 0\n",
      "2020-02-23 08:42:06,444 : INFO : worker thread finished; awaiting finish of 4 more threads\n",
      "2020-02-23 08:42:06,445 : INFO : worker thread finished; awaiting finish of 3 more threads\n",
      "2020-02-23 08:42:06,450 : INFO : worker thread finished; awaiting finish of 2 more threads\n",
      "2020-02-23 08:42:06,454 : INFO : worker thread finished; awaiting finish of 1 more threads\n",
      "2020-02-23 08:42:06,456 : INFO : worker thread finished; awaiting finish of 0 more threads\n",
      "2020-02-23 08:42:06,456 : INFO : EPOCH - 1 : training on 4866436 raw words (4113866 effective words) took 2.6s, 1561320 effective words/s\n",
      "2020-02-23 08:42:06,456 : INFO : training on a 4866436 raw words (4113866 effective words) took 2.6s, 1559173 effective words/s\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "found similar document with id 557 in position 4 with similarity score 0.4253980815410614\n",
      "found similar document with id 6400 in position 0 with similarity score 0.4955461621284485\n",
      "found similar document with id 5756 in position 0 with similarity score 0.47075992822647095\n",
      "found similar document with id 4463 in position 2 with similarity score 0.4597526490688324\n",
      "found similar document with id 1244 in position 3 with similarity score 0.3155973255634308\n",
      "found similar document with id 467 in position 3 with similarity score 0.44359251856803894\n",
      "found similar document with id 1760 in position 0 with similarity score 0.5016111731529236\n",
      "found similar document with id 4002 in position 3 with similarity score 0.44518810510635376\n",
      "mean percentiles: 65.00\n",
      "current mean_percentiles: 65.00, best: 100.00\n",
      "early stop...\n",
      "========== Saving best model with mean_percentiles: 100.00 ==========\n"
     ]
    }
   ],
   "source": [
    "model = train(documents)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
