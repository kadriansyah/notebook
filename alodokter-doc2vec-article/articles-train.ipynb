{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# import sys\n",
    "# !{sys.executable} -m pip install numpy pandas matplotlib sklearn seaborn\n",
    "# !{sys.executable} -m pip install --upgrade gensim\n",
    "# !{sys.executable} -m pip install nltk\n",
    "# !{sys.executable} -m pip install beautifulsoup4\n",
    "# import nltk\n",
    "# nltk.download('punkt')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import re\n",
    "import gensim\n",
    "import multiprocessing\n",
    "import random\n",
    "import logging\n",
    "import numpy as np\n",
    "import zipfile\n",
    "\n",
    "from urllib import request\n",
    "\n",
    "from pathlib import Path\n",
    "from os import listdir\n",
    "from os.path import isfile, join\n",
    "from nltk.tokenize import RegexpTokenizer\n",
    "from bs4 import BeautifulSoup\n",
    "\n",
    "from sklearn.cluster import KMeans\n",
    "from gensim.models.doc2vec import Doc2Vec, TaggedDocument"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "SKIP_FILES = \"\"\n",
    "NEWLINE = '\\n'\n",
    "\n",
    "def clean_str(string):\n",
    "    \"\"\"\n",
    "    Tokenization/string cleaning for all datasets except for SST.\n",
    "    Original taken from https://github.com/yoonkim/CNN_sentence/blob/master/process_data.py\n",
    "    \"\"\"\n",
    "    string = re.sub(r\"[^A-Za-z0-9(),!?\\'\\`]\", \" \", string)\n",
    "    string = re.sub(r\",\", \" \", string)\n",
    "    string = re.sub(r\"!\", \" ! \", string)\n",
    "    string = re.sub(r\"\\(\", \" ( \", string)\n",
    "    string = re.sub(r\"\\)\", \" ) \", string)\n",
    "    string = re.sub(r\"\\?\", \" ? \", string)\n",
    "    string = re.sub(r\"\\s{2,}\", \" \", string)\n",
    "    return string.strip().lower()\n",
    "\n",
    "\"\"\"\n",
    "read training files\n",
    "\"\"\"\n",
    "def read_files(path):\n",
    "    print(\"path: {}...\".format(path))\n",
    "    for root, dirnames, filenames in os.walk(path):\n",
    "        for dirname in dirnames:\n",
    "            read_files(os.path.join(root, dirname))\n",
    "        for filename in filenames:\n",
    "            if filename not in SKIP_FILES:\n",
    "                filepath = os.path.join(root, filename)\n",
    "                if os.path.isfile(filepath):\n",
    "                    lines = []\n",
    "                    f = open(filepath, encoding='latin-1')\n",
    "                    for line in f:\n",
    "                        lines.append(line)\n",
    "                    f.close()\n",
    "                    content = NEWLINE.join(lines)\n",
    "                    yield filename, content\n",
    "\n",
    "def download(url, filename):\n",
    "    \"\"\"Download a file if not present\"\"\"\n",
    "    if not os.path.exists(filename):\n",
    "        print(\"downloading {}...\".format(filename))\n",
    "        filename, _ = request.urlretrieve(url + filename, filename)\n",
    "\n",
    "        print(\"extracting {}...\".format(filename))\n",
    "        with zipfile.ZipFile(filename) as f:\n",
    "            f.extractall()\n",
    "            print(\"extracting {} done\".format(filename))\n",
    "\n",
    "    \"\"\"directory data\"\"\"\n",
    "    data_path = filename.replace('.zip','')\n",
    "    if not os.path.exists(data_path):\n",
    "        print(\"extracting {}...\".format(filename))\n",
    "        with zipfile.ZipFile(filename) as f:\n",
    "            f.extractall()\n",
    "            print(\"extracting {} done\".format(filename))\n",
    "\n",
    "    \"\"\"directory model for saving model while training\"\"\"\n",
    "    if not os.path.exists('model'):\n",
    "        os.mkdir('model')\n",
    "        print(\"directory model created...\")\n",
    "\n",
    "    return data_path"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_data(url, filename):\n",
    "    data_path = download(url, filename)\n",
    "    documents = []\n",
    "    print(\"building documents...\")\n",
    "    for fname, text in read_files(data_path):\n",
    "        documents.append(clean_str(text).split(' '))\n",
    "    documents = [TaggedDocument(doc, [i]) for i, doc in enumerate(documents)]\n",
    "    print(\"building documents done\")\n",
    "    return documents"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "downloading data.zip...\n",
      "extracting data.zip...\n",
      "directory model created...\n",
      "building documents...\n",
      "path: data...\n",
      "building documents done\n",
      "we have 7932 documents\n"
     ]
    }
   ],
   "source": [
    "# download data training\n",
    "documents = get_data(url='https://github.com/kadriansyah/notebook/raw/master/alodokter-doc2vec-article/', filename=\"data.zip\")\n",
    "print(\"we have {} documents\".format(len(documents)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "TaggedDocument(words=['penyebab', 'bayi', 'muntah', 'setelah', 'minum', 'asi', 'dan', 'cara', 'mengatasinya', 'bayi', 'muntah', 'setelah', 'minum', 'asi', '(', 'air', 'susu', 'ibu', ')', 'adalah', 'keluhan', 'yang', 'sering', 'terjadi', 'sebagian', 'bayi', 'bahkan', 'mengalaminya', 'hampir', 'setiap', 'kali', 'selesai', 'menyusu', 'meski', 'umumnya', 'normal', 'kondisi', 'ini', 'bisa', 'juga', 'disebabkan', 'oleh', 'gangguan', 'berbahaya', 'yang', 'harus', 'diwaspadai', 'bayi', 'muntah', 'setelah', 'minum', 'asi', 'dikenal', 'dengan', 'istilah', 'gumoh', 'gumoh', 'dikatakan', 'normal', 'apabila', 'tidak', 'menyebabkan', 'bayi', 'rewel', 'atau', 'sesak', 'napas', 'meskipun', 'dapat', 'dicegah', 'kondisi', 'tersebut', 'tidak', 'memerlukan', 'penanganan', 'khusus', 'dan', 'normal', 'terjadi', 'penyebab', 'bayi', 'muntah', 'setelah', 'minum', 'asi', 'gumoh', 'disebabkan', 'oleh', 'asi', 'atau', 'susu', 'yang', 'ditelan', 'bayi', 'kembali', 'ke', 'kerongkongan', 'karena', 'otot', 'di', 'saluran', 'pencernaan', 'bayi', 'yaitu', 'di', 'bagian', 'kerongkongan', 'dan', 'lambung', 'masih', 'lemah', 'kondisi', 'ini', 'disebut', 'sebagai', 'refluks', 'bayi', 'kemungkinan', 'mengalami', 'refluks', 'karena', 'ukuran', 'lambungnya', 'masih', 'sangat', 'kecil', 'sehingga', 'cepat', 'terisi', 'penuh', 'refluks', 'juga', 'terjadi', 'karena', 'katup', 'pada', 'kerongkongan', 'belum', 'sempurna', 'sehingga', 'belum', 'bekerja', 'secara', 'optimal', 'untuk', 'menahan', 'isi', 'lambung', 'umumnya', 'bayi', 'muntah', 'setelah', 'minum', 'asi', 'akan', 'berlangsung', 'hingga', 'usia', '4', '5', 'bulan', 'setelah', 'itu', 'gumoh', 'akan', 'berhenti', 'dengan', 'sendirinya', 'penyebab', 'lain', 'bayi', 'muntah', 'setelah', 'minum', 'asi', 'adalah', 'gastroenteritis', 'hanya', 'saja', 'infeksi', 'pada', 'saluran', 'cerna', 'bayi', 'ini', 'biasanya', 'disertai', 'dengan', 'diare', 'selain', 'gastoenteritis', 'ada', 'berbagai', 'penyebab', 'lain', 'bayi', 'muntah', 'setelah', 'minum', 'asi', 'mulai', 'dari', 'alergi', 'pilek', 'infeksi', 'telinga', 'infeksi', 'saluran', 'kemih', 'hingga', 'penyempitan', 'lambung', '(', 'stenosis', 'pilorus', ')', 'walaupun', 'bayi', 'muntah', 'setelah', 'minum', 'asi', 'sering', 'kali', 'disebabkan', 'oleh', 'gumoh', 'yang', 'normal', 'tapi', 'orang', 'tua', 'harus', 'tetap', 'mewaspadai', 'jika', 'bayi', 'muntah', 'disertai', 'dengan', 'gejala', 'lain', 'seperti', 'demam', 'kurang', 'mau', 'atau', 'tidak', 'mau', 'menyusu', 'sama', 'sekali', 'timbul', 'ruam', 'sulit', 'tidur', 'dan', 'rewel', 'ubun', 'ubun', 'tampak', 'menonjol', 'perut', 'bengkak', 'sesak', 'napas', 'muntah', 'disertai', 'darah', 'atau', 'cairan', 'hijau', 'muntah', 'terus', 'menerus', 'lebih', 'lebih', 'dari', 'satu', 'atau', 'dua', 'hari', 'mengalami', 'dehidrasi', 'yang', 'ditandai', 'dengan', 'bibir', 'kering', 'menangis', 'tanpa', 'air', 'mata', 'ubun', 'ubun', 'cekung', 'dan', 'jarang', 'buang', 'air', 'kecil', 'tips', 'meringankan', 'muntah', 'pada', 'bayi', 'bayi', 'gumoh', 'biasanya', 'tidak', 'perlu', 'dikhawatirkan', 'dan', 'akan', 'mereda', 'dengan', 'sendirinya', 'seiring', 'bertambahnya', 'usia', 'bayi', 'meski', 'demikian', 'ada', 'beberapa', 'cara', 'yang', 'dapat', 'dilakukan', 'untuk', 'meringankan', 'keluhan', 'bayi', 'muntah', 'setelah', 'minum', 'asi', 'upayakan', 'posisi', 'kepala', 'bayi', 'lebih', 'tinggi', 'dari', 'tubuhnya', 'saat', 'menyusu', 'posisikan', 'tubuhnya', 'tetap', 'tegak', 'setelah', 'menyusu', 'agar', 'bayi', 'dapat', 'lebih', 'mudah', 'bersendawa', 'biarkan', 'bayi', 'menyusu', 'dalam', 'keadaan', 'tenang', 'hal', 'ini', 'akan', 'mencegah', 'bayi', 'mengisap', 'terlalu', 'banyak', 'udara', 'bersamaan', 'dengan', 'asi', 'biasakan', 'bayi', 'menyusu', 'secukupnya', 'namun', 'lebih', 'sering', 'menyusu', 'terlalu', 'banyak', 'dapat', 'membuat', 'lambung', 'bayi', 'teregang', 'karena', 'penuh', 'sehingga', 'memicu', 'bayi', 'untuk', 'muntah', 'setelah', 'minum', 'asi', 'buat', 'bayi', 'sendawa', 'setiap', 'kali', 'habis', 'menyusu', 'biarkan', 'bayi', 'sendawa', 'terlebih', 'dulu', 'sebelum', 'berganti', 'payudara', 'pastikan', 'pakaian', 'atau', 'popok', 'bayi', 'tidak', 'terlalu', 'ketat', 'serta', 'hindari', 'menggendong', 'bayi', 'untuk', 'sendawa', 'dengan', 'posisi', 'perut', 'bayi', 'tepat', 'di', 'bahu', 'anda', 'hal', 'ini', 'untuk', 'mengurangi', 'tekanan', 'pada', 'perutnya', 'hindari', 'menggoyangkan', 'bayi', 'atau', 'membuat', 'bayi', 'aktif', 'segera', 'setelah', 'menyusu', 'sebaiknya', 'juga', 'jangan', 'bepergian', 'dengan', 'kendaraan', 'sesaat', 'setelah', 'bayi', 'menyusu', 'jika', 'bayi', 'sudah', 'cukup', 'besar', 'posisikan', 'agar', 'ia', 'duduk', 'sekitar', '30', 'menit', 'setelah', 'menyusu', 'posisikan', 'kepala', 'bayi', 'sedikit', 'lebih', 'tinggi', 'saat', 'tidur', 'anda', 'dapat', 'meletakkan', 'selimut', 'atau', 'handuk', 'yang', 'digulung', 'di', 'bawah', 'bahu', 'dan', 'kepalanya', 'sebaiknya', 'hindari', 'menggunakan', 'bantal', 'pada', 'bayi', 'teliti', 'kemungkinan', 'bayi', 'muntah', 'setelah', 'minum', 'asi', 'akibat', 'makanan', 'atau', 'minuman', 'yang', 'dikonsumsi', 'ibu', 'misalnya', 'susu', 'sapi', 'jika', 'bayi', 'muntah', 'setelah', 'minum', 'asi', 'disertai', 'tanda', 'tanda', 'bahaya', 'di', 'atas', 'atau', 'jika', 'anda', 'merasa', 'khawatir', 'akan', 'kondisi', 'ini', 'segeralah', 'konsultasikan', 'dengan', 'dokter', 'anak', 'catat', 'berapa', 'kali', 'atau', 'berapa', 'banyak', 'bayi', 'muntah', 'dan', 'apakah', 'terdapat', 'gejala', 'gejala', 'lainnya'], tags=[0])"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "documents[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "def evaluate(model, documents, steps):\n",
    "    percentiles = np.zeros(steps)\n",
    "    for step in range(steps):\n",
    "        docid = np.random.randint(model.docvecs.count)\n",
    "        inferred_vector = model.infer_vector(documents[docid][0])\n",
    "        similars = model.docvecs.most_similar(positive=[inferred_vector], topn=10)\n",
    "        for idx,simdoc in enumerate(similars):\n",
    "            if simdoc[0] == docid:\n",
    "                print(\"found similar document with id {} in position {} with similarity score {}\".format(simdoc[0], idx, simdoc[1]))\n",
    "                percentiles[step] = ((len(similars) - idx) / len(similars)) * 100\n",
    "                break\n",
    "    return np.mean(percentiles)\n",
    "\n",
    "def train(documents=documents, model_name=\"model/alodokter-articles-doc2vec.model\", max_epochs=50, patience=3):\n",
    "    best_mean_percentiles = 0\n",
    "    logging.basicConfig(format='%(asctime)s : %(levelname)s : %(message)s', level=logging.INFO)\n",
    "    model = Doc2Vec(dm=1, vector_size=300, window=2, alpha=0.1, min_alpha=0.0001, min_count=5, epochs=1, workers=5)\n",
    "    model.build_vocab(documents)\n",
    "    for epoch in range(max_epochs):\n",
    "        print('training epoch {:d} ...'.format(epoch))\n",
    "        model.train(documents, total_examples=model.corpus_count,epochs=model.epochs)\n",
    "        mean_percentiles = evaluate(model,documents,10)\n",
    "        print('mean percentiles: {:.2f}'.format(mean_percentiles))\n",
    "        \n",
    "        if mean_percentiles < best_mean_percentiles:\n",
    "            print(\"current mean_percentiles: {:.2f}, best: {:.2f}\".format(mean_percentiles, best_mean_percentiles))\n",
    "            patience = patience-1\n",
    "        else:\n",
    "            best_mean_percentiles = mean_percentiles\n",
    "            print(\"========== Saving best model with mean_percentiles: {:.2f} ==========\".format(mean_percentiles))\n",
    "            model.save(model_name)\n",
    "            patience = patience+1\n",
    "        \n",
    "        if patience == 0:\n",
    "            print(\"early stop...\")\n",
    "            print(\"========== Saving best model with mean_percentiles: {:.2f} ==========\".format(best_mean_percentiles))\n",
    "            break\n",
    "    \n",
    "    return model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2020-02-23 09:59:53,541 : INFO : collecting all words and their counts\n",
      "2020-02-23 09:59:53,542 : INFO : PROGRESS: at example #0, processed 0 words (0/s), 0 word types, 0 tags\n",
      "2020-02-23 09:59:54,211 : INFO : collected 54008 word types and 7932 unique tags from a corpus of 7932 examples and 4866436 words\n",
      "2020-02-23 09:59:54,212 : INFO : Loading a fresh vocabulary\n",
      "2020-02-23 09:59:54,248 : INFO : effective_min_count=5 retains 15409 unique words (28% of original 54008, drops 38599)\n",
      "2020-02-23 09:59:54,248 : INFO : effective_min_count=5 leaves 4811064 word corpus (98% of original 4866436, drops 55372)\n",
      "2020-02-23 09:59:54,290 : INFO : deleting the raw counts dictionary of 54008 items\n",
      "2020-02-23 09:59:54,292 : INFO : sample=0.001 downsamples 51 most-common words\n",
      "2020-02-23 09:59:54,293 : INFO : downsampling leaves estimated 4105293 word corpus (85.3% of prior 4811064)\n",
      "2020-02-23 09:59:54,333 : INFO : estimated required memory for 15409 words and 300 dimensions: 54204500 bytes\n",
      "2020-02-23 09:59:54,334 : INFO : resetting layer weights\n",
      "2020-02-23 09:59:57,936 : INFO : training model with 5 workers on 15409 vocabulary and 300 features, using sg=0 hs=0 sample=0.001 negative=5 window=2\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "training epoch 0 ...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2020-02-23 09:59:58,943 : INFO : EPOCH 1 - PROGRESS: at 36.91% examples, 1515329 words/s, in_qsize 9, out_qsize 0\n",
      "2020-02-23 09:59:59,947 : INFO : EPOCH 1 - PROGRESS: at 75.26% examples, 1540463 words/s, in_qsize 9, out_qsize 0\n",
      "2020-02-23 10:00:00,621 : INFO : worker thread finished; awaiting finish of 4 more threads\n",
      "2020-02-23 10:00:00,629 : INFO : worker thread finished; awaiting finish of 3 more threads\n",
      "2020-02-23 10:00:00,631 : INFO : worker thread finished; awaiting finish of 2 more threads\n",
      "2020-02-23 10:00:00,631 : INFO : worker thread finished; awaiting finish of 1 more threads\n",
      "2020-02-23 10:00:00,632 : INFO : worker thread finished; awaiting finish of 0 more threads\n",
      "2020-02-23 10:00:00,633 : INFO : EPOCH - 1 : training on 4866436 raw words (4113427 effective words) took 2.7s, 1525990 effective words/s\n",
      "2020-02-23 10:00:00,634 : INFO : training on a 4866436 raw words (4113427 effective words) took 2.7s, 1524820 effective words/s\n",
      "2020-02-23 10:00:00,636 : INFO : precomputing L2-norms of doc weight vectors\n",
      "2020-02-23 10:00:00,682 : INFO : saving Doc2Vec object under model/alodokter-articles-doc2vec.model, separately None\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "found similar document with id 3700 in position 0 with similarity score 0.6231238842010498\n",
      "found similar document with id 7568 in position 0 with similarity score 0.7852587103843689\n",
      "found similar document with id 5502 in position 0 with similarity score 0.7272913455963135\n",
      "found similar document with id 4699 in position 0 with similarity score 0.750701367855072\n",
      "found similar document with id 4810 in position 0 with similarity score 0.7558729648590088\n",
      "found similar document with id 4295 in position 0 with similarity score 0.8224493265151978\n",
      "found similar document with id 6448 in position 0 with similarity score 0.8298599720001221\n",
      "found similar document with id 2632 in position 0 with similarity score 0.7019071578979492\n",
      "found similar document with id 3084 in position 0 with similarity score 0.585481584072113\n",
      "mean percentiles: 90.00\n",
      "========== Saving best model with mean_percentiles: 90.00 ==========\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2020-02-23 10:00:01,124 : INFO : saved model/alodokter-articles-doc2vec.model\n",
      "2020-02-23 10:00:01,125 : WARNING : Effective 'alpha' higher than previous training cycles\n",
      "2020-02-23 10:00:01,125 : INFO : training model with 5 workers on 15409 vocabulary and 300 features, using sg=0 hs=0 sample=0.001 negative=5 window=2\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "training epoch 1 ...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2020-02-23 10:00:02,141 : INFO : EPOCH 1 - PROGRESS: at 26.63% examples, 1074402 words/s, in_qsize 8, out_qsize 1\n",
      "2020-02-23 10:00:03,142 : INFO : EPOCH 1 - PROGRESS: at 60.33% examples, 1234665 words/s, in_qsize 9, out_qsize 0\n",
      "2020-02-23 10:00:04,142 : INFO : EPOCH 1 - PROGRESS: at 96.75% examples, 1323094 words/s, in_qsize 10, out_qsize 0\n",
      "2020-02-23 10:00:04,211 : INFO : worker thread finished; awaiting finish of 4 more threads\n",
      "2020-02-23 10:00:04,214 : INFO : worker thread finished; awaiting finish of 3 more threads\n",
      "2020-02-23 10:00:04,222 : INFO : worker thread finished; awaiting finish of 2 more threads\n",
      "2020-02-23 10:00:04,229 : INFO : worker thread finished; awaiting finish of 1 more threads\n",
      "2020-02-23 10:00:04,233 : INFO : worker thread finished; awaiting finish of 0 more threads\n",
      "2020-02-23 10:00:04,233 : INFO : EPOCH - 1 : training on 4866436 raw words (4113436 effective words) took 3.1s, 1325287 effective words/s\n",
      "2020-02-23 10:00:04,234 : INFO : training on a 4866436 raw words (4113436 effective words) took 3.1s, 1323553 effective words/s\n",
      "2020-02-23 10:00:04,266 : INFO : saving Doc2Vec object under model/alodokter-articles-doc2vec.model, separately None\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "found similar document with id 571 in position 1 with similarity score 0.5982423424720764\n",
      "found similar document with id 7040 in position 0 with similarity score 0.6924117207527161\n",
      "found similar document with id 1551 in position 0 with similarity score 0.5424140095710754\n",
      "found similar document with id 6438 in position 0 with similarity score 0.669685959815979\n",
      "found similar document with id 373 in position 9 with similarity score 0.4449630379676819\n",
      "found similar document with id 5437 in position 0 with similarity score 0.6495814323425293\n",
      "found similar document with id 4804 in position 0 with similarity score 0.6243957877159119\n",
      "found similar document with id 2464 in position 0 with similarity score 0.637941837310791\n",
      "found similar document with id 3942 in position 0 with similarity score 0.6084734797477722\n",
      "found similar document with id 6217 in position 0 with similarity score 0.7411275506019592\n",
      "mean percentiles: 90.00\n",
      "========== Saving best model with mean_percentiles: 90.00 ==========\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2020-02-23 10:00:04,660 : INFO : saved model/alodokter-articles-doc2vec.model\n",
      "2020-02-23 10:00:04,661 : WARNING : Effective 'alpha' higher than previous training cycles\n",
      "2020-02-23 10:00:04,661 : INFO : training model with 5 workers on 15409 vocabulary and 300 features, using sg=0 hs=0 sample=0.001 negative=5 window=2\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "training epoch 2 ...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2020-02-23 10:00:05,673 : INFO : EPOCH 1 - PROGRESS: at 36.91% examples, 1510696 words/s, in_qsize 9, out_qsize 0\n",
      "2020-02-23 10:00:06,677 : INFO : EPOCH 1 - PROGRESS: at 74.89% examples, 1530604 words/s, in_qsize 10, out_qsize 0\n",
      "2020-02-23 10:00:07,439 : INFO : worker thread finished; awaiting finish of 4 more threads\n",
      "2020-02-23 10:00:07,441 : INFO : worker thread finished; awaiting finish of 3 more threads\n",
      "2020-02-23 10:00:07,443 : INFO : worker thread finished; awaiting finish of 2 more threads\n",
      "2020-02-23 10:00:07,445 : INFO : worker thread finished; awaiting finish of 1 more threads\n",
      "2020-02-23 10:00:07,450 : INFO : worker thread finished; awaiting finish of 0 more threads\n",
      "2020-02-23 10:00:07,451 : INFO : EPOCH - 1 : training on 4866436 raw words (4113873 effective words) took 2.8s, 1476558 effective words/s\n",
      "2020-02-23 10:00:07,451 : INFO : training on a 4866436 raw words (4113873 effective words) took 2.8s, 1474992 effective words/s\n",
      "2020-02-23 10:00:07,478 : WARNING : Effective 'alpha' higher than previous training cycles\n",
      "2020-02-23 10:00:07,479 : INFO : training model with 5 workers on 15409 vocabulary and 300 features, using sg=0 hs=0 sample=0.001 negative=5 window=2\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "found similar document with id 6266 in position 0 with similarity score 0.4655887484550476\n",
      "found similar document with id 4497 in position 0 with similarity score 0.592694878578186\n",
      "found similar document with id 2337 in position 0 with similarity score 0.5482645630836487\n",
      "found similar document with id 2086 in position 0 with similarity score 0.6456488370895386\n",
      "found similar document with id 3489 in position 0 with similarity score 0.6533195376396179\n",
      "found similar document with id 4807 in position 0 with similarity score 0.670346736907959\n",
      "found similar document with id 5934 in position 0 with similarity score 0.6296235918998718\n",
      "found similar document with id 1630 in position 2 with similarity score 0.526195764541626\n",
      "found similar document with id 4401 in position 0 with similarity score 0.5927433371543884\n",
      "mean percentiles: 88.00\n",
      "current mean_percentiles: 88.00, best: 90.00\n",
      "training epoch 3 ...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2020-02-23 10:00:08,483 : INFO : EPOCH 1 - PROGRESS: at 30.08% examples, 1232685 words/s, in_qsize 9, out_qsize 0\n",
      "2020-02-23 10:00:09,485 : INFO : EPOCH 1 - PROGRESS: at 63.64% examples, 1310117 words/s, in_qsize 10, out_qsize 0\n",
      "2020-02-23 10:00:10,420 : INFO : worker thread finished; awaiting finish of 4 more threads\n",
      "2020-02-23 10:00:10,424 : INFO : worker thread finished; awaiting finish of 3 more threads\n",
      "2020-02-23 10:00:10,427 : INFO : worker thread finished; awaiting finish of 2 more threads\n",
      "2020-02-23 10:00:10,432 : INFO : worker thread finished; awaiting finish of 1 more threads\n",
      "2020-02-23 10:00:10,433 : INFO : worker thread finished; awaiting finish of 0 more threads\n",
      "2020-02-23 10:00:10,433 : INFO : EPOCH - 1 : training on 4866436 raw words (4112803 effective words) took 3.0s, 1393835 effective words/s\n",
      "2020-02-23 10:00:10,434 : INFO : training on a 4866436 raw words (4112803 effective words) took 3.0s, 1392241 effective words/s\n",
      "2020-02-23 10:00:10,465 : INFO : saving Doc2Vec object under model/alodokter-articles-doc2vec.model, separately None\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "found similar document with id 6927 in position 0 with similarity score 0.5845781564712524\n",
      "found similar document with id 4407 in position 0 with similarity score 0.7064756155014038\n",
      "found similar document with id 6178 in position 0 with similarity score 0.611943781375885\n",
      "found similar document with id 678 in position 3 with similarity score 0.5245034694671631\n",
      "found similar document with id 3654 in position 0 with similarity score 0.6501209735870361\n",
      "found similar document with id 7185 in position 0 with similarity score 0.5646973848342896\n",
      "found similar document with id 3661 in position 0 with similarity score 0.5748719573020935\n",
      "found similar document with id 5724 in position 0 with similarity score 0.6617432832717896\n",
      "found similar document with id 2752 in position 0 with similarity score 0.6111876368522644\n",
      "found similar document with id 3916 in position 0 with similarity score 0.7313289642333984\n",
      "mean percentiles: 97.00\n",
      "========== Saving best model with mean_percentiles: 97.00 ==========\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2020-02-23 10:00:10,874 : INFO : saved model/alodokter-articles-doc2vec.model\n",
      "2020-02-23 10:00:10,874 : WARNING : Effective 'alpha' higher than previous training cycles\n",
      "2020-02-23 10:00:10,875 : INFO : training model with 5 workers on 15409 vocabulary and 300 features, using sg=0 hs=0 sample=0.001 negative=5 window=2\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "training epoch 4 ...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2020-02-23 10:00:11,890 : INFO : EPOCH 1 - PROGRESS: at 37.10% examples, 1513927 words/s, in_qsize 10, out_qsize 1\n",
      "2020-02-23 10:00:12,899 : INFO : EPOCH 1 - PROGRESS: at 75.08% examples, 1528522 words/s, in_qsize 10, out_qsize 0\n",
      "2020-02-23 10:00:13,525 : INFO : worker thread finished; awaiting finish of 4 more threads\n",
      "2020-02-23 10:00:13,528 : INFO : worker thread finished; awaiting finish of 3 more threads\n",
      "2020-02-23 10:00:13,529 : INFO : worker thread finished; awaiting finish of 2 more threads\n",
      "2020-02-23 10:00:13,530 : INFO : worker thread finished; awaiting finish of 1 more threads\n",
      "2020-02-23 10:00:13,535 : INFO : worker thread finished; awaiting finish of 0 more threads\n",
      "2020-02-23 10:00:13,536 : INFO : EPOCH - 1 : training on 4866436 raw words (4113198 effective words) took 2.7s, 1548181 effective words/s\n",
      "2020-02-23 10:00:13,536 : INFO : training on a 4866436 raw words (4113198 effective words) took 2.7s, 1545907 effective words/s\n",
      "2020-02-23 10:00:13,561 : WARNING : Effective 'alpha' higher than previous training cycles\n",
      "2020-02-23 10:00:13,562 : INFO : training model with 5 workers on 15409 vocabulary and 300 features, using sg=0 hs=0 sample=0.001 negative=5 window=2\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "found similar document with id 7296 in position 5 with similarity score 0.4947265684604645\n",
      "found similar document with id 3299 in position 0 with similarity score 0.5944305658340454\n",
      "found similar document with id 7384 in position 0 with similarity score 0.563948392868042\n",
      "found similar document with id 2174 in position 0 with similarity score 0.5458066463470459\n",
      "found similar document with id 7795 in position 0 with similarity score 0.6145461797714233\n",
      "found similar document with id 6517 in position 0 with similarity score 0.6841855049133301\n",
      "found similar document with id 3347 in position 0 with similarity score 0.5656232833862305\n",
      "found similar document with id 4263 in position 0 with similarity score 0.5948383212089539\n",
      "found similar document with id 733 in position 2 with similarity score 0.534643292427063\n",
      "mean percentiles: 83.00\n",
      "current mean_percentiles: 83.00, best: 97.00\n",
      "training epoch 5 ...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2020-02-23 10:00:14,565 : INFO : EPOCH 1 - PROGRESS: at 37.10% examples, 1531295 words/s, in_qsize 10, out_qsize 0\n",
      "2020-02-23 10:00:15,567 : INFO : EPOCH 1 - PROGRESS: at 74.26% examples, 1525621 words/s, in_qsize 10, out_qsize 0\n",
      "2020-02-23 10:00:16,257 : INFO : worker thread finished; awaiting finish of 4 more threads\n",
      "2020-02-23 10:00:16,261 : INFO : worker thread finished; awaiting finish of 3 more threads\n",
      "2020-02-23 10:00:16,265 : INFO : worker thread finished; awaiting finish of 2 more threads\n",
      "2020-02-23 10:00:16,268 : INFO : worker thread finished; awaiting finish of 1 more threads\n",
      "2020-02-23 10:00:16,273 : INFO : worker thread finished; awaiting finish of 0 more threads\n",
      "2020-02-23 10:00:16,274 : INFO : EPOCH - 1 : training on 4866436 raw words (4114013 effective words) took 2.7s, 1518458 effective words/s\n",
      "2020-02-23 10:00:16,274 : INFO : training on a 4866436 raw words (4114013 effective words) took 2.7s, 1516778 effective words/s\n",
      "2020-02-23 10:00:16,300 : WARNING : Effective 'alpha' higher than previous training cycles\n",
      "2020-02-23 10:00:16,300 : INFO : training model with 5 workers on 15409 vocabulary and 300 features, using sg=0 hs=0 sample=0.001 negative=5 window=2\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "found similar document with id 4536 in position 0 with similarity score 0.5941367745399475\n",
      "found similar document with id 1575 in position 0 with similarity score 0.5020698308944702\n",
      "found similar document with id 4938 in position 0 with similarity score 0.5367515683174133\n",
      "found similar document with id 1693 in position 0 with similarity score 0.5017469525337219\n",
      "found similar document with id 6706 in position 0 with similarity score 0.5239243507385254\n",
      "found similar document with id 5156 in position 0 with similarity score 0.5190706849098206\n",
      "found similar document with id 5807 in position 0 with similarity score 0.6640538573265076\n",
      "found similar document with id 5658 in position 0 with similarity score 0.6732567548751831\n",
      "found similar document with id 7867 in position 9 with similarity score 0.49959293007850647\n",
      "mean percentiles: 81.00\n",
      "current mean_percentiles: 81.00, best: 97.00\n",
      "training epoch 6 ...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2020-02-23 10:00:17,310 : INFO : EPOCH 1 - PROGRESS: at 35.70% examples, 1460172 words/s, in_qsize 9, out_qsize 0\n",
      "2020-02-23 10:00:18,311 : INFO : EPOCH 1 - PROGRESS: at 73.01% examples, 1497440 words/s, in_qsize 9, out_qsize 0\n",
      "2020-02-23 10:00:19,020 : INFO : worker thread finished; awaiting finish of 4 more threads\n",
      "2020-02-23 10:00:19,025 : INFO : worker thread finished; awaiting finish of 3 more threads\n",
      "2020-02-23 10:00:19,029 : INFO : worker thread finished; awaiting finish of 2 more threads\n",
      "2020-02-23 10:00:19,032 : INFO : worker thread finished; awaiting finish of 1 more threads\n",
      "2020-02-23 10:00:19,037 : INFO : worker thread finished; awaiting finish of 0 more threads\n",
      "2020-02-23 10:00:19,037 : INFO : EPOCH - 1 : training on 4866436 raw words (4113792 effective words) took 2.7s, 1504702 effective words/s\n",
      "2020-02-23 10:00:19,038 : INFO : training on a 4866436 raw words (4113792 effective words) took 2.7s, 1503053 effective words/s\n",
      "2020-02-23 10:00:19,066 : INFO : saving Doc2Vec object under model/alodokter-articles-doc2vec.model, separately None\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "found similar document with id 1086 in position 0 with similarity score 0.5050361156463623\n",
      "found similar document with id 7821 in position 0 with similarity score 0.4977290630340576\n",
      "found similar document with id 4293 in position 0 with similarity score 0.5938915014266968\n",
      "found similar document with id 1289 in position 0 with similarity score 0.4444548189640045\n",
      "found similar document with id 5550 in position 0 with similarity score 0.5768442153930664\n",
      "found similar document with id 3930 in position 0 with similarity score 0.5669462084770203\n",
      "found similar document with id 5120 in position 0 with similarity score 0.540306806564331\n",
      "found similar document with id 5317 in position 0 with similarity score 0.6424815654754639\n",
      "found similar document with id 1765 in position 1 with similarity score 0.49373659491539\n",
      "found similar document with id 4473 in position 0 with similarity score 0.5734233856201172\n",
      "mean percentiles: 99.00\n",
      "========== Saving best model with mean_percentiles: 99.00 ==========\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2020-02-23 10:00:19,470 : INFO : saved model/alodokter-articles-doc2vec.model\n",
      "2020-02-23 10:00:19,471 : WARNING : Effective 'alpha' higher than previous training cycles\n",
      "2020-02-23 10:00:19,471 : INFO : training model with 5 workers on 15409 vocabulary and 300 features, using sg=0 hs=0 sample=0.001 negative=5 window=2\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "training epoch 7 ...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2020-02-23 10:00:20,482 : INFO : EPOCH 1 - PROGRESS: at 36.91% examples, 1511032 words/s, in_qsize 9, out_qsize 0\n",
      "2020-02-23 10:00:21,484 : INFO : EPOCH 1 - PROGRESS: at 72.44% examples, 1483106 words/s, in_qsize 9, out_qsize 0\n",
      "2020-02-23 10:00:22,245 : INFO : worker thread finished; awaiting finish of 4 more threads\n",
      "2020-02-23 10:00:22,246 : INFO : worker thread finished; awaiting finish of 3 more threads\n",
      "2020-02-23 10:00:22,252 : INFO : worker thread finished; awaiting finish of 2 more threads\n",
      "2020-02-23 10:00:22,254 : INFO : worker thread finished; awaiting finish of 1 more threads\n",
      "2020-02-23 10:00:22,257 : INFO : worker thread finished; awaiting finish of 0 more threads\n",
      "2020-02-23 10:00:22,258 : INFO : EPOCH - 1 : training on 4866436 raw words (4112647 effective words) took 2.8s, 1476996 effective words/s\n",
      "2020-02-23 10:00:22,258 : INFO : training on a 4866436 raw words (4112647 effective words) took 2.8s, 1475870 effective words/s\n",
      "2020-02-23 10:00:22,281 : WARNING : Effective 'alpha' higher than previous training cycles\n",
      "2020-02-23 10:00:22,282 : INFO : training model with 5 workers on 15409 vocabulary and 300 features, using sg=0 hs=0 sample=0.001 negative=5 window=2\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "found similar document with id 2386 in position 0 with similarity score 0.6560759544372559\n",
      "found similar document with id 2935 in position 0 with similarity score 0.5385875701904297\n",
      "found similar document with id 5445 in position 6 with similarity score 0.4988081455230713\n",
      "found similar document with id 2887 in position 0 with similarity score 0.5284514427185059\n",
      "found similar document with id 4150 in position 0 with similarity score 0.565554141998291\n",
      "found similar document with id 962 in position 0 with similarity score 0.5409508347511292\n",
      "found similar document with id 4267 in position 0 with similarity score 0.5429056882858276\n",
      "found similar document with id 5097 in position 0 with similarity score 0.6230177879333496\n",
      "mean percentiles: 74.00\n",
      "current mean_percentiles: 74.00, best: 99.00\n",
      "training epoch 8 ...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2020-02-23 10:00:23,287 : INFO : EPOCH 1 - PROGRESS: at 35.26% examples, 1450329 words/s, in_qsize 10, out_qsize 0\n",
      "2020-02-23 10:00:24,293 : INFO : EPOCH 1 - PROGRESS: at 73.63% examples, 1509079 words/s, in_qsize 10, out_qsize 1\n",
      "2020-02-23 10:00:24,980 : INFO : worker thread finished; awaiting finish of 4 more threads\n",
      "2020-02-23 10:00:24,984 : INFO : worker thread finished; awaiting finish of 3 more threads\n",
      "2020-02-23 10:00:24,987 : INFO : worker thread finished; awaiting finish of 2 more threads\n",
      "2020-02-23 10:00:24,989 : INFO : worker thread finished; awaiting finish of 1 more threads\n",
      "2020-02-23 10:00:24,990 : INFO : worker thread finished; awaiting finish of 0 more threads\n",
      "2020-02-23 10:00:24,991 : INFO : EPOCH - 1 : training on 4866436 raw words (4113100 effective words) took 2.7s, 1520113 effective words/s\n",
      "2020-02-23 10:00:24,991 : INFO : training on a 4866436 raw words (4113100 effective words) took 2.7s, 1518216 effective words/s\n",
      "2020-02-23 10:00:25,016 : INFO : saving Doc2Vec object under model/alodokter-articles-doc2vec.model, separately None\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "found similar document with id 6952 in position 0 with similarity score 0.5690685510635376\n",
      "found similar document with id 5084 in position 0 with similarity score 0.6109544038772583\n",
      "found similar document with id 3548 in position 0 with similarity score 0.5299829840660095\n",
      "found similar document with id 4701 in position 0 with similarity score 0.5516369342803955\n",
      "found similar document with id 583 in position 0 with similarity score 0.44746965169906616\n",
      "found similar document with id 4207 in position 0 with similarity score 0.53471839427948\n",
      "found similar document with id 7704 in position 0 with similarity score 0.5501301884651184\n",
      "found similar document with id 7734 in position 0 with similarity score 0.6207619905471802\n",
      "found similar document with id 4241 in position 0 with similarity score 0.609315037727356\n",
      "found similar document with id 6880 in position 0 with similarity score 0.5950736999511719\n",
      "mean percentiles: 100.00\n",
      "========== Saving best model with mean_percentiles: 100.00 ==========\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2020-02-23 10:00:25,414 : INFO : saved model/alodokter-articles-doc2vec.model\n",
      "2020-02-23 10:00:25,414 : WARNING : Effective 'alpha' higher than previous training cycles\n",
      "2020-02-23 10:00:25,415 : INFO : training model with 5 workers on 15409 vocabulary and 300 features, using sg=0 hs=0 sample=0.001 negative=5 window=2\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "training epoch 9 ...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2020-02-23 10:00:26,423 : INFO : EPOCH 1 - PROGRESS: at 37.71% examples, 1551746 words/s, in_qsize 10, out_qsize 0\n",
      "2020-02-23 10:00:27,428 : INFO : EPOCH 1 - PROGRESS: at 72.63% examples, 1488935 words/s, in_qsize 9, out_qsize 0\n",
      "2020-02-23 10:00:28,219 : INFO : worker thread finished; awaiting finish of 4 more threads\n",
      "2020-02-23 10:00:28,223 : INFO : worker thread finished; awaiting finish of 3 more threads\n",
      "2020-02-23 10:00:28,225 : INFO : worker thread finished; awaiting finish of 2 more threads\n",
      "2020-02-23 10:00:28,226 : INFO : worker thread finished; awaiting finish of 1 more threads\n",
      "2020-02-23 10:00:28,228 : INFO : worker thread finished; awaiting finish of 0 more threads\n",
      "2020-02-23 10:00:28,228 : INFO : EPOCH - 1 : training on 4866436 raw words (4113059 effective words) took 2.8s, 1464859 effective words/s\n",
      "2020-02-23 10:00:28,229 : INFO : training on a 4866436 raw words (4113059 effective words) took 2.8s, 1462053 effective words/s\n",
      "2020-02-23 10:00:28,251 : WARNING : Effective 'alpha' higher than previous training cycles\n",
      "2020-02-23 10:00:28,252 : INFO : training model with 5 workers on 15409 vocabulary and 300 features, using sg=0 hs=0 sample=0.001 negative=5 window=2\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "found similar document with id 7623 in position 1 with similarity score 0.5045701861381531\n",
      "found similar document with id 5692 in position 0 with similarity score 0.4925502836704254\n",
      "found similar document with id 3873 in position 0 with similarity score 0.6064233779907227\n",
      "found similar document with id 2735 in position 1 with similarity score 0.44647854566574097\n",
      "found similar document with id 2619 in position 0 with similarity score 0.45451104640960693\n",
      "found similar document with id 4347 in position 0 with similarity score 0.464932382106781\n",
      "found similar document with id 3388 in position 0 with similarity score 0.4294683337211609\n",
      "found similar document with id 4167 in position 0 with similarity score 0.5130352973937988\n",
      "mean percentiles: 78.00\n",
      "current mean_percentiles: 78.00, best: 100.00\n",
      "training epoch 10 ...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2020-02-23 10:00:29,274 : INFO : EPOCH 1 - PROGRESS: at 36.91% examples, 1496369 words/s, in_qsize 10, out_qsize 0\n",
      "2020-02-23 10:00:30,274 : INFO : EPOCH 1 - PROGRESS: at 70.35% examples, 1436538 words/s, in_qsize 9, out_qsize 0\n",
      "2020-02-23 10:00:31,015 : INFO : worker thread finished; awaiting finish of 4 more threads\n",
      "2020-02-23 10:00:31,018 : INFO : worker thread finished; awaiting finish of 3 more threads\n",
      "2020-02-23 10:00:31,019 : INFO : worker thread finished; awaiting finish of 2 more threads\n",
      "2020-02-23 10:00:31,020 : INFO : worker thread finished; awaiting finish of 1 more threads\n",
      "2020-02-23 10:00:31,028 : INFO : worker thread finished; awaiting finish of 0 more threads\n",
      "2020-02-23 10:00:31,029 : INFO : EPOCH - 1 : training on 4866436 raw words (4113468 effective words) took 2.8s, 1483231 effective words/s\n",
      "2020-02-23 10:00:31,029 : INFO : training on a 4866436 raw words (4113468 effective words) took 2.8s, 1481350 effective words/s\n",
      "2020-02-23 10:00:31,053 : WARNING : Effective 'alpha' higher than previous training cycles\n",
      "2020-02-23 10:00:31,053 : INFO : training model with 5 workers on 15409 vocabulary and 300 features, using sg=0 hs=0 sample=0.001 negative=5 window=2\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "found similar document with id 4119 in position 0 with similarity score 0.4817700982093811\n",
      "found similar document with id 2976 in position 3 with similarity score 0.4866436719894409\n",
      "found similar document with id 6770 in position 0 with similarity score 0.5098720788955688\n",
      "found similar document with id 7777 in position 0 with similarity score 0.5361309051513672\n",
      "found similar document with id 4517 in position 1 with similarity score 0.5081150531768799\n",
      "found similar document with id 4165 in position 0 with similarity score 0.5586714148521423\n",
      "found similar document with id 5589 in position 0 with similarity score 0.5203511118888855\n",
      "found similar document with id 1063 in position 0 with similarity score 0.5195136070251465\n",
      "mean percentiles: 76.00\n",
      "current mean_percentiles: 76.00, best: 100.00\n",
      "training epoch 11 ...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2020-02-23 10:00:32,061 : INFO : EPOCH 1 - PROGRESS: at 37.32% examples, 1532816 words/s, in_qsize 10, out_qsize 0\n",
      "2020-02-23 10:00:33,077 : INFO : EPOCH 1 - PROGRESS: at 76.07% examples, 1548092 words/s, in_qsize 10, out_qsize 1\n",
      "2020-02-23 10:00:33,662 : INFO : worker thread finished; awaiting finish of 4 more threads\n",
      "2020-02-23 10:00:33,667 : INFO : worker thread finished; awaiting finish of 3 more threads\n",
      "2020-02-23 10:00:33,668 : INFO : worker thread finished; awaiting finish of 2 more threads\n",
      "2020-02-23 10:00:33,671 : INFO : worker thread finished; awaiting finish of 1 more threads\n",
      "2020-02-23 10:00:33,672 : INFO : worker thread finished; awaiting finish of 0 more threads\n",
      "2020-02-23 10:00:33,672 : INFO : EPOCH - 1 : training on 4866436 raw words (4113151 effective words) took 2.6s, 1572415 effective words/s\n",
      "2020-02-23 10:00:33,673 : INFO : training on a 4866436 raw words (4113151 effective words) took 2.6s, 1570482 effective words/s\n",
      "2020-02-23 10:00:33,697 : WARNING : Effective 'alpha' higher than previous training cycles\n",
      "2020-02-23 10:00:33,698 : INFO : training model with 5 workers on 15409 vocabulary and 300 features, using sg=0 hs=0 sample=0.001 negative=5 window=2\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "found similar document with id 6504 in position 0 with similarity score 0.43613314628601074\n",
      "found similar document with id 7434 in position 0 with similarity score 0.5340348482131958\n",
      "found similar document with id 531 in position 8 with similarity score 0.48238855600357056\n",
      "found similar document with id 7359 in position 1 with similarity score 0.3738921582698822\n",
      "found similar document with id 7758 in position 5 with similarity score 0.37554943561553955\n",
      "found similar document with id 6593 in position 0 with similarity score 0.3600296080112457\n",
      "mean percentiles: 46.00\n",
      "current mean_percentiles: 46.00, best: 100.00\n",
      "training epoch 12 ...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2020-02-23 10:00:34,704 : INFO : EPOCH 1 - PROGRESS: at 36.28% examples, 1486485 words/s, in_qsize 9, out_qsize 0\n",
      "2020-02-23 10:00:35,715 : INFO : EPOCH 1 - PROGRESS: at 74.47% examples, 1521212 words/s, in_qsize 9, out_qsize 0\n",
      "2020-02-23 10:00:36,375 : INFO : worker thread finished; awaiting finish of 4 more threads\n",
      "2020-02-23 10:00:36,380 : INFO : worker thread finished; awaiting finish of 3 more threads\n",
      "2020-02-23 10:00:36,382 : INFO : worker thread finished; awaiting finish of 2 more threads\n",
      "2020-02-23 10:00:36,382 : INFO : worker thread finished; awaiting finish of 1 more threads\n",
      "2020-02-23 10:00:36,384 : INFO : worker thread finished; awaiting finish of 0 more threads\n",
      "2020-02-23 10:00:36,385 : INFO : EPOCH - 1 : training on 4866436 raw words (4114068 effective words) took 2.7s, 1532675 effective words/s\n",
      "2020-02-23 10:00:36,385 : INFO : training on a 4866436 raw words (4114068 effective words) took 2.7s, 1530995 effective words/s\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "found similar document with id 5518 in position 0 with similarity score 0.33522993326187134\n",
      "found similar document with id 3107 in position 3 with similarity score 0.45306405425071716\n",
      "found similar document with id 6105 in position 1 with similarity score 0.4211587607860565\n",
      "mean percentiles: 26.00\n",
      "current mean_percentiles: 26.00, best: 100.00\n",
      "early stop...\n",
      "========== Saving best model with mean_percentiles: 100.00 ==========\n"
     ]
    }
   ],
   "source": [
    "model = train(documents)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
