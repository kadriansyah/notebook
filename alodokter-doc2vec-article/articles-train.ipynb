{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# import sys\n",
    "# !{sys.executable} -m pip install numpy pandas matplotlib sklearn seaborn\n",
    "# !{sys.executable} -m pip install --upgrade gensim\n",
    "# !{sys.executable} -m pip install nltk\n",
    "# import nltk\n",
    "# nltk.download('punkt')\n",
    "# !{sys.executable} -m pip install beautifulsoup4"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import re\n",
    "import gensim\n",
    "import multiprocessing\n",
    "import random\n",
    "import logging\n",
    "import numpy as np\n",
    "\n",
    "from pathlib import Path\n",
    "from os import listdir\n",
    "from os.path import isfile, join\n",
    "from nltk.tokenize import RegexpTokenizer\n",
    "from bs4 import BeautifulSoup\n",
    "\n",
    "from sklearn.cluster import KMeans\n",
    "from gensim.models.doc2vec import Doc2Vec, TaggedDocument"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "CORPUS_PATH  = 'data/'\n",
    "SKIP_FILES = \"\"\n",
    "NEWLINE = '\\n'\n",
    "\n",
    "def clean_str(string):\n",
    "    \"\"\"\n",
    "    Tokenization/string cleaning for all datasets except for SST.\n",
    "    Original taken from https://github.com/yoonkim/CNN_sentence/blob/master/process_data.py\n",
    "    \"\"\"\n",
    "    string = re.sub(r\"[^A-Za-z0-9(),!?\\'\\`]\", \" \", string)\n",
    "    string = re.sub(r\",\", \" \", string)\n",
    "    string = re.sub(r\"!\", \" ! \", string)\n",
    "    string = re.sub(r\"\\(\", \" ( \", string)\n",
    "    string = re.sub(r\"\\)\", \" ) \", string)\n",
    "    string = re.sub(r\"\\?\", \" ? \", string)\n",
    "    string = re.sub(r\"\\s{2,}\", \" \", string)\n",
    "    return string.strip().lower()\n",
    "\n",
    "\"\"\"\n",
    "read training files\n",
    "\"\"\"\n",
    "def read_files(path=CORPUS_PATH):\n",
    "#     print(\"processing path: {} ...\".format(path))\n",
    "    for root, dirnames, filenames in os.walk(path):\n",
    "        for dirname in dirnames:\n",
    "            read_files(os.path.join(root, dirname))\n",
    "        for filename in filenames:\n",
    "            if filename not in SKIP_FILES:\n",
    "                filepath = os.path.join(root, filename)\n",
    "                if os.path.isfile(filepath):\n",
    "                    lines = []\n",
    "                    f = open(filepath, encoding='latin-1')\n",
    "                    for line in f:\n",
    "                        lines.append(line)\n",
    "                    f.close()\n",
    "                    content = NEWLINE.join(lines)\n",
    "                    yield filename, content"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_data():\n",
    "    documents = []\n",
    "    for filename, text in read_files():\n",
    "#         print(\"==== filename is {} ====\\n{}\\n\\n\".format(filename, text))\n",
    "        documents.append(clean_str(text).split(' '))\n",
    "    documents = [TaggedDocument(doc, [i]) for i, doc in enumerate(documents)]\n",
    "    return documents"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "we have 7932 documents\n"
     ]
    }
   ],
   "source": [
    "documents = get_data()\n",
    "print(\"we have {} documents\".format(len(documents)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "TaggedDocument(words=['penyebab', 'bayi', 'muntah', 'setelah', 'minum', 'asi', 'dan', 'cara', 'mengatasinya', 'bayi', 'muntah', 'setelah', 'minum', 'asi', '(', 'air', 'susu', 'ibu', ')', 'adalah', 'keluhan', 'yang', 'sering', 'terjadi', 'sebagian', 'bayi', 'bahkan', 'mengalaminya', 'hampir', 'setiap', 'kali', 'selesai', 'menyusu', 'meski', 'umumnya', 'normal', 'kondisi', 'ini', 'bisa', 'juga', 'disebabkan', 'oleh', 'gangguan', 'berbahaya', 'yang', 'harus', 'diwaspadai', 'bayi', 'muntah', 'setelah', 'minum', 'asi', 'dikenal', 'dengan', 'istilah', 'gumoh', 'gumoh', 'dikatakan', 'normal', 'apabila', 'tidak', 'menyebabkan', 'bayi', 'rewel', 'atau', 'sesak', 'napas', 'meskipun', 'dapat', 'dicegah', 'kondisi', 'tersebut', 'tidak', 'memerlukan', 'penanganan', 'khusus', 'dan', 'normal', 'terjadi', 'penyebab', 'bayi', 'muntah', 'setelah', 'minum', 'asi', 'gumoh', 'disebabkan', 'oleh', 'asi', 'atau', 'susu', 'yang', 'ditelan', 'bayi', 'kembali', 'ke', 'kerongkongan', 'karena', 'otot', 'di', 'saluran', 'pencernaan', 'bayi', 'yaitu', 'di', 'bagian', 'kerongkongan', 'dan', 'lambung', 'masih', 'lemah', 'kondisi', 'ini', 'disebut', 'sebagai', 'refluks', 'bayi', 'kemungkinan', 'mengalami', 'refluks', 'karena', 'ukuran', 'lambungnya', 'masih', 'sangat', 'kecil', 'sehingga', 'cepat', 'terisi', 'penuh', 'refluks', 'juga', 'terjadi', 'karena', 'katup', 'pada', 'kerongkongan', 'belum', 'sempurna', 'sehingga', 'belum', 'bekerja', 'secara', 'optimal', 'untuk', 'menahan', 'isi', 'lambung', 'umumnya', 'bayi', 'muntah', 'setelah', 'minum', 'asi', 'akan', 'berlangsung', 'hingga', 'usia', '4', '5', 'bulan', 'setelah', 'itu', 'gumoh', 'akan', 'berhenti', 'dengan', 'sendirinya', 'penyebab', 'lain', 'bayi', 'muntah', 'setelah', 'minum', 'asi', 'adalah', 'gastroenteritis', 'hanya', 'saja', 'infeksi', 'pada', 'saluran', 'cerna', 'bayi', 'ini', 'biasanya', 'disertai', 'dengan', 'diare', 'selain', 'gastoenteritis', 'ada', 'berbagai', 'penyebab', 'lain', 'bayi', 'muntah', 'setelah', 'minum', 'asi', 'mulai', 'dari', 'alergi', 'pilek', 'infeksi', 'telinga', 'infeksi', 'saluran', 'kemih', 'hingga', 'penyempitan', 'lambung', '(', 'stenosis', 'pilorus', ')', 'walaupun', 'bayi', 'muntah', 'setelah', 'minum', 'asi', 'sering', 'kali', 'disebabkan', 'oleh', 'gumoh', 'yang', 'normal', 'tapi', 'orang', 'tua', 'harus', 'tetap', 'mewaspadai', 'jika', 'bayi', 'muntah', 'disertai', 'dengan', 'gejala', 'lain', 'seperti', 'demam', 'kurang', 'mau', 'atau', 'tidak', 'mau', 'menyusu', 'sama', 'sekali', 'timbul', 'ruam', 'sulit', 'tidur', 'dan', 'rewel', 'ubun', 'ubun', 'tampak', 'menonjol', 'perut', 'bengkak', 'sesak', 'napas', 'muntah', 'disertai', 'darah', 'atau', 'cairan', 'hijau', 'muntah', 'terus', 'menerus', 'lebih', 'lebih', 'dari', 'satu', 'atau', 'dua', 'hari', 'mengalami', 'dehidrasi', 'yang', 'ditandai', 'dengan', 'bibir', 'kering', 'menangis', 'tanpa', 'air', 'mata', 'ubun', 'ubun', 'cekung', 'dan', 'jarang', 'buang', 'air', 'kecil', 'tips', 'meringankan', 'muntah', 'pada', 'bayi', 'bayi', 'gumoh', 'biasanya', 'tidak', 'perlu', 'dikhawatirkan', 'dan', 'akan', 'mereda', 'dengan', 'sendirinya', 'seiring', 'bertambahnya', 'usia', 'bayi', 'meski', 'demikian', 'ada', 'beberapa', 'cara', 'yang', 'dapat', 'dilakukan', 'untuk', 'meringankan', 'keluhan', 'bayi', 'muntah', 'setelah', 'minum', 'asi', 'upayakan', 'posisi', 'kepala', 'bayi', 'lebih', 'tinggi', 'dari', 'tubuhnya', 'saat', 'menyusu', 'posisikan', 'tubuhnya', 'tetap', 'tegak', 'setelah', 'menyusu', 'agar', 'bayi', 'dapat', 'lebih', 'mudah', 'bersendawa', 'biarkan', 'bayi', 'menyusu', 'dalam', 'keadaan', 'tenang', 'hal', 'ini', 'akan', 'mencegah', 'bayi', 'mengisap', 'terlalu', 'banyak', 'udara', 'bersamaan', 'dengan', 'asi', 'biasakan', 'bayi', 'menyusu', 'secukupnya', 'namun', 'lebih', 'sering', 'menyusu', 'terlalu', 'banyak', 'dapat', 'membuat', 'lambung', 'bayi', 'teregang', 'karena', 'penuh', 'sehingga', 'memicu', 'bayi', 'untuk', 'muntah', 'setelah', 'minum', 'asi', 'buat', 'bayi', 'sendawa', 'setiap', 'kali', 'habis', 'menyusu', 'biarkan', 'bayi', 'sendawa', 'terlebih', 'dulu', 'sebelum', 'berganti', 'payudara', 'pastikan', 'pakaian', 'atau', 'popok', 'bayi', 'tidak', 'terlalu', 'ketat', 'serta', 'hindari', 'menggendong', 'bayi', 'untuk', 'sendawa', 'dengan', 'posisi', 'perut', 'bayi', 'tepat', 'di', 'bahu', 'anda', 'hal', 'ini', 'untuk', 'mengurangi', 'tekanan', 'pada', 'perutnya', 'hindari', 'menggoyangkan', 'bayi', 'atau', 'membuat', 'bayi', 'aktif', 'segera', 'setelah', 'menyusu', 'sebaiknya', 'juga', 'jangan', 'bepergian', 'dengan', 'kendaraan', 'sesaat', 'setelah', 'bayi', 'menyusu', 'jika', 'bayi', 'sudah', 'cukup', 'besar', 'posisikan', 'agar', 'ia', 'duduk', 'sekitar', '30', 'menit', 'setelah', 'menyusu', 'posisikan', 'kepala', 'bayi', 'sedikit', 'lebih', 'tinggi', 'saat', 'tidur', 'anda', 'dapat', 'meletakkan', 'selimut', 'atau', 'handuk', 'yang', 'digulung', 'di', 'bawah', 'bahu', 'dan', 'kepalanya', 'sebaiknya', 'hindari', 'menggunakan', 'bantal', 'pada', 'bayi', 'teliti', 'kemungkinan', 'bayi', 'muntah', 'setelah', 'minum', 'asi', 'akibat', 'makanan', 'atau', 'minuman', 'yang', 'dikonsumsi', 'ibu', 'misalnya', 'susu', 'sapi', 'jika', 'bayi', 'muntah', 'setelah', 'minum', 'asi', 'disertai', 'tanda', 'tanda', 'bahaya', 'di', 'atas', 'atau', 'jika', 'anda', 'merasa', 'khawatir', 'akan', 'kondisi', 'ini', 'segeralah', 'konsultasikan', 'dengan', 'dokter', 'anak', 'catat', 'berapa', 'kali', 'atau', 'berapa', 'banyak', 'bayi', 'muntah', 'dan', 'apakah', 'terdapat', 'gejala', 'gejala', 'lainnya'], tags=[0])"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "documents[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 134,
   "metadata": {},
   "outputs": [],
   "source": [
    "def evaluate(model, documents, steps):\n",
    "    percentiles = np.zeros(steps)\n",
    "    for step in range(steps):\n",
    "        docid = np.random.randint(model.docvecs.count)\n",
    "        inferred_vector = model.infer_vector(documents[docid][0])\n",
    "        similars = model.docvecs.most_similar(positive=[inferred_vector], topn=10)\n",
    "        for idx,simdoc in enumerate(similars):\n",
    "            if simdoc[0] == docid:\n",
    "                print(\"found similar document with id {} in position {} with similarity score {}\".format(simdoc[0], idx, simdoc[1]))\n",
    "                percentiles[step] = ((len(similars) - idx) / len(similars)) * 100\n",
    "                break\n",
    "    return np.mean(percentiles)\n",
    "\n",
    "def train(documents=documents, model_name=\"model/alodokter-articles-doc2vec.model\", max_epochs=50, patience=3):\n",
    "    best_mean_percentiles = 0\n",
    "    logging.basicConfig(format='%(asctime)s : %(levelname)s : %(message)s', level=logging.INFO)\n",
    "    model = Doc2Vec(dm=1, vector_size=300, window=2, alpha=0.1, min_alpha=0.0001, min_count=5, epochs=1, workers=5)\n",
    "    model.build_vocab(documents)\n",
    "    for epoch in range(max_epochs):\n",
    "        print('training epoch {:d} ...'.format(epoch))\n",
    "        model.train(documents, total_examples=model.corpus_count,epochs=model.epochs)\n",
    "        mean_percentiles = evaluate(model,documents,10)\n",
    "        print('mean percentiles: {:.2f}'.format(mean_percentiles))\n",
    "        \n",
    "        if mean_percentiles < best_mean_percentiles:\n",
    "            print(\"current mean_percentiles: {:.2f}, best: {:.2f}\".format(mean_percentiles, best_mean_percentiles))\n",
    "            patience = patience-1\n",
    "        else:\n",
    "            best_mean_percentiles = mean_percentiles\n",
    "            print(\"========== Saving best model with mean_percentiles: {:.2f} ==========\".format(mean_percentiles))\n",
    "            model.save(model_name)\n",
    "            patience = patience+1\n",
    "        \n",
    "        if patience == 0:\n",
    "            print(\"early stop...\")\n",
    "            print(\"========== Saving best model with mean_percentiles: {:.2f} ==========\".format(best_mean_percentiles))\n",
    "            break\n",
    "    \n",
    "    return model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 135,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2020-02-22 22:30:25,178 : INFO : collecting all words and their counts\n",
      "2020-02-22 22:30:25,179 : INFO : PROGRESS: at example #0, processed 0 words (0/s), 0 word types, 0 tags\n",
      "2020-02-22 22:30:25,885 : INFO : collected 54008 word types and 7932 unique tags from a corpus of 7932 examples and 4866436 words\n",
      "2020-02-22 22:30:25,886 : INFO : Loading a fresh vocabulary\n",
      "2020-02-22 22:30:26,042 : INFO : effective_min_count=5 retains 15409 unique words (28% of original 54008, drops 38599)\n",
      "2020-02-22 22:30:26,043 : INFO : effective_min_count=5 leaves 4811064 word corpus (98% of original 4866436, drops 55372)\n",
      "2020-02-22 22:30:26,084 : INFO : deleting the raw counts dictionary of 54008 items\n",
      "2020-02-22 22:30:26,085 : INFO : sample=0.001 downsamples 51 most-common words\n",
      "2020-02-22 22:30:26,086 : INFO : downsampling leaves estimated 4105293 word corpus (85.3% of prior 4811064)\n",
      "2020-02-22 22:30:26,134 : INFO : estimated required memory for 15409 words and 300 dimensions: 54204500 bytes\n",
      "2020-02-22 22:30:26,135 : INFO : resetting layer weights\n",
      "2020-02-22 22:30:30,113 : INFO : training model with 5 workers on 15409 vocabulary and 300 features, using sg=0 hs=0 sample=0.001 negative=5 window=2\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "training epoch 0 ...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2020-02-22 22:30:31,134 : INFO : EPOCH 1 - PROGRESS: at 18.23% examples, 730934 words/s, in_qsize 10, out_qsize 0\n",
      "2020-02-22 22:30:32,136 : INFO : EPOCH 1 - PROGRESS: at 48.74% examples, 993015 words/s, in_qsize 10, out_qsize 0\n",
      "2020-02-22 22:30:33,139 : INFO : EPOCH 1 - PROGRESS: at 78.64% examples, 1070627 words/s, in_qsize 9, out_qsize 0\n",
      "2020-02-22 22:30:34,142 : INFO : EPOCH 1 - PROGRESS: at 95.57% examples, 978026 words/s, in_qsize 10, out_qsize 0\n",
      "2020-02-22 22:30:34,328 : INFO : worker thread finished; awaiting finish of 4 more threads\n",
      "2020-02-22 22:30:34,335 : INFO : worker thread finished; awaiting finish of 3 more threads\n",
      "2020-02-22 22:30:34,338 : INFO : worker thread finished; awaiting finish of 2 more threads\n",
      "2020-02-22 22:30:34,340 : INFO : worker thread finished; awaiting finish of 1 more threads\n",
      "2020-02-22 22:30:34,343 : INFO : worker thread finished; awaiting finish of 0 more threads\n",
      "2020-02-22 22:30:34,344 : INFO : EPOCH - 1 : training on 4866436 raw words (4112247 effective words) took 4.2s, 972951 effective words/s\n",
      "2020-02-22 22:30:34,344 : INFO : training on a 4866436 raw words (4112247 effective words) took 4.2s, 972046 effective words/s\n",
      "2020-02-22 22:30:34,347 : INFO : precomputing L2-norms of doc weight vectors\n",
      "2020-02-22 22:30:34,384 : INFO : saving Doc2Vec object under model/alodokter-articles-doc2vec.model, separately None\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "found similar document with id 5299 in position 0 with similarity score 0.7587615847587585\n",
      "found similar document with id 2364 in position 0 with similarity score 0.6658836603164673\n",
      "found similar document with id 1721 in position 0 with similarity score 0.7171398401260376\n",
      "found similar document with id 998 in position 2 with similarity score 0.6046286821365356\n",
      "found similar document with id 3040 in position 0 with similarity score 0.5846401453018188\n",
      "found similar document with id 4962 in position 0 with similarity score 0.7138915061950684\n",
      "found similar document with id 3248 in position 0 with similarity score 0.607184648513794\n",
      "found similar document with id 4415 in position 0 with similarity score 0.7327130436897278\n",
      "found similar document with id 3125 in position 0 with similarity score 0.6402595043182373\n",
      "mean percentiles: 88.00\n",
      "========== Saving best model with mean_percentiles: 88.00 ==========\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2020-02-22 22:30:34,888 : INFO : saved model/alodokter-articles-doc2vec.model\n",
      "2020-02-22 22:30:34,888 : WARNING : Effective 'alpha' higher than previous training cycles\n",
      "2020-02-22 22:30:34,889 : INFO : training model with 5 workers on 15409 vocabulary and 300 features, using sg=0 hs=0 sample=0.001 negative=5 window=2\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "training epoch 1 ...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2020-02-22 22:30:35,894 : INFO : EPOCH 1 - PROGRESS: at 25.62% examples, 1043574 words/s, in_qsize 10, out_qsize 0\n",
      "2020-02-22 22:30:36,900 : INFO : EPOCH 1 - PROGRESS: at 52.76% examples, 1083348 words/s, in_qsize 10, out_qsize 0\n",
      "2020-02-22 22:30:37,901 : INFO : EPOCH 1 - PROGRESS: at 79.22% examples, 1083757 words/s, in_qsize 9, out_qsize 0\n",
      "2020-02-22 22:30:38,601 : INFO : worker thread finished; awaiting finish of 4 more threads\n",
      "2020-02-22 22:30:38,605 : INFO : worker thread finished; awaiting finish of 3 more threads\n",
      "2020-02-22 22:30:38,606 : INFO : worker thread finished; awaiting finish of 2 more threads\n",
      "2020-02-22 22:30:38,611 : INFO : worker thread finished; awaiting finish of 1 more threads\n",
      "2020-02-22 22:30:38,614 : INFO : worker thread finished; awaiting finish of 0 more threads\n",
      "2020-02-22 22:30:38,614 : INFO : EPOCH - 1 : training on 4866436 raw words (4113669 effective words) took 3.7s, 1105142 effective words/s\n",
      "2020-02-22 22:30:38,615 : INFO : training on a 4866436 raw words (4113669 effective words) took 3.7s, 1104197 effective words/s\n",
      "2020-02-22 22:30:38,662 : INFO : saving Doc2Vec object under model/alodokter-articles-doc2vec.model, separately None\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "found similar document with id 7786 in position 0 with similarity score 0.6994785070419312\n",
      "found similar document with id 6907 in position 0 with similarity score 0.6400388479232788\n",
      "found similar document with id 657 in position 0 with similarity score 0.5217722654342651\n",
      "found similar document with id 4520 in position 0 with similarity score 0.6477442979812622\n",
      "found similar document with id 3507 in position 0 with similarity score 0.5979304909706116\n",
      "found similar document with id 4141 in position 0 with similarity score 0.5762260556221008\n",
      "found similar document with id 4727 in position 0 with similarity score 0.6891166567802429\n",
      "found similar document with id 1610 in position 0 with similarity score 0.5776258707046509\n",
      "found similar document with id 6647 in position 0 with similarity score 0.6328952312469482\n",
      "found similar document with id 2749 in position 0 with similarity score 0.584449291229248\n",
      "mean percentiles: 100.00\n",
      "========== Saving best model with mean_percentiles: 100.00 ==========\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2020-02-22 22:30:39,091 : INFO : saved model/alodokter-articles-doc2vec.model\n",
      "2020-02-22 22:30:39,092 : WARNING : Effective 'alpha' higher than previous training cycles\n",
      "2020-02-22 22:30:39,092 : INFO : training model with 5 workers on 15409 vocabulary and 300 features, using sg=0 hs=0 sample=0.001 negative=5 window=2\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "training epoch 2 ...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2020-02-22 22:30:40,100 : INFO : EPOCH 1 - PROGRESS: at 18.62% examples, 756298 words/s, in_qsize 9, out_qsize 0\n",
      "2020-02-22 22:30:41,111 : INFO : EPOCH 1 - PROGRESS: at 45.92% examples, 938576 words/s, in_qsize 9, out_qsize 0\n",
      "2020-02-22 22:30:42,120 : INFO : EPOCH 1 - PROGRESS: at 75.26% examples, 1023762 words/s, in_qsize 9, out_qsize 0\n",
      "2020-02-22 22:30:42,906 : INFO : worker thread finished; awaiting finish of 4 more threads\n",
      "2020-02-22 22:30:42,911 : INFO : worker thread finished; awaiting finish of 3 more threads\n",
      "2020-02-22 22:30:42,915 : INFO : worker thread finished; awaiting finish of 2 more threads\n",
      "2020-02-22 22:30:42,918 : INFO : worker thread finished; awaiting finish of 1 more threads\n",
      "2020-02-22 22:30:42,923 : INFO : worker thread finished; awaiting finish of 0 more threads\n",
      "2020-02-22 22:30:42,924 : INFO : EPOCH - 1 : training on 4866436 raw words (4113325 effective words) took 3.8s, 1074630 effective words/s\n",
      "2020-02-22 22:30:42,924 : INFO : training on a 4866436 raw words (4113325 effective words) took 3.8s, 1073448 effective words/s\n",
      "2020-02-22 22:30:42,960 : WARNING : Effective 'alpha' higher than previous training cycles\n",
      "2020-02-22 22:30:42,961 : INFO : training model with 5 workers on 15409 vocabulary and 300 features, using sg=0 hs=0 sample=0.001 negative=5 window=2\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "found similar document with id 7427 in position 0 with similarity score 0.5726195573806763\n",
      "found similar document with id 4845 in position 0 with similarity score 0.6867046356201172\n",
      "found similar document with id 1296 in position 0 with similarity score 0.6159794926643372\n",
      "found similar document with id 4833 in position 0 with similarity score 0.6139371395111084\n",
      "found similar document with id 1253 in position 6 with similarity score 0.4956313669681549\n",
      "found similar document with id 3999 in position 0 with similarity score 0.5518233776092529\n",
      "found similar document with id 2582 in position 2 with similarity score 0.4904721975326538\n",
      "found similar document with id 2419 in position 0 with similarity score 0.6069518327713013\n",
      "mean percentiles: 72.00\n",
      "current mean_percentiles: 72.00, best: 100.00\n",
      "training epoch 3 ...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2020-02-22 22:30:43,973 : INFO : EPOCH 1 - PROGRESS: at 26.01% examples, 1056570 words/s, in_qsize 9, out_qsize 0\n",
      "2020-02-22 22:30:44,982 : INFO : EPOCH 1 - PROGRESS: at 53.59% examples, 1095970 words/s, in_qsize 10, out_qsize 0\n",
      "2020-02-22 22:30:45,992 : INFO : EPOCH 1 - PROGRESS: at 84.34% examples, 1147609 words/s, in_qsize 10, out_qsize 0\n",
      "2020-02-22 22:30:46,504 : INFO : worker thread finished; awaiting finish of 4 more threads\n",
      "2020-02-22 22:30:46,506 : INFO : worker thread finished; awaiting finish of 3 more threads\n",
      "2020-02-22 22:30:46,508 : INFO : worker thread finished; awaiting finish of 2 more threads\n",
      "2020-02-22 22:30:46,513 : INFO : worker thread finished; awaiting finish of 1 more threads\n",
      "2020-02-22 22:30:46,516 : INFO : worker thread finished; awaiting finish of 0 more threads\n",
      "2020-02-22 22:30:46,516 : INFO : EPOCH - 1 : training on 4866436 raw words (4113563 effective words) took 3.5s, 1158935 effective words/s\n",
      "2020-02-22 22:30:46,517 : INFO : training on a 4866436 raw words (4113563 effective words) took 3.6s, 1157278 effective words/s\n",
      "2020-02-22 22:30:46,553 : WARNING : Effective 'alpha' higher than previous training cycles\n",
      "2020-02-22 22:30:46,554 : INFO : training model with 5 workers on 15409 vocabulary and 300 features, using sg=0 hs=0 sample=0.001 negative=5 window=2\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "found similar document with id 6760 in position 0 with similarity score 0.5724490284919739\n",
      "found similar document with id 3453 in position 0 with similarity score 0.6574223041534424\n",
      "found similar document with id 3717 in position 0 with similarity score 0.5568020343780518\n",
      "found similar document with id 4058 in position 0 with similarity score 0.6083765029907227\n",
      "found similar document with id 3818 in position 0 with similarity score 0.5052177906036377\n",
      "found similar document with id 1277 in position 1 with similarity score 0.605597198009491\n",
      "found similar document with id 4629 in position 0 with similarity score 0.6412221789360046\n",
      "found similar document with id 1826 in position 0 with similarity score 0.5820738077163696\n",
      "mean percentiles: 79.00\n",
      "current mean_percentiles: 79.00, best: 100.00\n",
      "training epoch 4 ...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2020-02-22 22:30:47,571 : INFO : EPOCH 1 - PROGRESS: at 29.02% examples, 1179192 words/s, in_qsize 9, out_qsize 0\n",
      "2020-02-22 22:30:48,579 : INFO : EPOCH 1 - PROGRESS: at 58.94% examples, 1201717 words/s, in_qsize 9, out_qsize 0\n",
      "2020-02-22 22:30:49,581 : INFO : EPOCH 1 - PROGRESS: at 88.05% examples, 1200258 words/s, in_qsize 9, out_qsize 0\n",
      "2020-02-22 22:30:49,968 : INFO : worker thread finished; awaiting finish of 4 more threads\n",
      "2020-02-22 22:30:49,970 : INFO : worker thread finished; awaiting finish of 3 more threads\n",
      "2020-02-22 22:30:49,971 : INFO : worker thread finished; awaiting finish of 2 more threads\n",
      "2020-02-22 22:30:49,974 : INFO : worker thread finished; awaiting finish of 1 more threads\n",
      "2020-02-22 22:30:49,975 : INFO : worker thread finished; awaiting finish of 0 more threads\n",
      "2020-02-22 22:30:49,975 : INFO : EPOCH - 1 : training on 4866436 raw words (4113122 effective words) took 3.4s, 1204145 effective words/s\n",
      "2020-02-22 22:30:49,976 : INFO : training on a 4866436 raw words (4113122 effective words) took 3.4s, 1202321 effective words/s\n",
      "2020-02-22 22:30:50,008 : WARNING : Effective 'alpha' higher than previous training cycles\n",
      "2020-02-22 22:30:50,008 : INFO : training model with 5 workers on 15409 vocabulary and 300 features, using sg=0 hs=0 sample=0.001 negative=5 window=2\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "found similar document with id 2410 in position 0 with similarity score 0.5771746635437012\n",
      "found similar document with id 1239 in position 0 with similarity score 0.43497687578201294\n",
      "found similar document with id 6359 in position 0 with similarity score 0.58217453956604\n",
      "found similar document with id 762 in position 3 with similarity score 0.4244115948677063\n",
      "found similar document with id 5770 in position 0 with similarity score 0.6495475769042969\n",
      "found similar document with id 1742 in position 0 with similarity score 0.6210180521011353\n",
      "found similar document with id 924 in position 1 with similarity score 0.4558679461479187\n",
      "found similar document with id 2059 in position 0 with similarity score 0.599189281463623\n",
      "found similar document with id 6859 in position 2 with similarity score 0.4884864389896393\n",
      "found similar document with id 6311 in position 0 with similarity score 0.6011608242988586\n",
      "mean percentiles: 94.00\n",
      "current mean_percentiles: 94.00, best: 100.00\n",
      "training epoch 5 ...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2020-02-22 22:30:51,028 : INFO : EPOCH 1 - PROGRESS: at 27.61% examples, 1110314 words/s, in_qsize 9, out_qsize 0\n",
      "2020-02-22 22:30:52,032 : INFO : EPOCH 1 - PROGRESS: at 55.86% examples, 1141542 words/s, in_qsize 9, out_qsize 0\n",
      "2020-02-22 22:30:53,041 : INFO : EPOCH 1 - PROGRESS: at 84.19% examples, 1143734 words/s, in_qsize 9, out_qsize 0\n",
      "2020-02-22 22:30:53,588 : INFO : worker thread finished; awaiting finish of 4 more threads\n",
      "2020-02-22 22:30:53,593 : INFO : worker thread finished; awaiting finish of 3 more threads\n",
      "2020-02-22 22:30:53,600 : INFO : worker thread finished; awaiting finish of 2 more threads\n",
      "2020-02-22 22:30:53,601 : INFO : worker thread finished; awaiting finish of 1 more threads\n",
      "2020-02-22 22:30:53,604 : INFO : worker thread finished; awaiting finish of 0 more threads\n",
      "2020-02-22 22:30:53,605 : INFO : EPOCH - 1 : training on 4866436 raw words (4112854 effective words) took 3.6s, 1144930 effective words/s\n",
      "2020-02-22 22:30:53,606 : INFO : training on a 4866436 raw words (4112854 effective words) took 3.6s, 1143546 effective words/s\n",
      "2020-02-22 22:30:53,640 : WARNING : Effective 'alpha' higher than previous training cycles\n",
      "2020-02-22 22:30:53,641 : INFO : training model with 5 workers on 15409 vocabulary and 300 features, using sg=0 hs=0 sample=0.001 negative=5 window=2\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "found similar document with id 5843 in position 0 with similarity score 0.5966777801513672\n",
      "found similar document with id 3121 in position 1 with similarity score 0.595870852470398\n",
      "found similar document with id 2542 in position 0 with similarity score 0.5717759728431702\n",
      "found similar document with id 7703 in position 0 with similarity score 0.5209951996803284\n",
      "found similar document with id 4261 in position 0 with similarity score 0.6220839023590088\n",
      "found similar document with id 6729 in position 1 with similarity score 0.5184998512268066\n",
      "found similar document with id 7777 in position 0 with similarity score 0.659661054611206\n",
      "found similar document with id 2651 in position 0 with similarity score 0.6376208066940308\n",
      "found similar document with id 3554 in position 0 with similarity score 0.5351495146751404\n",
      "found similar document with id 2133 in position 0 with similarity score 0.6039854288101196\n",
      "mean percentiles: 98.00\n",
      "current mean_percentiles: 98.00, best: 100.00\n",
      "training epoch 6 ...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2020-02-22 22:30:54,647 : INFO : EPOCH 1 - PROGRESS: at 25.82% examples, 1052883 words/s, in_qsize 9, out_qsize 0\n",
      "2020-02-22 22:30:55,661 : INFO : EPOCH 1 - PROGRESS: at 53.78% examples, 1100056 words/s, in_qsize 10, out_qsize 0\n",
      "2020-02-22 22:30:56,662 : INFO : EPOCH 1 - PROGRESS: at 80.50% examples, 1097166 words/s, in_qsize 10, out_qsize 0\n",
      "2020-02-22 22:30:57,378 : INFO : worker thread finished; awaiting finish of 4 more threads\n",
      "2020-02-22 22:30:57,382 : INFO : worker thread finished; awaiting finish of 3 more threads\n",
      "2020-02-22 22:30:57,386 : INFO : worker thread finished; awaiting finish of 2 more threads\n",
      "2020-02-22 22:30:57,389 : INFO : worker thread finished; awaiting finish of 1 more threads\n",
      "2020-02-22 22:30:57,393 : INFO : worker thread finished; awaiting finish of 0 more threads\n",
      "2020-02-22 22:30:57,394 : INFO : EPOCH - 1 : training on 4866436 raw words (4113017 effective words) took 3.7s, 1097558 effective words/s\n",
      "2020-02-22 22:30:57,394 : INFO : training on a 4866436 raw words (4113017 effective words) took 3.8s, 1096213 effective words/s\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "found similar document with id 1345 in position 0 with similarity score 0.44535577297210693\n",
      "found similar document with id 1906 in position 0 with similarity score 0.5315725803375244\n",
      "found similar document with id 7199 in position 0 with similarity score 0.6234700679779053\n",
      "found similar document with id 991 in position 1 with similarity score 0.44617241621017456\n",
      "found similar document with id 6787 in position 0 with similarity score 0.5314539074897766\n",
      "found similar document with id 3314 in position 0 with similarity score 0.5584055185317993\n",
      "found similar document with id 3920 in position 0 with similarity score 0.5845468044281006\n",
      "found similar document with id 4687 in position 0 with similarity score 0.64349365234375\n",
      "found similar document with id 7504 in position 0 with similarity score 0.5365829467773438\n",
      "found similar document with id 5070 in position 0 with similarity score 0.625667929649353\n",
      "mean percentiles: 99.00\n",
      "current mean_percentiles: 99.00, best: 100.00\n",
      "early stop...\n",
      "========== Saving best model with mean_percentiles: 100.00 ==========\n"
     ]
    }
   ],
   "source": [
    "model = train(documents)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
