{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### source: https://github.com/adventuresinML/adventures-in-ml-code/blob/master/gensim_word2vec.py\n",
    "##### source: https://towardsdatascience.com/word2vec-for-phrases-learning-embeddings-for-more-than-one-word\n",
    "##### source: https://radimrehurek.com/gensim/models/phrases.html\n",
    "##### source: http://kavita-ganesan.com/gensim-word2vec-tutorial-starter-code/\n",
    "##### source: https://towardsdatascience.com/word-embedding-with-word2vec-and-fasttext"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# import sys\n",
    "# !{sys.executable} -m pip install numpy pandas matplotlib sklearn seaborn\n",
    "# !{sys.executable} -m pip install --upgrade gensim"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {},
   "outputs": [],
   "source": [
    "import logging\n",
    "import collections\n",
    "import os\n",
    "import zipfile\n",
    "\n",
    "import numpy as np\n",
    "import gensim\n",
    "import tensorflow as tf\n",
    "\n",
    "from gensim.models import FastText\n",
    "from gensim.models.phrases import Phrases, Phraser\n",
    "\n",
    "def build_phrases(sentences, model_name='phrases.model'):\n",
    "    phrases = Phrases(sentences, min_count=5, threshold=7, progress_per=1000)\n",
    "    phrases_model = Phraser(phrases)\n",
    "    phrases_model.save(model_name)\n",
    "    return phrases_model\n",
    "\n",
    "def sentences_to_bigrams(phrases_model, sentences):\n",
    "    bigrams_sentences = []\n",
    "    for sentence in sentences:\n",
    "        phrases_sentence = phrases_model[sentence]\n",
    "        bigrams_sentences.append(phrases_sentence)\n",
    "    return bigrams_sentences\n",
    "\n",
    "def get_data(filename=\"questions.dat\"):\n",
    "    sentences = []\n",
    "    dataset = tf.data.TextLineDataset(filename)\n",
    "    dataset = dataset.enumerate() \n",
    "    for element in dataset.as_numpy_iterator():\n",
    "        text = element[1].decode(\"utf-8\")\n",
    "        sentences.append(text.split(' '))\n",
    "    return sentences"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {},
   "outputs": [],
   "source": [
    "def train(model_name=\"alodokter-word2vec-fasttext.model\"):\n",
    "    sentences = get_data()\n",
    "    logging.basicConfig(format='%(asctime)s : %(levelname)s : %(message)s', level=logging.INFO)\n",
    "    model = FastText(sentences, size=100, window=5, min_count=5, workers=4, sg=1)\n",
    "    model.save(model_name)\n",
    "    return model\n",
    "\n",
    "def train_bigrams(model_name=\"alodokter-word2vec-fasttext-bigram.model\"):\n",
    "    sentences = get_data()\n",
    "    phrases_model = build_phrases(sentences)\n",
    "    sentences = sentences_to_bigrams(phrases_model, sentences)\n",
    "    logging.basicConfig(format='%(asctime)s : %(levelname)s : %(message)s', level=logging.INFO)\n",
    "    model = FastText(sentences, size=100, window=5, min_count=5, workers=4, sg=1)\n",
    "    model.save(model_name)\n",
    "    return model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "training = True\n",
    "if training:\n",
    "    model = train()\n",
    "else:\n",
    "    model = FastText.load(\"alodokter-word2vec-fasttext.model\")\n",
    "model.wv.most_similar(positive=['kemaluan'])\n",
    "\n",
    "# test = 'prostat'\n",
    "# print(test in model.wv.vocab)\n",
    "# model.wv.most_similar(positive=[test])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 67,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2020-02-19 19:01:34,519 : INFO : loading FastText object from alodokter-word2vec-fasttext-bigram.model\n",
      "2020-02-19 19:01:34,842 : INFO : loading wv recursively from alodokter-word2vec-fasttext-bigram.model.wv.* with mmap=None\n",
      "2020-02-19 19:01:34,842 : INFO : loading vectors_ngrams from alodokter-word2vec-fasttext-bigram.model.wv.vectors_ngrams.npy with mmap=None\n",
      "2020-02-19 19:01:35,233 : INFO : setting ignored attribute vectors_norm to None\n",
      "2020-02-19 19:01:35,234 : INFO : setting ignored attribute vectors_vocab_norm to None\n",
      "2020-02-19 19:01:35,234 : INFO : setting ignored attribute vectors_ngrams_norm to None\n",
      "2020-02-19 19:01:35,234 : INFO : setting ignored attribute buckets_word to None\n",
      "2020-02-19 19:01:35,235 : INFO : loading vocabulary recursively from alodokter-word2vec-fasttext-bigram.model.vocabulary.* with mmap=None\n",
      "2020-02-19 19:01:35,235 : INFO : loading trainables recursively from alodokter-word2vec-fasttext-bigram.model.trainables.* with mmap=None\n",
      "2020-02-19 19:01:35,236 : INFO : loading vectors_ngrams_lockf from alodokter-word2vec-fasttext-bigram.model.trainables.vectors_ngrams_lockf.npy with mmap=None\n",
      "2020-02-19 19:01:35,715 : INFO : loaded alodokter-word2vec-fasttext-bigram.model\n",
      "2020-02-19 19:01:35,877 : INFO : precomputing L2-norms of word weight vectors\n",
      "2020-02-19 19:01:35,884 : INFO : precomputing L2-norms of ngram weight vectors\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "is 'babnya ada berlendir' Phrase in Vocabulary? False\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "[('feses_berlendir', 0.9052314758300781),\n",
       " ('hijau_berlendir', 0.9005783796310425),\n",
       " ('berlendir', 0.9004101753234863),\n",
       " ('fesesnya_berlendir', 0.8864094018936157),\n",
       " ('babnya_berlendir', 0.883073091506958),\n",
       " ('pupnya_berlendir', 0.8699895143508911),\n",
       " ('fesesnya_cair', 0.8115257620811462),\n",
       " ('fesesnya_berwarna', 0.8106538653373718),\n",
       " ('warna_fesesnya', 0.8097831010818481),\n",
       " ('fases', 0.8090940713882446)]"
      ]
     },
     "execution_count": 67,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "training = False\n",
    "if training:\n",
    "    model = train_bigrams()\n",
    "else:\n",
    "    model = FastText.load(\"alodokter-word2vec-fasttext-bigram.model\")\n",
    "# model.wv.most_similar(positive=['kemaluan'])\n",
    "\n",
    "phrase = 'babnya ada berlendir'\n",
    "print(\"is '{}' Phrase in Vocabulary? {}\".format(phrase, phrase in model.wv.vocab))\n",
    "model.wv.most_similar(positive=[phrase])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
