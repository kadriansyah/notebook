{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### source: https://github.com/KevinLiao159/MyDataSciencePortfolio/blob/master/movie_recommender/movie_recommendation_using_NeuMF.ipynb"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import zipfile\n",
    "from urllib import request\n",
    "\n",
    "import pprint\n",
    "pp = pprint.PrettyPrinter(indent=2)\n",
    "\n",
    "# data science imports\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "\n",
    "import tensorflow as tf\n",
    "import tensorflow.keras.backend as K\n",
    "\n",
    "# sklearn imports\n",
    "from sklearn.model_selection import train_test_split\n",
    "\n",
    "# keras/tensorflow imports\n",
    "from tensorflow.keras.layers import Input, Embedding, Flatten, Dense, Multiply, Concatenate\n",
    "from tensorflow.keras.regularizers import l2\n",
    "from tensorflow.keras.models import Model\n",
    "\n",
    "# from tensorflow.keras.optimizers import Adagrad, Adam, SGD, RMSprop\n",
    "from tensorflow.keras.callbacks import EarlyStopping, ModelCheckpoint\n",
    "from tensorflow.keras.models import load_model\n",
    "\n",
    "# visualization imports\n",
    "import matplotlib.pyplot as plt\n",
    "%matplotlib inline"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "def download(url, filename):\n",
    "    \"\"\"Download a file if not present\"\"\"\n",
    "    if not os.path.exists(filename):\n",
    "        print(\"downloading {}...\".format(filename))\n",
    "        filename, _ = request.urlretrieve(url + filename, filename)\n",
    "\n",
    "        print(\"extracting {}...\".format(filename))\n",
    "        with zipfile.ZipFile(filename) as f:\n",
    "            f.extractall()\n",
    "            print(\"extracting {} done\".format(filename))\n",
    "\n",
    "    \"\"\"directory data\"\"\"\n",
    "    data_path = filename.replace('.zip','')\n",
    "    if not os.path.exists(data_path):\n",
    "        print(\"extracting {}...\".format(filename))\n",
    "        with zipfile.ZipFile(filename) as f:\n",
    "            f.extractall()\n",
    "            print(\"extracting {} done\".format(filename))\n",
    "\n",
    "    \"\"\"directory model for saving model while training\"\"\"\n",
    "    if not os.path.exists('model'):\n",
    "        os.mkdir('model')\n",
    "        print(\"directory model created...\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "extracting data.zip...\n",
      "extracting data.zip done\n"
     ]
    }
   ],
   "source": [
    "# download dataset\n",
    "download(url='https://github.com/kadriansyah/notebook/raw/master/', filename=\"data.zip\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "def load_books():\n",
    "    df = pd.read_csv('data/book-books.dat', sep=';', header=1, encoding=\"latin-1\")\n",
    "    df.columns = ['isbn', 'title', 'author', 'year_of_publication', 'publisher', 'image_url_s', 'image_url_m', 'image_url_l']\n",
    "    \n",
    "    # insert custom index for word embedding training\n",
    "    df.insert(0, 'bid', range(1, len(df) + 1))\n",
    "    return df[['bid','isbn','title','author','year_of_publication','publisher']]\n",
    "\n",
    "def load_users():\n",
    "    df = pd.read_csv('data/book-users.dat', sep=';', header=1, encoding=\"latin-1\")\n",
    "    df.columns=['user_id', 'location', 'age']\n",
    "    \n",
    "    # insert custom index for word embedding training\n",
    "    df.insert(0, 'uid', range(1, len(df) + 1))\n",
    "    return df[['uid','user_id','location','age']]\n",
    "\n",
    "def load_ratings():\n",
    "    df = pd.read_csv('data/book-ratings.dat', sep=';', header=1, encoding=\"latin-1\")\n",
    "    df.columns=['user_id', 'isbn', 'rating']\n",
    "    return df[['user_id','isbn','rating']]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>bid</th>\n",
       "      <th>isbn</th>\n",
       "      <th>title</th>\n",
       "      <th>author</th>\n",
       "      <th>year_of_publication</th>\n",
       "      <th>publisher</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>1</td>\n",
       "      <td>0002005018</td>\n",
       "      <td>Clara Callan</td>\n",
       "      <td>Richard Bruce Wright</td>\n",
       "      <td>2001</td>\n",
       "      <td>HarperFlamingo Canada</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>2</td>\n",
       "      <td>0060973129</td>\n",
       "      <td>Decision in Normandy</td>\n",
       "      <td>Carlo D'Este</td>\n",
       "      <td>1991</td>\n",
       "      <td>HarperPerennial</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>3</td>\n",
       "      <td>0374157065</td>\n",
       "      <td>Flu: The Story of the Great Influenza Pandemic...</td>\n",
       "      <td>Gina Bari Kolata</td>\n",
       "      <td>1999</td>\n",
       "      <td>Farrar Straus Giroux</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>4</td>\n",
       "      <td>0393045218</td>\n",
       "      <td>The Mummies of Urumchi</td>\n",
       "      <td>E. J. W. Barber</td>\n",
       "      <td>1999</td>\n",
       "      <td>W. W. Norton &amp;amp; Company</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>5</td>\n",
       "      <td>0399135782</td>\n",
       "      <td>The Kitchen God's Wife</td>\n",
       "      <td>Amy Tan</td>\n",
       "      <td>1991</td>\n",
       "      <td>Putnam Pub Group</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>271354</th>\n",
       "      <td>271355</td>\n",
       "      <td>0440400988</td>\n",
       "      <td>There's a Bat in Bunk Five</td>\n",
       "      <td>Paula Danziger</td>\n",
       "      <td>1988</td>\n",
       "      <td>Random House Childrens Pub (Mm)</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>271355</th>\n",
       "      <td>271356</td>\n",
       "      <td>0525447644</td>\n",
       "      <td>From One to One Hundred</td>\n",
       "      <td>Teri Sloat</td>\n",
       "      <td>1991</td>\n",
       "      <td>Dutton Books</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>271356</th>\n",
       "      <td>271357</td>\n",
       "      <td>006008667X</td>\n",
       "      <td>Lily Dale : The True Story of the Town that Ta...</td>\n",
       "      <td>Christine Wicker</td>\n",
       "      <td>2004</td>\n",
       "      <td>HarperSanFrancisco</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>271357</th>\n",
       "      <td>271358</td>\n",
       "      <td>0192126040</td>\n",
       "      <td>Republic (World's Classics)</td>\n",
       "      <td>Plato</td>\n",
       "      <td>1996</td>\n",
       "      <td>Oxford University Press</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>271358</th>\n",
       "      <td>271359</td>\n",
       "      <td>0767409752</td>\n",
       "      <td>A Guided Tour of Rene Descartes' Meditations o...</td>\n",
       "      <td>Christopher  Biffle</td>\n",
       "      <td>2000</td>\n",
       "      <td>McGraw-Hill Humanities/Social Sciences/Languages</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>271359 rows × 6 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "           bid        isbn                                              title  \\\n",
       "0            1  0002005018                                       Clara Callan   \n",
       "1            2  0060973129                               Decision in Normandy   \n",
       "2            3  0374157065  Flu: The Story of the Great Influenza Pandemic...   \n",
       "3            4  0393045218                             The Mummies of Urumchi   \n",
       "4            5  0399135782                             The Kitchen God's Wife   \n",
       "...        ...         ...                                                ...   \n",
       "271354  271355  0440400988                         There's a Bat in Bunk Five   \n",
       "271355  271356  0525447644                            From One to One Hundred   \n",
       "271356  271357  006008667X  Lily Dale : The True Story of the Town that Ta...   \n",
       "271357  271358  0192126040                        Republic (World's Classics)   \n",
       "271358  271359  0767409752  A Guided Tour of Rene Descartes' Meditations o...   \n",
       "\n",
       "                      author year_of_publication  \\\n",
       "0       Richard Bruce Wright                2001   \n",
       "1               Carlo D'Este                1991   \n",
       "2           Gina Bari Kolata                1999   \n",
       "3            E. J. W. Barber                1999   \n",
       "4                    Amy Tan                1991   \n",
       "...                      ...                 ...   \n",
       "271354        Paula Danziger                1988   \n",
       "271355            Teri Sloat                1991   \n",
       "271356      Christine Wicker                2004   \n",
       "271357                 Plato                1996   \n",
       "271358   Christopher  Biffle                2000   \n",
       "\n",
       "                                               publisher  \n",
       "0                                  HarperFlamingo Canada  \n",
       "1                                        HarperPerennial  \n",
       "2                                   Farrar Straus Giroux  \n",
       "3                             W. W. Norton &amp; Company  \n",
       "4                                       Putnam Pub Group  \n",
       "...                                                  ...  \n",
       "271354                   Random House Childrens Pub (Mm)  \n",
       "271355                                      Dutton Books  \n",
       "271356                                HarperSanFrancisco  \n",
       "271357                           Oxford University Press  \n",
       "271358  McGraw-Hill Humanities/Social Sciences/Languages  \n",
       "\n",
       "[271359 rows x 6 columns]"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "books = load_books()\n",
    "books"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>uid</th>\n",
       "      <th>user_id</th>\n",
       "      <th>location</th>\n",
       "      <th>age</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>1</td>\n",
       "      <td>2</td>\n",
       "      <td>stockton, california, usa</td>\n",
       "      <td>18.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>2</td>\n",
       "      <td>3</td>\n",
       "      <td>moscow, yukon territory, russia</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>3</td>\n",
       "      <td>4</td>\n",
       "      <td>porto, v.n.gaia, portugal</td>\n",
       "      <td>17.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>4</td>\n",
       "      <td>5</td>\n",
       "      <td>farnborough, hants, united kingdom</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>5</td>\n",
       "      <td>6</td>\n",
       "      <td>santa monica, california, usa</td>\n",
       "      <td>61.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>278852</th>\n",
       "      <td>278853</td>\n",
       "      <td>278854</td>\n",
       "      <td>portland, oregon, usa</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>278853</th>\n",
       "      <td>278854</td>\n",
       "      <td>278855</td>\n",
       "      <td>tacoma, washington, united kingdom</td>\n",
       "      <td>50.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>278854</th>\n",
       "      <td>278855</td>\n",
       "      <td>278856</td>\n",
       "      <td>brampton, ontario, canada</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>278855</th>\n",
       "      <td>278856</td>\n",
       "      <td>278857</td>\n",
       "      <td>knoxville, tennessee, usa</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>278856</th>\n",
       "      <td>278857</td>\n",
       "      <td>278858</td>\n",
       "      <td>dublin, n/a, ireland</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>278857 rows × 4 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "           uid  user_id                            location   age\n",
       "0            1        2           stockton, california, usa  18.0\n",
       "1            2        3     moscow, yukon territory, russia   NaN\n",
       "2            3        4           porto, v.n.gaia, portugal  17.0\n",
       "3            4        5  farnborough, hants, united kingdom   NaN\n",
       "4            5        6       santa monica, california, usa  61.0\n",
       "...        ...      ...                                 ...   ...\n",
       "278852  278853   278854               portland, oregon, usa   NaN\n",
       "278853  278854   278855  tacoma, washington, united kingdom  50.0\n",
       "278854  278855   278856           brampton, ontario, canada   NaN\n",
       "278855  278856   278857           knoxville, tennessee, usa   NaN\n",
       "278856  278857   278858                dublin, n/a, ireland   NaN\n",
       "\n",
       "[278857 rows x 4 columns]"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "users = load_users()\n",
    "users"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>user_id</th>\n",
       "      <th>isbn</th>\n",
       "      <th>rating</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>276726</td>\n",
       "      <td>0155061224</td>\n",
       "      <td>5</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>276727</td>\n",
       "      <td>0446520802</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>276729</td>\n",
       "      <td>052165615X</td>\n",
       "      <td>3</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>276729</td>\n",
       "      <td>0521795028</td>\n",
       "      <td>6</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>276733</td>\n",
       "      <td>2080674722</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1149774</th>\n",
       "      <td>276704</td>\n",
       "      <td>1563526298</td>\n",
       "      <td>9</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1149775</th>\n",
       "      <td>276706</td>\n",
       "      <td>0679447156</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1149776</th>\n",
       "      <td>276709</td>\n",
       "      <td>0515107662</td>\n",
       "      <td>10</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1149777</th>\n",
       "      <td>276721</td>\n",
       "      <td>0590442449</td>\n",
       "      <td>10</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1149778</th>\n",
       "      <td>276723</td>\n",
       "      <td>05162443314</td>\n",
       "      <td>8</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>1149779 rows × 3 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "         user_id         isbn  rating\n",
       "0         276726   0155061224       5\n",
       "1         276727   0446520802       0\n",
       "2         276729   052165615X       3\n",
       "3         276729   0521795028       6\n",
       "4         276733   2080674722       0\n",
       "...          ...          ...     ...\n",
       "1149774   276704   1563526298       9\n",
       "1149775   276706   0679447156       0\n",
       "1149776   276709   0515107662      10\n",
       "1149777   276721   0590442449      10\n",
       "1149778   276723  05162443314       8\n",
       "\n",
       "[1149779 rows x 3 columns]"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "ratings = load_ratings()\n",
    "ratings"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>user_id</th>\n",
       "      <th>isbn</th>\n",
       "      <th>rating</th>\n",
       "      <th>bid</th>\n",
       "      <th>title</th>\n",
       "      <th>author</th>\n",
       "      <th>year_of_publication</th>\n",
       "      <th>publisher</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>276726</td>\n",
       "      <td>0155061224</td>\n",
       "      <td>5</td>\n",
       "      <td>225816</td>\n",
       "      <td>Rites of Passage</td>\n",
       "      <td>Judith Rae</td>\n",
       "      <td>2001</td>\n",
       "      <td>Heinle</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>276727</td>\n",
       "      <td>0446520802</td>\n",
       "      <td>0</td>\n",
       "      <td>11053</td>\n",
       "      <td>The Notebook</td>\n",
       "      <td>Nicholas Sparks</td>\n",
       "      <td>1996</td>\n",
       "      <td>Warner Books</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>276729</td>\n",
       "      <td>052165615X</td>\n",
       "      <td>3</td>\n",
       "      <td>246838</td>\n",
       "      <td>Help!: Level 1</td>\n",
       "      <td>Philip Prowse</td>\n",
       "      <td>1999</td>\n",
       "      <td>Cambridge University Press</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>276729</td>\n",
       "      <td>0521795028</td>\n",
       "      <td>6</td>\n",
       "      <td>246839</td>\n",
       "      <td>The Amsterdam Connection : Level 4 (Cambridge ...</td>\n",
       "      <td>Sue Leather</td>\n",
       "      <td>2001</td>\n",
       "      <td>Cambridge University Press</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>276733</td>\n",
       "      <td>2080674722</td>\n",
       "      <td>0</td>\n",
       "      <td>123639</td>\n",
       "      <td>Les Particules Elementaires</td>\n",
       "      <td>Michel Houellebecq</td>\n",
       "      <td>1998</td>\n",
       "      <td>Flammarion</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1149773</th>\n",
       "      <td>276704</td>\n",
       "      <td>0876044011</td>\n",
       "      <td>0</td>\n",
       "      <td>69543</td>\n",
       "      <td>Edgar Cayce on the Akashic Records: The Book o...</td>\n",
       "      <td>Kevin J. Todeschi</td>\n",
       "      <td>1998</td>\n",
       "      <td>A.R.E. Press (Association of Research &amp;amp; Enlig</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1149774</th>\n",
       "      <td>276704</td>\n",
       "      <td>1563526298</td>\n",
       "      <td>9</td>\n",
       "      <td>69544</td>\n",
       "      <td>Get Clark Smart : The Ultimate Guide for the S...</td>\n",
       "      <td>Clark Howard</td>\n",
       "      <td>2000</td>\n",
       "      <td>Longstreet Press</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1149775</th>\n",
       "      <td>276706</td>\n",
       "      <td>0679447156</td>\n",
       "      <td>0</td>\n",
       "      <td>52540</td>\n",
       "      <td>Eight Weeks to Optimum Health: A Proven Progra...</td>\n",
       "      <td>Andrew Weil</td>\n",
       "      <td>1997</td>\n",
       "      <td>Alfred A. Knopf</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1149776</th>\n",
       "      <td>276709</td>\n",
       "      <td>0515107662</td>\n",
       "      <td>10</td>\n",
       "      <td>15978</td>\n",
       "      <td>The Sherbrooke Bride (Bride Trilogy (Paperback))</td>\n",
       "      <td>Catherine Coulter</td>\n",
       "      <td>1996</td>\n",
       "      <td>Jove Books</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1149777</th>\n",
       "      <td>276721</td>\n",
       "      <td>0590442449</td>\n",
       "      <td>10</td>\n",
       "      <td>56814</td>\n",
       "      <td>Fourth Grade Rats</td>\n",
       "      <td>Jerry Spinelli</td>\n",
       "      <td>1996</td>\n",
       "      <td>Scholastic</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>1031134 rows × 8 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "         user_id        isbn  rating     bid  \\\n",
       "0         276726  0155061224       5  225816   \n",
       "1         276727  0446520802       0   11053   \n",
       "2         276729  052165615X       3  246838   \n",
       "3         276729  0521795028       6  246839   \n",
       "4         276733  2080674722       0  123639   \n",
       "...          ...         ...     ...     ...   \n",
       "1149773   276704  0876044011       0   69543   \n",
       "1149774   276704  1563526298       9   69544   \n",
       "1149775   276706  0679447156       0   52540   \n",
       "1149776   276709  0515107662      10   15978   \n",
       "1149777   276721  0590442449      10   56814   \n",
       "\n",
       "                                                     title  \\\n",
       "0                                         Rites of Passage   \n",
       "1                                             The Notebook   \n",
       "2                                           Help!: Level 1   \n",
       "3        The Amsterdam Connection : Level 4 (Cambridge ...   \n",
       "4                              Les Particules Elementaires   \n",
       "...                                                    ...   \n",
       "1149773  Edgar Cayce on the Akashic Records: The Book o...   \n",
       "1149774  Get Clark Smart : The Ultimate Guide for the S...   \n",
       "1149775  Eight Weeks to Optimum Health: A Proven Progra...   \n",
       "1149776   The Sherbrooke Bride (Bride Trilogy (Paperback))   \n",
       "1149777                                  Fourth Grade Rats   \n",
       "\n",
       "                     author year_of_publication  \\\n",
       "0                Judith Rae                2001   \n",
       "1           Nicholas Sparks                1996   \n",
       "2             Philip Prowse                1999   \n",
       "3               Sue Leather                2001   \n",
       "4        Michel Houellebecq                1998   \n",
       "...                     ...                 ...   \n",
       "1149773   Kevin J. Todeschi                1998   \n",
       "1149774        Clark Howard                2000   \n",
       "1149775         Andrew Weil                1997   \n",
       "1149776   Catherine Coulter                1996   \n",
       "1149777      Jerry Spinelli                1996   \n",
       "\n",
       "                                                 publisher  \n",
       "0                                                   Heinle  \n",
       "1                                             Warner Books  \n",
       "2                               Cambridge University Press  \n",
       "3                               Cambridge University Press  \n",
       "4                                               Flammarion  \n",
       "...                                                    ...  \n",
       "1149773  A.R.E. Press (Association of Research &amp; Enlig  \n",
       "1149774                                   Longstreet Press  \n",
       "1149775                                    Alfred A. Knopf  \n",
       "1149776                                         Jove Books  \n",
       "1149777                                         Scholastic  \n",
       "\n",
       "[1031134 rows x 8 columns]"
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# do some preprocessing to make sure data quality\n",
    "ratings_clean_1 = ratings.merge(books, on='isbn', how='left', indicator=True)\n",
    "ratings_clean_1 = ratings_clean_1[ratings_clean_1._merge != 'left_only']\n",
    "ratings_clean_1 = ratings_clean_1.astype({'bid': 'int32'})\n",
    "ratings_clean_1 = ratings_clean_1.drop(['_merge'], axis=1)\n",
    "ratings_clean_1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>user_id</th>\n",
       "      <th>isbn</th>\n",
       "      <th>rating</th>\n",
       "      <th>bid</th>\n",
       "      <th>title</th>\n",
       "      <th>author</th>\n",
       "      <th>year_of_publication</th>\n",
       "      <th>publisher</th>\n",
       "      <th>uid</th>\n",
       "      <th>location</th>\n",
       "      <th>age</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>276726</td>\n",
       "      <td>0155061224</td>\n",
       "      <td>5</td>\n",
       "      <td>225816</td>\n",
       "      <td>Rites of Passage</td>\n",
       "      <td>Judith Rae</td>\n",
       "      <td>2001</td>\n",
       "      <td>Heinle</td>\n",
       "      <td>276725</td>\n",
       "      <td>seattle, washington, usa</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>276729</td>\n",
       "      <td>052165615X</td>\n",
       "      <td>3</td>\n",
       "      <td>246838</td>\n",
       "      <td>Help!: Level 1</td>\n",
       "      <td>Philip Prowse</td>\n",
       "      <td>1999</td>\n",
       "      <td>Cambridge University Press</td>\n",
       "      <td>276728</td>\n",
       "      <td>rijeka, n/a, croatia</td>\n",
       "      <td>16.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>276729</td>\n",
       "      <td>0521795028</td>\n",
       "      <td>6</td>\n",
       "      <td>246839</td>\n",
       "      <td>The Amsterdam Connection : Level 4 (Cambridge ...</td>\n",
       "      <td>Sue Leather</td>\n",
       "      <td>2001</td>\n",
       "      <td>Cambridge University Press</td>\n",
       "      <td>276728</td>\n",
       "      <td>rijeka, n/a, croatia</td>\n",
       "      <td>16.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>276744</td>\n",
       "      <td>038550120X</td>\n",
       "      <td>7</td>\n",
       "      <td>9294</td>\n",
       "      <td>A Painted House</td>\n",
       "      <td>JOHN GRISHAM</td>\n",
       "      <td>2001</td>\n",
       "      <td>Doubleday</td>\n",
       "      <td>276743</td>\n",
       "      <td>torrance, california, usa</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>12</th>\n",
       "      <td>276747</td>\n",
       "      <td>0060517794</td>\n",
       "      <td>9</td>\n",
       "      <td>4779</td>\n",
       "      <td>Little Altars Everywhere</td>\n",
       "      <td>Rebecca Wells</td>\n",
       "      <td>2003</td>\n",
       "      <td>HarperTorch</td>\n",
       "      <td>276746</td>\n",
       "      <td>iowa city, iowa, usa</td>\n",
       "      <td>25.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1031126</th>\n",
       "      <td>276704</td>\n",
       "      <td>0743211383</td>\n",
       "      <td>7</td>\n",
       "      <td>881</td>\n",
       "      <td>Dreamcatcher</td>\n",
       "      <td>Stephen King</td>\n",
       "      <td>2001</td>\n",
       "      <td>Scribner</td>\n",
       "      <td>276703</td>\n",
       "      <td>cedar park, texas, usa</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1031128</th>\n",
       "      <td>276704</td>\n",
       "      <td>0806917695</td>\n",
       "      <td>5</td>\n",
       "      <td>69541</td>\n",
       "      <td>Perplexing Lateral Thinking Puzzles: Scholasti...</td>\n",
       "      <td>Paul Sloane</td>\n",
       "      <td>1997</td>\n",
       "      <td>Sterling Publishing</td>\n",
       "      <td>276703</td>\n",
       "      <td>cedar park, texas, usa</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1031130</th>\n",
       "      <td>276704</td>\n",
       "      <td>1563526298</td>\n",
       "      <td>9</td>\n",
       "      <td>69544</td>\n",
       "      <td>Get Clark Smart : The Ultimate Guide for the S...</td>\n",
       "      <td>Clark Howard</td>\n",
       "      <td>2000</td>\n",
       "      <td>Longstreet Press</td>\n",
       "      <td>276703</td>\n",
       "      <td>cedar park, texas, usa</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1031132</th>\n",
       "      <td>276709</td>\n",
       "      <td>0515107662</td>\n",
       "      <td>10</td>\n",
       "      <td>15978</td>\n",
       "      <td>The Sherbrooke Bride (Bride Trilogy (Paperback))</td>\n",
       "      <td>Catherine Coulter</td>\n",
       "      <td>1996</td>\n",
       "      <td>Jove Books</td>\n",
       "      <td>276708</td>\n",
       "      <td>mannington, west virginia, usa</td>\n",
       "      <td>38.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1031133</th>\n",
       "      <td>276721</td>\n",
       "      <td>0590442449</td>\n",
       "      <td>10</td>\n",
       "      <td>56814</td>\n",
       "      <td>Fourth Grade Rats</td>\n",
       "      <td>Jerry Spinelli</td>\n",
       "      <td>1996</td>\n",
       "      <td>Scholastic</td>\n",
       "      <td>276720</td>\n",
       "      <td>providence, rhode island, usa</td>\n",
       "      <td>14.0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>383842 rows × 11 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "         user_id        isbn  rating     bid  \\\n",
       "0         276726  0155061224       5  225816   \n",
       "2         276729  052165615X       3  246838   \n",
       "3         276729  0521795028       6  246839   \n",
       "5         276744  038550120X       7    9294   \n",
       "12        276747  0060517794       9    4779   \n",
       "...          ...         ...     ...     ...   \n",
       "1031126   276704  0743211383       7     881   \n",
       "1031128   276704  0806917695       5   69541   \n",
       "1031130   276704  1563526298       9   69544   \n",
       "1031132   276709  0515107662      10   15978   \n",
       "1031133   276721  0590442449      10   56814   \n",
       "\n",
       "                                                     title             author  \\\n",
       "0                                         Rites of Passage         Judith Rae   \n",
       "2                                           Help!: Level 1      Philip Prowse   \n",
       "3        The Amsterdam Connection : Level 4 (Cambridge ...        Sue Leather   \n",
       "5                                          A Painted House       JOHN GRISHAM   \n",
       "12                                Little Altars Everywhere      Rebecca Wells   \n",
       "...                                                    ...                ...   \n",
       "1031126                                       Dreamcatcher       Stephen King   \n",
       "1031128  Perplexing Lateral Thinking Puzzles: Scholasti...        Paul Sloane   \n",
       "1031130  Get Clark Smart : The Ultimate Guide for the S...       Clark Howard   \n",
       "1031132   The Sherbrooke Bride (Bride Trilogy (Paperback))  Catherine Coulter   \n",
       "1031133                                  Fourth Grade Rats     Jerry Spinelli   \n",
       "\n",
       "        year_of_publication                   publisher     uid  \\\n",
       "0                      2001                      Heinle  276725   \n",
       "2                      1999  Cambridge University Press  276728   \n",
       "3                      2001  Cambridge University Press  276728   \n",
       "5                      2001                   Doubleday  276743   \n",
       "12                     2003                 HarperTorch  276746   \n",
       "...                     ...                         ...     ...   \n",
       "1031126                2001                    Scribner  276703   \n",
       "1031128                1997         Sterling Publishing  276703   \n",
       "1031130                2000            Longstreet Press  276703   \n",
       "1031132                1996                  Jove Books  276708   \n",
       "1031133                1996                  Scholastic  276720   \n",
       "\n",
       "                               location   age  \n",
       "0              seattle, washington, usa   NaN  \n",
       "2                  rijeka, n/a, croatia  16.0  \n",
       "3                  rijeka, n/a, croatia  16.0  \n",
       "5             torrance, california, usa   NaN  \n",
       "12                 iowa city, iowa, usa  25.0  \n",
       "...                                 ...   ...  \n",
       "1031126          cedar park, texas, usa   NaN  \n",
       "1031128          cedar park, texas, usa   NaN  \n",
       "1031130          cedar park, texas, usa   NaN  \n",
       "1031132  mannington, west virginia, usa  38.0  \n",
       "1031133   providence, rhode island, usa  14.0  \n",
       "\n",
       "[383842 rows x 11 columns]"
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# do some preprocessing to make sure data quality\n",
    "ratings_clean_2 = ratings_clean_1.merge(users, on='user_id', how='left', indicator=True)\n",
    "ratings_clean_2 = ratings_clean_2[ratings_clean_2.rating != 0]\n",
    "ratings_clean_2 = ratings_clean_2.drop(['_merge'], axis=1)\n",
    "ratings_clean_2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "There are 68091 unique users and 149836 unique books in this data set\n"
     ]
    }
   ],
   "source": [
    "num_users = len(ratings_clean_2.uid.unique())\n",
    "num_items = len(ratings_clean_2.bid.unique())\n",
    "print('There are {} unique users and {} unique books in this data set'.format(num_users, num_items))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "There are 68091 distinct users in ratings and the max of uid is 278857\n",
      "There are 149836 distinct books in ratings and the max of bid is 271359\n"
     ]
    }
   ],
   "source": [
    "user_max_id = users.uid.max()\n",
    "book_max_id = books.bid.max()\n",
    "print('There are {} distinct users in ratings and the max of uid is {}'.format(num_users, user_max_id))\n",
    "print('There are {} distinct books in ratings and the max of bid is {}'.format(num_items, book_max_id))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### Split Data Into Train/Test"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "shape of training data set:\n",
      "(307073, 11)\n",
      "shape of test data set:\n",
      "(76769, 11)\n"
     ]
    }
   ],
   "source": [
    "train, test = train_test_split(ratings_clean_2, test_size=0.2, shuffle=True, random_state=99)\n",
    "print('shape of training data set:')\n",
    "print(train.shape)\n",
    "print('shape of test data set:')\n",
    "print(test.shape)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### Train Generalized Matrix Factorization and Test Model"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### define GMF model architeture and train routine"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_GMF_model(num_users, num_items, latent_dim, vu_reg, vi_reg):\n",
    "    \"\"\"\n",
    "    Build Generalized Matrix Factorization Model Topology\n",
    "    \n",
    "    Parameters\n",
    "    ----------\n",
    "    num_users: int, total number of users\n",
    "    num_iterms: int, total number of items\n",
    "    latent_dim: int, embedded dimension for user vector and item vector\n",
    "    vu_reg: float, L2 regularization of user embedded layer\n",
    "    vi_reg: float, L2 regularization of item embedded layer\n",
    "\n",
    "    Return\n",
    "    ------\n",
    "    A Keras Model with GMF model architeture\n",
    "    \"\"\"\n",
    "    # Input variables\n",
    "    user_input = Input(shape=(1,), dtype='int32', name='user_input')\n",
    "    item_input = Input(shape=(1,), dtype='int32', name='item_input')\n",
    "\n",
    "    mf_embedding_user = Embedding(\n",
    "        input_dim = num_users + 1,\n",
    "        output_dim = latent_dim,\n",
    "        embeddings_initializer = 'uniform',\n",
    "        name = 'user_embedding',\n",
    "        embeddings_regularizer = l2(vu_reg),\n",
    "        input_length = 1\n",
    "    )\n",
    "    \n",
    "    mf_embedding_item = Embedding(\n",
    "        input_dim = num_items + 1,\n",
    "        output_dim = latent_dim,\n",
    "        embeddings_initializer = 'uniform',\n",
    "        name = 'item_embedding',\n",
    "        embeddings_regularizer = l2(vi_reg),\n",
    "        input_length = 1\n",
    "    ) \n",
    "    \n",
    "    # Crucial to flatten an embedding vector!\n",
    "    user_latent = Flatten()(mf_embedding_user(user_input))\n",
    "    item_latent = Flatten()(mf_embedding_item(item_input))\n",
    "\n",
    "    # Element-wise product of user and item embeddings \n",
    "    predict_vector = Multiply()([user_latent, item_latent])\n",
    "    \n",
    "    # Final prediction layer\n",
    "    prediction = Dense(1, kernel_initializer='glorot_uniform', name='prediction')(predict_vector)\n",
    "    \n",
    "    # Stitch input and output\n",
    "    model = Model([user_input, item_input], prediction)\n",
    "    \n",
    "    return model\n",
    "\n",
    "def train_model(model, learner, batch_size, epochs, val_split, inputs, outputs, filepath):\n",
    "    \"\"\"\n",
    "    define training routine, train models and save best model\n",
    "    \n",
    "    Parameters\n",
    "    ----------\n",
    "    model: a Keras model\n",
    "    learner: str, one of ['sgd', 'adam', 'rmsprop', 'adagrad']\n",
    "    batch_size: num samples per update\n",
    "    epochs: num iterations\n",
    "    val_split: split ratio for validation data\n",
    "    inputs: inputs data\n",
    "    outputs: outputs data\n",
    "    \"\"\"\n",
    "    # add customized metric\n",
    "    def rmse(y_true, y_pred):\n",
    "        return K.sqrt(K.mean(K.square(y_true - y_pred)))\n",
    "    \n",
    "    # compile model\n",
    "    model.compile(optimizer=learner, loss='mean_squared_error', metrics=['mean_squared_error', rmse])\n",
    "    \n",
    "    # add call backs\n",
    "    early_stopper = EarlyStopping(monitor='val_rmse', patience=10, verbose=1)\n",
    "    model_saver = ModelCheckpoint(filepath=filepath, monitor='val_rmse', save_best_only=True, save_weights_only=True)\n",
    "    \n",
    "    # train model\n",
    "    history = model.fit(inputs, outputs, batch_size=batch_size, epochs=epochs, validation_split=val_split, callbacks=[early_stopper, model_saver])\n",
    "    \n",
    "    return history\n",
    "\n",
    "def load_trained_model(model, weights_path):\n",
    "    model.load_weights(weights_path)\n",
    "    return model"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### create GMF model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"model\"\n",
      "__________________________________________________________________________________________________\n",
      "Layer (type)                    Output Shape         Param #     Connected to                     \n",
      "==================================================================================================\n",
      "user_input (InputLayer)         [(None, 1)]          0                                            \n",
      "__________________________________________________________________________________________________\n",
      "item_input (InputLayer)         [(None, 1)]          0                                            \n",
      "__________________________________________________________________________________________________\n",
      "user_embedding (Embedding)      (None, 1, 10)        2788580     user_input[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "item_embedding (Embedding)      (None, 1, 10)        2713600     item_input[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "flatten (Flatten)               (None, 10)           0           user_embedding[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "flatten_1 (Flatten)             (None, 10)           0           item_embedding[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "multiply (Multiply)             (None, 10)           0           flatten[0][0]                    \n",
      "                                                                 flatten_1[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "prediction (Dense)              (None, 1)            11          multiply[0][0]                   \n",
      "==================================================================================================\n",
      "Total params: 5,502,191\n",
      "Trainable params: 5,502,191\n",
      "Non-trainable params: 0\n",
      "__________________________________________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "GMF_model = get_GMF_model(user_max_id, book_max_id, 10, 0, 0)\n",
    "GMF_model.summary()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### train GMF model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train on 230304 samples, validate on 76769 samples\n",
      "Epoch 1/10000\n",
      "230304/230304 [==============================] - 3s 12us/sample - loss: 30.6278 - mean_squared_error: 30.6278 - rmse: 5.3276 - val_loss: 9.5389 - val_mean_squared_error: 9.5389 - val_rmse: 3.0885\n",
      "Epoch 2/10000\n",
      "230304/230304 [==============================] - 2s 10us/sample - loss: 3.7679 - mean_squared_error: 3.7679 - rmse: 1.9307 - val_loss: 5.0499 - val_mean_squared_error: 5.0499 - val_rmse: 2.2472\n",
      "Epoch 3/10000\n",
      "230304/230304 [==============================] - 2s 10us/sample - loss: 1.1799 - mean_squared_error: 1.1799 - rmse: 1.0865 - val_loss: 4.7759 - val_mean_squared_error: 4.7759 - val_rmse: 2.1854\n",
      "Epoch 4/10000\n",
      "230304/230304 [==============================] - 2s 10us/sample - loss: 0.6799 - mean_squared_error: 0.6799 - rmse: 0.8238 - val_loss: 4.6161 - val_mean_squared_error: 4.6161 - val_rmse: 2.1484\n",
      "Epoch 5/10000\n",
      "230304/230304 [==============================] - 2s 10us/sample - loss: 0.4505 - mean_squared_error: 0.4505 - rmse: 0.6718 - val_loss: 4.7202 - val_mean_squared_error: 4.7202 - val_rmse: 2.1726\n",
      "Epoch 6/10000\n",
      "230304/230304 [==============================] - 2s 10us/sample - loss: 0.3443 - mean_squared_error: 0.3443 - rmse: 0.5868 - val_loss: 4.6535 - val_mean_squared_error: 4.6535 - val_rmse: 2.1571\n",
      "Epoch 7/10000\n",
      "230304/230304 [==============================] - 2s 10us/sample - loss: 0.2978 - mean_squared_error: 0.2978 - rmse: 0.5457 - val_loss: 4.7341 - val_mean_squared_error: 4.7341 - val_rmse: 2.1757\n",
      "Epoch 8/10000\n",
      "230304/230304 [==============================] - 2s 10us/sample - loss: 0.2706 - mean_squared_error: 0.2706 - rmse: 0.5196 - val_loss: 4.6067 - val_mean_squared_error: 4.6067 - val_rmse: 2.1462\n",
      "Epoch 9/10000\n",
      "230304/230304 [==============================] - 2s 10us/sample - loss: 0.2487 - mean_squared_error: 0.2487 - rmse: 0.4982 - val_loss: 4.6143 - val_mean_squared_error: 4.6143 - val_rmse: 2.1480\n",
      "Epoch 10/10000\n",
      "230304/230304 [==============================] - 2s 10us/sample - loss: 0.2250 - mean_squared_error: 0.2250 - rmse: 0.4745 - val_loss: 4.5311 - val_mean_squared_error: 4.5311 - val_rmse: 2.1285\n",
      "Epoch 11/10000\n",
      "230304/230304 [==============================] - 2s 10us/sample - loss: 0.2047 - mean_squared_error: 0.2047 - rmse: 0.4520 - val_loss: 4.5521 - val_mean_squared_error: 4.5521 - val_rmse: 2.1334\n",
      "Epoch 12/10000\n",
      "230304/230304 [==============================] - 2s 10us/sample - loss: 0.1920 - mean_squared_error: 0.1920 - rmse: 0.4376 - val_loss: 4.4740 - val_mean_squared_error: 4.4740 - val_rmse: 2.1150\n",
      "Epoch 13/10000\n",
      "230304/230304 [==============================] - 2s 10us/sample - loss: 0.1852 - mean_squared_error: 0.1852 - rmse: 0.4303 - val_loss: 4.5526 - val_mean_squared_error: 4.5526 - val_rmse: 2.1335\n",
      "Epoch 14/10000\n",
      "230304/230304 [==============================] - 2s 10us/sample - loss: 0.1729 - mean_squared_error: 0.1729 - rmse: 0.4157 - val_loss: 4.5011 - val_mean_squared_error: 4.5011 - val_rmse: 2.1214\n",
      "Epoch 15/10000\n",
      "230304/230304 [==============================] - 2s 10us/sample - loss: 0.1616 - mean_squared_error: 0.1616 - rmse: 0.4018 - val_loss: 4.4687 - val_mean_squared_error: 4.4687 - val_rmse: 2.1137\n",
      "Epoch 16/10000\n",
      "230304/230304 [==============================] - 2s 11us/sample - loss: 0.1508 - mean_squared_error: 0.1508 - rmse: 0.3886 - val_loss: 4.4121 - val_mean_squared_error: 4.4121 - val_rmse: 2.1003\n",
      "Epoch 17/10000\n",
      "230304/230304 [==============================] - 2s 10us/sample - loss: 0.1446 - mean_squared_error: 0.1446 - rmse: 0.3799 - val_loss: 4.3821 - val_mean_squared_error: 4.3821 - val_rmse: 2.0931\n",
      "Epoch 18/10000\n",
      "230304/230304 [==============================] - 2s 10us/sample - loss: 0.1384 - mean_squared_error: 0.1384 - rmse: 0.3719 - val_loss: 4.3981 - val_mean_squared_error: 4.3981 - val_rmse: 2.0970\n",
      "Epoch 19/10000\n",
      "230304/230304 [==============================] - 3s 11us/sample - loss: 0.1280 - mean_squared_error: 0.1280 - rmse: 0.3577 - val_loss: 4.2590 - val_mean_squared_error: 4.2590 - val_rmse: 2.0635\n",
      "Epoch 20/10000\n",
      "230304/230304 [==============================] - 2s 10us/sample - loss: 0.1284 - mean_squared_error: 0.1284 - rmse: 0.3582 - val_loss: 4.4112 - val_mean_squared_error: 4.4112 - val_rmse: 2.1000\n",
      "Epoch 21/10000\n",
      "230304/230304 [==============================] - 2s 10us/sample - loss: 0.1319 - mean_squared_error: 0.1319 - rmse: 0.3629 - val_loss: 4.3786 - val_mean_squared_error: 4.3786 - val_rmse: 2.0923\n",
      "Epoch 22/10000\n",
      "230304/230304 [==============================] - 2s 10us/sample - loss: 0.1259 - mean_squared_error: 0.1259 - rmse: 0.3555 - val_loss: 4.3109 - val_mean_squared_error: 4.3109 - val_rmse: 2.0760\n",
      "Epoch 23/10000\n",
      "230304/230304 [==============================] - 2s 10us/sample - loss: 0.1162 - mean_squared_error: 0.1162 - rmse: 0.3407 - val_loss: 4.3223 - val_mean_squared_error: 4.3223 - val_rmse: 2.0788\n",
      "Epoch 24/10000\n",
      "230304/230304 [==============================] - 2s 10us/sample - loss: 0.1060 - mean_squared_error: 0.1060 - rmse: 0.3255 - val_loss: 4.2944 - val_mean_squared_error: 4.2944 - val_rmse: 2.0721\n",
      "Epoch 25/10000\n",
      "230304/230304 [==============================] - 2s 10us/sample - loss: 0.1050 - mean_squared_error: 0.1050 - rmse: 0.3242 - val_loss: 4.3850 - val_mean_squared_error: 4.3850 - val_rmse: 2.0938\n",
      "Epoch 26/10000\n",
      "230304/230304 [==============================] - 2s 10us/sample - loss: 0.1139 - mean_squared_error: 0.1139 - rmse: 0.3370 - val_loss: 4.3117 - val_mean_squared_error: 4.3117 - val_rmse: 2.0762\n",
      "Epoch 27/10000\n",
      "230304/230304 [==============================] - 2s 10us/sample - loss: 0.1180 - mean_squared_error: 0.1180 - rmse: 0.3428 - val_loss: 4.3077 - val_mean_squared_error: 4.3077 - val_rmse: 2.0752\n",
      "Epoch 28/10000\n",
      "230304/230304 [==============================] - 2s 10us/sample - loss: 0.1130 - mean_squared_error: 0.1130 - rmse: 0.3359 - val_loss: 4.3357 - val_mean_squared_error: 4.3357 - val_rmse: 2.0820\n",
      "Epoch 29/10000\n",
      "230304/230304 [==============================] - 2s 11us/sample - loss: 0.1200 - mean_squared_error: 0.1200 - rmse: 0.3456 - val_loss: 4.2506 - val_mean_squared_error: 4.2506 - val_rmse: 2.0615\n",
      "Epoch 30/10000\n",
      "230304/230304 [==============================] - 2s 11us/sample - loss: 0.1227 - mean_squared_error: 0.1227 - rmse: 0.3504 - val_loss: 4.2472 - val_mean_squared_error: 4.2472 - val_rmse: 2.0607\n",
      "Epoch 31/10000\n",
      "230304/230304 [==============================] - 3s 11us/sample - loss: 0.1131 - mean_squared_error: 0.1131 - rmse: 0.3359 - val_loss: 4.3412 - val_mean_squared_error: 4.3412 - val_rmse: 2.0833\n",
      "Epoch 32/10000\n",
      "230304/230304 [==============================] - 2s 10us/sample - loss: 0.1077 - mean_squared_error: 0.1077 - rmse: 0.3281 - val_loss: 4.2174 - val_mean_squared_error: 4.2174 - val_rmse: 2.0534\n",
      "Epoch 33/10000\n",
      "230304/230304 [==============================] - 3s 11us/sample - loss: 0.1004 - mean_squared_error: 0.1004 - rmse: 0.3166 - val_loss: 4.2406 - val_mean_squared_error: 4.2406 - val_rmse: 2.0591\n",
      "Epoch 34/10000\n",
      "230304/230304 [==============================] - 2s 10us/sample - loss: 0.0965 - mean_squared_error: 0.0965 - rmse: 0.3102 - val_loss: 4.1996 - val_mean_squared_error: 4.1996 - val_rmse: 2.0491\n",
      "Epoch 35/10000\n",
      "230304/230304 [==============================] - 2s 10us/sample - loss: 0.0912 - mean_squared_error: 0.0912 - rmse: 0.3015 - val_loss: 4.1823 - val_mean_squared_error: 4.1823 - val_rmse: 2.0448\n",
      "Epoch 36/10000\n",
      "230304/230304 [==============================] - 2s 10us/sample - loss: 0.0828 - mean_squared_error: 0.0828 - rmse: 0.2877 - val_loss: 4.2408 - val_mean_squared_error: 4.2408 - val_rmse: 2.0592\n",
      "Epoch 37/10000\n",
      "230304/230304 [==============================] - 2s 9us/sample - loss: 0.0845 - mean_squared_error: 0.0845 - rmse: 0.2904 - val_loss: 4.1753 - val_mean_squared_error: 4.1753 - val_rmse: 2.0431\n",
      "Epoch 38/10000\n",
      "230304/230304 [==============================] - 2s 9us/sample - loss: 0.0942 - mean_squared_error: 0.0942 - rmse: 0.3061 - val_loss: 4.2751 - val_mean_squared_error: 4.2751 - val_rmse: 2.0674\n",
      "Epoch 39/10000\n",
      "230304/230304 [==============================] - 2s 9us/sample - loss: 0.1127 - mean_squared_error: 0.1127 - rmse: 0.3349 - val_loss: 4.2570 - val_mean_squared_error: 4.2570 - val_rmse: 2.0631\n",
      "Epoch 40/10000\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "230304/230304 [==============================] - 3s 12us/sample - loss: 0.1225 - mean_squared_error: 0.1225 - rmse: 0.3495 - val_loss: 4.1905 - val_mean_squared_error: 4.1905 - val_rmse: 2.0469\n",
      "Epoch 41/10000\n",
      "230304/230304 [==============================] - 3s 11us/sample - loss: 0.1106 - mean_squared_error: 0.1106 - rmse: 0.3315 - val_loss: 4.1229 - val_mean_squared_error: 4.1229 - val_rmse: 2.0302\n",
      "Epoch 42/10000\n",
      "230304/230304 [==============================] - 2s 9us/sample - loss: 0.1141 - mean_squared_error: 0.1141 - rmse: 0.3372 - val_loss: 4.1438 - val_mean_squared_error: 4.1438 - val_rmse: 2.0354\n",
      "Epoch 43/10000\n",
      "230304/230304 [==============================] - 2s 9us/sample - loss: 0.1057 - mean_squared_error: 0.1057 - rmse: 0.3243 - val_loss: 4.1755 - val_mean_squared_error: 4.1755 - val_rmse: 2.0431\n",
      "Epoch 44/10000\n",
      "230304/230304 [==============================] - 2s 9us/sample - loss: 0.1018 - mean_squared_error: 0.1018 - rmse: 0.3190 - val_loss: 3.9667 - val_mean_squared_error: 3.9667 - val_rmse: 1.9915\n",
      "Epoch 45/10000\n",
      "230304/230304 [==============================] - 2s 9us/sample - loss: 0.0991 - mean_squared_error: 0.0991 - rmse: 0.3142 - val_loss: 4.2050 - val_mean_squared_error: 4.2050 - val_rmse: 2.0504\n",
      "Epoch 46/10000\n",
      "230304/230304 [==============================] - 2s 9us/sample - loss: 0.0922 - mean_squared_error: 0.0922 - rmse: 0.3034 - val_loss: 4.0268 - val_mean_squared_error: 4.0268 - val_rmse: 2.0065\n",
      "Epoch 47/10000\n",
      "230304/230304 [==============================] - 2s 9us/sample - loss: 0.0856 - mean_squared_error: 0.0856 - rmse: 0.2927 - val_loss: 3.9806 - val_mean_squared_error: 3.9806 - val_rmse: 1.9949\n",
      "Epoch 48/10000\n",
      "230304/230304 [==============================] - 2s 9us/sample - loss: 0.0856 - mean_squared_error: 0.0856 - rmse: 0.2917 - val_loss: 4.0925 - val_mean_squared_error: 4.0925 - val_rmse: 2.0228\n",
      "Epoch 49/10000\n",
      "230304/230304 [==============================] - 2s 9us/sample - loss: 0.0886 - mean_squared_error: 0.0886 - rmse: 0.2973 - val_loss: 4.0586 - val_mean_squared_error: 4.0586 - val_rmse: 2.0144\n",
      "Epoch 50/10000\n",
      "230304/230304 [==============================] - 2s 9us/sample - loss: 0.0913 - mean_squared_error: 0.0913 - rmse: 0.3002 - val_loss: 4.0375 - val_mean_squared_error: 4.0375 - val_rmse: 2.0091\n",
      "Epoch 51/10000\n",
      "230304/230304 [==============================] - 2s 9us/sample - loss: 0.1047 - mean_squared_error: 0.1047 - rmse: 0.3227 - val_loss: 4.1694 - val_mean_squared_error: 4.1694 - val_rmse: 2.0418\n",
      "Epoch 52/10000\n",
      "230304/230304 [==============================] - 2s 9us/sample - loss: 0.1076 - mean_squared_error: 0.1076 - rmse: 0.3267 - val_loss: 3.9913 - val_mean_squared_error: 3.9913 - val_rmse: 1.9976\n",
      "Epoch 53/10000\n",
      "230304/230304 [==============================] - 2s 10us/sample - loss: 0.1061 - mean_squared_error: 0.1061 - rmse: 0.3253 - val_loss: 3.9957 - val_mean_squared_error: 3.9957 - val_rmse: 1.9987\n",
      "Epoch 54/10000\n",
      "230304/230304 [==============================] - 2s 9us/sample - loss: 0.1287 - mean_squared_error: 0.1287 - rmse: 0.3533 - val_loss: 4.0348 - val_mean_squared_error: 4.0348 - val_rmse: 2.0085\n",
      "Epoch 00054: early stopping\n"
     ]
    }
   ],
   "source": [
    "# model config\n",
    "BATCH_SIZE = 4096\n",
    "EPOCHS = 10000\n",
    "VAL_SPLIT = 0.25\n",
    "\n",
    "# train model\n",
    "history = train_model(\n",
    "    GMF_model,\n",
    "    tf.keras.optimizers.Adam(0.1),\n",
    "    BATCH_SIZE,\n",
    "    EPOCHS,\n",
    "    VAL_SPLIT,\n",
    "    inputs=[train.uid.values, train.bid.values],\n",
    "    outputs=train.rating.values,\n",
    "    filepath='model/neural-gmf-weights.hdf5')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [],
   "source": [
    "def plot_learning_curve(history, metric):\n",
    "    \"\"\"\n",
    "    Plot learning curve to compare training error vs. validation error\n",
    "    \"\"\"\n",
    "    # get training error\n",
    "    errors = history.history[metric]\n",
    "    \n",
    "    # get validation error\n",
    "    val_errors = history.history['val_{}'.format(metric)]\n",
    "    \n",
    "    # get epochs\n",
    "    epochs = range(1, len(errors) + 1)\n",
    "\n",
    "    # plot\n",
    "    plt.figure(figsize=(12, 7))\n",
    "    plt.plot(epochs, errors, 'bo', label='training {}'.format(metric))\n",
    "    plt.plot(epochs, val_errors, 'b', label='validation {}'.format(metric))\n",
    "    plt.xlabel('number of epochs')\n",
    "    plt.ylabel(metric)\n",
    "    plt.title('Model Learning Curve')\n",
    "    plt.grid(True)\n",
    "    plt.legend()\n",
    "    plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 864x504 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "plot_learning_curve(history, 'rmse')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### GMF model testing"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [],
   "source": [
    "# define rmse function\n",
    "rmse = lambda true, pred: np.sqrt(np.mean(np.square(np.squeeze(predictions) - np.squeeze(test.rating.values))))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The out-of-sample RMSE of rating predictions is 1.9944\n"
     ]
    }
   ],
   "source": [
    "# load best model\n",
    "GMF_model = get_GMF_model(user_max_id, book_max_id, 10, 0, 0)\n",
    "GMF_model = load_trained_model(GMF_model, 'model/neural-gmf-weights.hdf5')\n",
    "\n",
    "# make prediction using test data\n",
    "predictions = GMF_model.predict([test.uid.values, test.bid.values])\n",
    "\n",
    "# get the RMSE\n",
    "error = rmse(test.rating.values, predictions)\n",
    "print('The out-of-sample RMSE of rating predictions is', round(error, 4))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Train Multi-Layer Perceptron Model and Test Model"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### define MLP model architeture"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_MLP_model(num_users, num_items, layers, reg_layers):\n",
    "    \"\"\"\n",
    "    Build Multi-Layer Perceptron Model Topology\n",
    "    \n",
    "    Parameters\n",
    "    ----------\n",
    "    num_users: int, total number of users\n",
    "    num_iterms: int, total number of items\n",
    "    layers: list of int, each element is the number of hidden units for each layer,\n",
    "        with the exception of first element. First element is the sum of dims of\n",
    "        user latent vector and item latent vector\n",
    "    reg_layers: list of int, each element is the L2 regularization parameter for\n",
    "        each layer in MLP\n",
    "\n",
    "    Return\n",
    "    ------\n",
    "    A Keras Model with MLP model architeture\n",
    "    \"\"\"\n",
    "    assert len(layers) == len(reg_layers)\n",
    "    num_layer = len(layers) # Number of layers in the MLP\n",
    "    \n",
    "    # Input variables\n",
    "    user_input = Input(shape=(1,), dtype='int32', name='user_input')\n",
    "    item_input = Input(shape=(1,), dtype='int32', name='item_input')\n",
    "\n",
    "    mlp_embedding_user = Embedding(\n",
    "        input_dim=num_users + 1,\n",
    "        output_dim=layers[0] // 2,\n",
    "        embeddings_initializer='uniform',\n",
    "        name='user_embedding',\n",
    "        embeddings_regularizer=l2(reg_layers[0]),\n",
    "        input_length=1)\n",
    "    \n",
    "    mlp_embedding_item = Embedding(\n",
    "        input_dim=num_items + 1,\n",
    "        output_dim=layers[0] // 2,\n",
    "        embeddings_initializer='uniform',\n",
    "        name='item_embedding',\n",
    "        embeddings_regularizer=l2(reg_layers[0]),\n",
    "        input_length=1) \n",
    "    \n",
    "    # Crucial to flatten an embedding vector!\n",
    "    user_latent = Flatten()(mlp_embedding_user(user_input))\n",
    "    item_latent = Flatten()(mlp_embedding_item(item_input))\n",
    "\n",
    "    # The 0-th layer is the concatenation of embedding layers\n",
    "    vector = Concatenate(axis=-1)([user_latent, item_latent])\n",
    "\n",
    "    # MLP layers\n",
    "    for idx in range(1, num_layer):\n",
    "        layer = Dense(\n",
    "            units=layers[idx],\n",
    "            activation='relu',\n",
    "            kernel_initializer='glorot_uniform',\n",
    "            kernel_regularizer=l2(reg_layers[idx]),\n",
    "            name = 'layer%d' %idx)\n",
    "        vector = layer(vector)\n",
    "    \n",
    "    # Final prediction layer\n",
    "    prediction = Dense(1, kernel_initializer='glorot_uniform', name='prediction')(vector)\n",
    "    \n",
    "    # Stitch input and output\n",
    "    model = Model([user_input, item_input], prediction)\n",
    "    \n",
    "    return model"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### create MLP model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"model_2\"\n",
      "__________________________________________________________________________________________________\n",
      "Layer (type)                    Output Shape         Param #     Connected to                     \n",
      "==================================================================================================\n",
      "user_input (InputLayer)         [(None, 1)]          0                                            \n",
      "__________________________________________________________________________________________________\n",
      "item_input (InputLayer)         [(None, 1)]          0                                            \n",
      "__________________________________________________________________________________________________\n",
      "user_embedding (Embedding)      (None, 1, 32)        8923456     user_input[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "item_embedding (Embedding)      (None, 1, 32)        8683520     item_input[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "flatten_4 (Flatten)             (None, 32)           0           user_embedding[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "flatten_5 (Flatten)             (None, 32)           0           item_embedding[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "concatenate (Concatenate)       (None, 64)           0           flatten_4[0][0]                  \n",
      "                                                                 flatten_5[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "layer1 (Dense)                  (None, 32)           2080        concatenate[0][0]                \n",
      "__________________________________________________________________________________________________\n",
      "layer2 (Dense)                  (None, 16)           528         layer1[0][0]                     \n",
      "__________________________________________________________________________________________________\n",
      "layer3 (Dense)                  (None, 8)            136         layer2[0][0]                     \n",
      "__________________________________________________________________________________________________\n",
      "prediction (Dense)              (None, 1)            9           layer3[0][0]                     \n",
      "==================================================================================================\n",
      "Total params: 17,609,729\n",
      "Trainable params: 17,609,729\n",
      "Non-trainable params: 0\n",
      "__________________________________________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "MLP_model = get_MLP_model(user_max_id, book_max_id, [64, 32, 16, 8], [0, 0, 0, 0])\n",
    "MLP_model.summary()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### train MLP model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train on 230304 samples, validate on 76769 samples\n",
      "Epoch 1/10000\n",
      "230304/230304 [==============================] - 8s 35us/sample - loss: 6.9507 - mean_squared_error: 6.9507 - rmse: 2.2888 - val_loss: 2.8398 - val_mean_squared_error: 2.8398 - val_rmse: 1.6845\n",
      "Epoch 2/10000\n",
      "230304/230304 [==============================] - 7s 32us/sample - loss: 1.9433 - mean_squared_error: 1.9433 - rmse: 1.3952 - val_loss: 2.9103 - val_mean_squared_error: 2.9103 - val_rmse: 1.7058\n",
      "Epoch 3/10000\n",
      "230304/230304 [==============================] - 8s 33us/sample - loss: 1.2951 - mean_squared_error: 1.2951 - rmse: 1.1388 - val_loss: 2.9997 - val_mean_squared_error: 2.9997 - val_rmse: 1.7318\n",
      "Epoch 4/10000\n",
      "230304/230304 [==============================] - 8s 33us/sample - loss: 0.9867 - mean_squared_error: 0.9867 - rmse: 0.9935 - val_loss: 3.0688 - val_mean_squared_error: 3.0688 - val_rmse: 1.7516\n",
      "Epoch 5/10000\n",
      "230304/230304 [==============================] - 7s 32us/sample - loss: 0.8148 - mean_squared_error: 0.8148 - rmse: 0.9030 - val_loss: 3.0943 - val_mean_squared_error: 3.0943 - val_rmse: 1.7588\n",
      "Epoch 6/10000\n",
      "230304/230304 [==============================] - 9s 38us/sample - loss: 0.7164 - mean_squared_error: 0.7164 - rmse: 0.8461 - val_loss: 3.1474 - val_mean_squared_error: 3.1474 - val_rmse: 1.7738\n",
      "Epoch 7/10000\n",
      "230304/230304 [==============================] - 8s 33us/sample - loss: 0.6429 - mean_squared_error: 0.6429 - rmse: 0.8015 - val_loss: 3.1565 - val_mean_squared_error: 3.1565 - val_rmse: 1.7763\n",
      "Epoch 8/10000\n",
      "230304/230304 [==============================] - 7s 33us/sample - loss: 0.5939 - mean_squared_error: 0.5939 - rmse: 0.7698 - val_loss: 3.3200 - val_mean_squared_error: 3.3200 - val_rmse: 1.8219\n",
      "Epoch 9/10000\n",
      "230304/230304 [==============================] - 8s 33us/sample - loss: 0.5546 - mean_squared_error: 0.5546 - rmse: 0.7444 - val_loss: 3.1655 - val_mean_squared_error: 3.1655 - val_rmse: 1.7789\n",
      "Epoch 10/10000\n",
      "230304/230304 [==============================] - 8s 33us/sample - loss: 0.5284 - mean_squared_error: 0.5284 - rmse: 0.7253 - val_loss: 3.2902 - val_mean_squared_error: 3.2902 - val_rmse: 1.8137\n",
      "Epoch 11/10000\n",
      "230304/230304 [==============================] - 8s 33us/sample - loss: 0.4944 - mean_squared_error: 0.4944 - rmse: 0.7030 - val_loss: 3.2552 - val_mean_squared_error: 3.2552 - val_rmse: 1.8040\n",
      "Epoch 00011: early stopping\n"
     ]
    }
   ],
   "source": [
    "# model config\n",
    "BATCH_SIZE = 4096\n",
    "EPOCHS = 10000\n",
    "VAL_SPLIT = 0.25\n",
    "\n",
    "# train model\n",
    "history = train_model(\n",
    "    MLP_model,\n",
    "    tf.keras.optimizers.Adam(0.1),\n",
    "    BATCH_SIZE,\n",
    "    EPOCHS,\n",
    "    VAL_SPLIT,\n",
    "    inputs=[train.uid.values, train.bid.values],\n",
    "    outputs=train.rating.values,\n",
    "    filepath='model/neural-mlp-weights.hdf5')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### MLP learning curve"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 864x504 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "plot_learning_curve(history, 'rmse')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### MLP model testing"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### And finally, make a prediction and check the testing error using out-of-sample data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The out-of-sample RMSE of rating predictions is 1.6834\n"
     ]
    }
   ],
   "source": [
    "# load best model\n",
    "MLP_model = get_MLP_model(user_max_id, book_max_id, [64, 32, 16, 8], [0, 0, 0, 0])\n",
    "MLP_model = load_trained_model(MLP_model, 'model/neural-mlp-weights.hdf5')\n",
    "\n",
    "# make prediction using test data\n",
    "predictions = MLP_model.predict([test.uid.values, test.bid.values])\n",
    "\n",
    "# get the RMSE\n",
    "error = rmse(test.rating.values, predictions)\n",
    "print('The out-of-sample RMSE of rating predictions is', round(error, 4))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Train Neural Matrix Factorization (NeuralMF) and Test Model"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### define NeuralMF model architeture"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_NeuralMF_model(num_users, num_items, MF_dim, MF_reg, MLP_layers, MLP_regs):\n",
    "    \"\"\"\n",
    "    Build Neural Matrix Factorization (NeuralMF) Model Topology.\n",
    "    This is stack version of both GMF and MLP\n",
    "    \n",
    "    Parameters\n",
    "    ----------\n",
    "    num_users: int, total number of users\n",
    "    num_iterms: int, total number of items\n",
    "    MF_dim: int, embedded dimension for user vector and item vector in MF\n",
    "    MF_reg: tuple of float, L2 regularization of MF embedded layer\n",
    "    MLP_layers: list of int, each element is the number of hidden units for each MLP layer,\n",
    "        with the exception of first element. First element is the sum of dims of\n",
    "        user latent vector and item latent vector\n",
    "    MLP_regs: list of int, each element is the L2 regularization parameter for\n",
    "        each layer in MLP\n",
    "\n",
    "    Return\n",
    "    ------\n",
    "    A Keras Model with MLP model architeture\n",
    "    \"\"\"\n",
    "    assert len(MLP_layers) == len(MLP_regs)\n",
    "    num_MLP_layer = len(MLP_layers) # Number of layers in the MLP\n",
    "    \n",
    "    # Input variables\n",
    "    user_input = Input(shape=(1,), dtype='int32', name='user_input')\n",
    "    item_input = Input(shape=(1,), dtype='int32', name='item_input')\n",
    "\n",
    "    # MF Embedding layer\n",
    "    mf_embedding_user = Embedding(\n",
    "        input_dim=num_users + 1,\n",
    "        output_dim=MF_dim,\n",
    "        embeddings_initializer='uniform',\n",
    "        name='mf_user_embedding',\n",
    "        embeddings_regularizer=l2(MF_reg[0]),\n",
    "        input_length=1)\n",
    "    \n",
    "    mf_embedding_item = Embedding(\n",
    "        input_dim=num_items + 1,\n",
    "        output_dim=MF_dim,\n",
    "        embeddings_initializer='uniform',\n",
    "        name='mf_item_embedding',\n",
    "        embeddings_regularizer=l2(MF_reg[1]),\n",
    "        input_length=1)\n",
    "    \n",
    "    # MLP\n",
    "    mlp_embedding_user = Embedding(\n",
    "        input_dim=num_users + 1,\n",
    "        output_dim=MLP_layers[0] // 2,\n",
    "        embeddings_initializer='uniform',\n",
    "        name='mlp_user_embedding',\n",
    "        embeddings_regularizer=l2(MLP_regs[0]),\n",
    "        input_length=1)\n",
    "    \n",
    "    mlp_embedding_Item = Embedding(\n",
    "        input_dim=num_items + 1,\n",
    "        output_dim=MLP_layers[0] // 2,\n",
    "        embeddings_initializer='uniform',\n",
    "        name='mlp_item_embedding',\n",
    "        embeddings_regularizer=l2(MLP_regs[0]),\n",
    "        input_length=1) \n",
    "    \n",
    "    # MF part\n",
    "    mf_user_latent = Flatten()(mf_embedding_user(user_input))\n",
    "    mf_item_latent = Flatten()(mf_embedding_item(item_input))\n",
    "    mf_vector = Multiply()([mf_user_latent, mf_item_latent])\n",
    "\n",
    "    # MLP part\n",
    "    mlp_user_latent = Flatten()(mlp_embedding_user(user_input))\n",
    "    mlp_item_latent = Flatten()(mlp_embedding_Item(item_input))\n",
    "    mlp_vector = Concatenate(axis=-1)([mlp_user_latent, mlp_item_latent])\n",
    "\n",
    "    for idx in range(1, num_MLP_layer):\n",
    "        layer = Dense(\n",
    "            units=MLP_layers[idx],\n",
    "            activation='relu',\n",
    "            kernel_initializer='glorot_uniform',\n",
    "            kernel_regularizer=l2(MLP_regs[idx]),\n",
    "            name = 'layer%d' %idx)\n",
    "        mlp_vector = layer(mlp_vector)\n",
    "    \n",
    "    # Concatenate MF and MLP parts\n",
    "    predict_vector = Concatenate(axis=-1)([mf_vector, mlp_vector])\n",
    "\n",
    "    # Final prediction layer\n",
    "    prediction = Dense(1, kernel_initializer='glorot_uniform', name='prediction')(predict_vector)\n",
    "    \n",
    "    # Stitch input and output\n",
    "    model = Model([user_input, item_input], prediction)\n",
    "    \n",
    "    return model"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### create NeuralMF model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"model_4\"\n",
      "__________________________________________________________________________________________________\n",
      "Layer (type)                    Output Shape         Param #     Connected to                     \n",
      "==================================================================================================\n",
      "user_input (InputLayer)         [(None, 1)]          0                                            \n",
      "__________________________________________________________________________________________________\n",
      "item_input (InputLayer)         [(None, 1)]          0                                            \n",
      "__________________________________________________________________________________________________\n",
      "mlp_user_embedding (Embedding)  (None, 1, 32)        8923456     user_input[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "mlp_item_embedding (Embedding)  (None, 1, 32)        8683520     item_input[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "flatten_10 (Flatten)            (None, 32)           0           mlp_user_embedding[0][0]         \n",
      "__________________________________________________________________________________________________\n",
      "flatten_11 (Flatten)            (None, 32)           0           mlp_item_embedding[0][0]         \n",
      "__________________________________________________________________________________________________\n",
      "concatenate_2 (Concatenate)     (None, 64)           0           flatten_10[0][0]                 \n",
      "                                                                 flatten_11[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "mf_user_embedding (Embedding)   (None, 1, 10)        2788580     user_input[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "mf_item_embedding (Embedding)   (None, 1, 10)        2713600     item_input[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "layer1 (Dense)                  (None, 32)           2080        concatenate_2[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "flatten_8 (Flatten)             (None, 10)           0           mf_user_embedding[0][0]          \n",
      "__________________________________________________________________________________________________\n",
      "flatten_9 (Flatten)             (None, 10)           0           mf_item_embedding[0][0]          \n",
      "__________________________________________________________________________________________________\n",
      "layer2 (Dense)                  (None, 16)           528         layer1[0][0]                     \n",
      "__________________________________________________________________________________________________\n",
      "multiply_2 (Multiply)           (None, 10)           0           flatten_8[0][0]                  \n",
      "                                                                 flatten_9[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "layer3 (Dense)                  (None, 8)            136         layer2[0][0]                     \n",
      "__________________________________________________________________________________________________\n",
      "concatenate_3 (Concatenate)     (None, 18)           0           multiply_2[0][0]                 \n",
      "                                                                 layer3[0][0]                     \n",
      "__________________________________________________________________________________________________\n",
      "prediction (Dense)              (None, 1)            19          concatenate_3[0][0]              \n",
      "==================================================================================================\n",
      "Total params: 23,111,919\n",
      "Trainable params: 23,111,919\n",
      "Non-trainable params: 0\n",
      "__________________________________________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "NeuralMF_model = get_NeuralMF_model(\n",
    "    num_users=user_max_id,\n",
    "    num_items=book_max_id,\n",
    "    MF_dim=10,\n",
    "    MF_reg=(0, 0),\n",
    "    MLP_layers=[64, 32, 16, 8],\n",
    "    MLP_regs=[0, 0, 0, 0])\n",
    "NeuralMF_model.summary()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### train NeuralMF model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train on 230304 samples, validate on 76769 samples\n",
      "Epoch 1/100000\n",
      "230304/230304 [==============================] - 10s 45us/sample - loss: 8.6418 - mean_squared_error: 8.6418 - rmse: 2.5670 - val_loss: 3.0765 - val_mean_squared_error: 3.0765 - val_rmse: 1.7536\n",
      "Epoch 2/100000\n",
      "230304/230304 [==============================] - 10s 42us/sample - loss: 2.1055 - mean_squared_error: 2.1055 - rmse: 1.4503 - val_loss: 3.0214 - val_mean_squared_error: 3.0214 - val_rmse: 1.7379\n",
      "Epoch 3/100000\n",
      "230304/230304 [==============================] - 10s 42us/sample - loss: 1.2051 - mean_squared_error: 1.2051 - rmse: 1.0976 - val_loss: 3.0664 - val_mean_squared_error: 3.0664 - val_rmse: 1.7508\n",
      "Epoch 4/100000\n",
      "230304/230304 [==============================] - 10s 43us/sample - loss: 0.8036 - mean_squared_error: 0.8036 - rmse: 0.8960 - val_loss: 3.1529 - val_mean_squared_error: 3.1529 - val_rmse: 1.7753\n",
      "Epoch 5/100000\n",
      "230304/230304 [==============================] - 10s 43us/sample - loss: 0.6047 - mean_squared_error: 0.6047 - rmse: 0.7774 - val_loss: 3.1501 - val_mean_squared_error: 3.1501 - val_rmse: 1.7745\n",
      "Epoch 6/100000\n",
      "230304/230304 [==============================] - 10s 43us/sample - loss: 0.4622 - mean_squared_error: 0.4622 - rmse: 0.6788 - val_loss: 3.1169 - val_mean_squared_error: 3.1169 - val_rmse: 1.7651\n",
      "Epoch 7/100000\n",
      "230304/230304 [==============================] - 10s 43us/sample - loss: 0.3599 - mean_squared_error: 0.3599 - rmse: 0.5998 - val_loss: 3.0863 - val_mean_squared_error: 3.0863 - val_rmse: 1.7564\n",
      "Epoch 8/100000\n",
      "230304/230304 [==============================] - 10s 43us/sample - loss: 0.2847 - mean_squared_error: 0.2847 - rmse: 0.5336 - val_loss: 3.1565 - val_mean_squared_error: 3.1565 - val_rmse: 1.7763\n",
      "Epoch 9/100000\n",
      "230304/230304 [==============================] - 10s 42us/sample - loss: 0.2287 - mean_squared_error: 0.2287 - rmse: 0.4779 - val_loss: 3.2617 - val_mean_squared_error: 3.2617 - val_rmse: 1.8057\n",
      "Epoch 10/100000\n",
      "230304/230304 [==============================] - 10s 43us/sample - loss: 0.2186 - mean_squared_error: 0.2186 - rmse: 0.4668 - val_loss: 3.2431 - val_mean_squared_error: 3.2431 - val_rmse: 1.8005\n",
      "Epoch 11/100000\n",
      "230304/230304 [==============================] - 10s 42us/sample - loss: 0.2107 - mean_squared_error: 0.2107 - rmse: 0.4590 - val_loss: 3.2063 - val_mean_squared_error: 3.2063 - val_rmse: 1.7902\n",
      "Epoch 12/100000\n",
      "230304/230304 [==============================] - 10s 42us/sample - loss: 0.1795 - mean_squared_error: 0.1795 - rmse: 0.4241 - val_loss: 3.1759 - val_mean_squared_error: 3.1759 - val_rmse: 1.7818\n",
      "Epoch 00012: early stopping\n"
     ]
    }
   ],
   "source": [
    "# model config\n",
    "BATCH_SIZE = 4096\n",
    "EPOCHS = 100000\n",
    "VAL_SPLIT = 0.25\n",
    "\n",
    "# train model\n",
    "history = train_model(\n",
    "    NeuralMF_model,\n",
    "    tf.keras.optimizers.Adam(0.1),\n",
    "    BATCH_SIZE,\n",
    "    EPOCHS,\n",
    "    VAL_SPLIT,\n",
    "    inputs=[train.uid.values, train.bid.values],\n",
    "    outputs=train.rating.values,\n",
    "    filepath='model/neural-nmf-weights.hdf5')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### Neural Matrix Factorization (NeuralMF) learning curve"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 864x504 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "plot_learning_curve(history, 'rmse')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### Neural Matrix Factorization (NeuralMF) model testing"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### And finally, make a prediction and check the testing error using out-of-sample data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The out-of-sample RMSE of rating predictions is 1.7331\n"
     ]
    }
   ],
   "source": [
    "# load best model\n",
    "NeuralMF_model = get_NeuralMF_model(\n",
    "    num_users=user_max_id,\n",
    "    num_items=book_max_id,\n",
    "    MF_dim=10,\n",
    "    MF_reg=(0, 0),\n",
    "    MLP_layers=[64, 32, 16, 8],\n",
    "    MLP_regs=[0, 0, 0, 0])\n",
    "NeuralMF_model = load_trained_model(NeuralMF_model, 'model/neural-nmf-weights.hdf5')\n",
    "\n",
    "# make prediction using test data\n",
    "predictions = NeuralMF_model.predict([test.uid.values, test.bid.values])\n",
    "\n",
    "# get the RMSE\n",
    "error = rmse(test.rating.values, predictions)\n",
    "print('The out-of-sample RMSE of rating predictions is', round(error, 4))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### Recommendation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>user_id</th>\n",
       "      <th>isbn</th>\n",
       "      <th>rating</th>\n",
       "      <th>bid</th>\n",
       "      <th>title</th>\n",
       "      <th>author</th>\n",
       "      <th>year_of_publication</th>\n",
       "      <th>publisher</th>\n",
       "      <th>uid</th>\n",
       "      <th>location</th>\n",
       "      <th>age</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>276726</td>\n",
       "      <td>0155061224</td>\n",
       "      <td>5</td>\n",
       "      <td>225816</td>\n",
       "      <td>Rites of Passage</td>\n",
       "      <td>Judith Rae</td>\n",
       "      <td>2001</td>\n",
       "      <td>Heinle</td>\n",
       "      <td>276725</td>\n",
       "      <td>seattle, washington, usa</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>276729</td>\n",
       "      <td>052165615X</td>\n",
       "      <td>3</td>\n",
       "      <td>246838</td>\n",
       "      <td>Help!: Level 1</td>\n",
       "      <td>Philip Prowse</td>\n",
       "      <td>1999</td>\n",
       "      <td>Cambridge University Press</td>\n",
       "      <td>276728</td>\n",
       "      <td>rijeka, n/a, croatia</td>\n",
       "      <td>16.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>276729</td>\n",
       "      <td>0521795028</td>\n",
       "      <td>6</td>\n",
       "      <td>246839</td>\n",
       "      <td>The Amsterdam Connection : Level 4 (Cambridge ...</td>\n",
       "      <td>Sue Leather</td>\n",
       "      <td>2001</td>\n",
       "      <td>Cambridge University Press</td>\n",
       "      <td>276728</td>\n",
       "      <td>rijeka, n/a, croatia</td>\n",
       "      <td>16.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>276744</td>\n",
       "      <td>038550120X</td>\n",
       "      <td>7</td>\n",
       "      <td>9294</td>\n",
       "      <td>A Painted House</td>\n",
       "      <td>JOHN GRISHAM</td>\n",
       "      <td>2001</td>\n",
       "      <td>Doubleday</td>\n",
       "      <td>276743</td>\n",
       "      <td>torrance, california, usa</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>12</th>\n",
       "      <td>276747</td>\n",
       "      <td>0060517794</td>\n",
       "      <td>9</td>\n",
       "      <td>4779</td>\n",
       "      <td>Little Altars Everywhere</td>\n",
       "      <td>Rebecca Wells</td>\n",
       "      <td>2003</td>\n",
       "      <td>HarperTorch</td>\n",
       "      <td>276746</td>\n",
       "      <td>iowa city, iowa, usa</td>\n",
       "      <td>25.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1031126</th>\n",
       "      <td>276704</td>\n",
       "      <td>0743211383</td>\n",
       "      <td>7</td>\n",
       "      <td>881</td>\n",
       "      <td>Dreamcatcher</td>\n",
       "      <td>Stephen King</td>\n",
       "      <td>2001</td>\n",
       "      <td>Scribner</td>\n",
       "      <td>276703</td>\n",
       "      <td>cedar park, texas, usa</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1031128</th>\n",
       "      <td>276704</td>\n",
       "      <td>0806917695</td>\n",
       "      <td>5</td>\n",
       "      <td>69541</td>\n",
       "      <td>Perplexing Lateral Thinking Puzzles: Scholasti...</td>\n",
       "      <td>Paul Sloane</td>\n",
       "      <td>1997</td>\n",
       "      <td>Sterling Publishing</td>\n",
       "      <td>276703</td>\n",
       "      <td>cedar park, texas, usa</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1031130</th>\n",
       "      <td>276704</td>\n",
       "      <td>1563526298</td>\n",
       "      <td>9</td>\n",
       "      <td>69544</td>\n",
       "      <td>Get Clark Smart : The Ultimate Guide for the S...</td>\n",
       "      <td>Clark Howard</td>\n",
       "      <td>2000</td>\n",
       "      <td>Longstreet Press</td>\n",
       "      <td>276703</td>\n",
       "      <td>cedar park, texas, usa</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1031132</th>\n",
       "      <td>276709</td>\n",
       "      <td>0515107662</td>\n",
       "      <td>10</td>\n",
       "      <td>15978</td>\n",
       "      <td>The Sherbrooke Bride (Bride Trilogy (Paperback))</td>\n",
       "      <td>Catherine Coulter</td>\n",
       "      <td>1996</td>\n",
       "      <td>Jove Books</td>\n",
       "      <td>276708</td>\n",
       "      <td>mannington, west virginia, usa</td>\n",
       "      <td>38.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1031133</th>\n",
       "      <td>276721</td>\n",
       "      <td>0590442449</td>\n",
       "      <td>10</td>\n",
       "      <td>56814</td>\n",
       "      <td>Fourth Grade Rats</td>\n",
       "      <td>Jerry Spinelli</td>\n",
       "      <td>1996</td>\n",
       "      <td>Scholastic</td>\n",
       "      <td>276720</td>\n",
       "      <td>providence, rhode island, usa</td>\n",
       "      <td>14.0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>383842 rows × 11 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "         user_id        isbn  rating     bid  \\\n",
       "0         276726  0155061224       5  225816   \n",
       "2         276729  052165615X       3  246838   \n",
       "3         276729  0521795028       6  246839   \n",
       "5         276744  038550120X       7    9294   \n",
       "12        276747  0060517794       9    4779   \n",
       "...          ...         ...     ...     ...   \n",
       "1031126   276704  0743211383       7     881   \n",
       "1031128   276704  0806917695       5   69541   \n",
       "1031130   276704  1563526298       9   69544   \n",
       "1031132   276709  0515107662      10   15978   \n",
       "1031133   276721  0590442449      10   56814   \n",
       "\n",
       "                                                     title             author  \\\n",
       "0                                         Rites of Passage         Judith Rae   \n",
       "2                                           Help!: Level 1      Philip Prowse   \n",
       "3        The Amsterdam Connection : Level 4 (Cambridge ...        Sue Leather   \n",
       "5                                          A Painted House       JOHN GRISHAM   \n",
       "12                                Little Altars Everywhere      Rebecca Wells   \n",
       "...                                                    ...                ...   \n",
       "1031126                                       Dreamcatcher       Stephen King   \n",
       "1031128  Perplexing Lateral Thinking Puzzles: Scholasti...        Paul Sloane   \n",
       "1031130  Get Clark Smart : The Ultimate Guide for the S...       Clark Howard   \n",
       "1031132   The Sherbrooke Bride (Bride Trilogy (Paperback))  Catherine Coulter   \n",
       "1031133                                  Fourth Grade Rats     Jerry Spinelli   \n",
       "\n",
       "        year_of_publication                   publisher     uid  \\\n",
       "0                      2001                      Heinle  276725   \n",
       "2                      1999  Cambridge University Press  276728   \n",
       "3                      2001  Cambridge University Press  276728   \n",
       "5                      2001                   Doubleday  276743   \n",
       "12                     2003                 HarperTorch  276746   \n",
       "...                     ...                         ...     ...   \n",
       "1031126                2001                    Scribner  276703   \n",
       "1031128                1997         Sterling Publishing  276703   \n",
       "1031130                2000            Longstreet Press  276703   \n",
       "1031132                1996                  Jove Books  276708   \n",
       "1031133                1996                  Scholastic  276720   \n",
       "\n",
       "                               location   age  \n",
       "0              seattle, washington, usa   NaN  \n",
       "2                  rijeka, n/a, croatia  16.0  \n",
       "3                  rijeka, n/a, croatia  16.0  \n",
       "5             torrance, california, usa   NaN  \n",
       "12                 iowa city, iowa, usa  25.0  \n",
       "...                                 ...   ...  \n",
       "1031126          cedar park, texas, usa   NaN  \n",
       "1031128          cedar park, texas, usa   NaN  \n",
       "1031130          cedar park, texas, usa   NaN  \n",
       "1031132  mannington, west virginia, usa  38.0  \n",
       "1031133   providence, rhode island, usa  14.0  \n",
       "\n",
       "[383842 rows x 11 columns]"
      ]
     },
     "execution_count": 37,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Creating dataset for making recommendations for the user\n",
    "ratings_clean_2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>user_id</th>\n",
       "      <th>isbn</th>\n",
       "      <th>rating</th>\n",
       "      <th>bid</th>\n",
       "      <th>title</th>\n",
       "      <th>author</th>\n",
       "      <th>year_of_publication</th>\n",
       "      <th>publisher</th>\n",
       "      <th>uid</th>\n",
       "      <th>location</th>\n",
       "      <th>age</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>9253</th>\n",
       "      <td>440</td>\n",
       "      <td>0743424425</td>\n",
       "      <td>10</td>\n",
       "      <td>502</td>\n",
       "      <td>The Shining</td>\n",
       "      <td>Stephen King</td>\n",
       "      <td>2001</td>\n",
       "      <td>Pocket</td>\n",
       "      <td>439</td>\n",
       "      <td>brookfield, wisconsin, usa</td>\n",
       "      <td>16.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9252</th>\n",
       "      <td>440</td>\n",
       "      <td>0393321576</td>\n",
       "      <td>8</td>\n",
       "      <td>501</td>\n",
       "      <td>Karl Marx: A Life</td>\n",
       "      <td>Francis Wheen</td>\n",
       "      <td>2001</td>\n",
       "      <td>W.W. Norton &amp;amp; Company</td>\n",
       "      <td>439</td>\n",
       "      <td>brookfield, wisconsin, usa</td>\n",
       "      <td>16.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9254</th>\n",
       "      <td>440</td>\n",
       "      <td>0786868015</td>\n",
       "      <td>7</td>\n",
       "      <td>503</td>\n",
       "      <td>The Diary of Ellen Rimbauer: My Life at Rose Red</td>\n",
       "      <td>Joyce Reardon</td>\n",
       "      <td>2001</td>\n",
       "      <td>Hyperion</td>\n",
       "      <td>439</td>\n",
       "      <td>brookfield, wisconsin, usa</td>\n",
       "      <td>16.0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "      user_id        isbn  rating  bid  \\\n",
       "9253      440  0743424425      10  502   \n",
       "9252      440  0393321576       8  501   \n",
       "9254      440  0786868015       7  503   \n",
       "\n",
       "                                                 title         author  \\\n",
       "9253                                       The Shining   Stephen King   \n",
       "9252                                 Karl Marx: A Life  Francis Wheen   \n",
       "9254  The Diary of Ellen Rimbauer: My Life at Rose Red  Joyce Reardon   \n",
       "\n",
       "     year_of_publication                  publisher  uid  \\\n",
       "9253                2001                     Pocket  439   \n",
       "9252                2001  W.W. Norton &amp; Company  439   \n",
       "9254                2001                   Hyperion  439   \n",
       "\n",
       "                        location   age  \n",
       "9253  brookfield, wisconsin, usa  16.0  \n",
       "9252  brookfield, wisconsin, usa  16.0  \n",
       "9254  brookfield, wisconsin, usa  16.0  "
      ]
     },
     "execution_count": 38,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# user ratings\n",
    "uid = 439\n",
    "books_data = np.array(list(set(ratings_clean_2.bid)))\n",
    "users_data = np.array([uid for i in range(len(books_data))])\n",
    "ratings_clean_2[ratings_clean_2.uid == uid].sort_values(['rating'], ascending=[0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>user_id</th>\n",
       "      <th>isbn</th>\n",
       "      <th>rating</th>\n",
       "      <th>bid</th>\n",
       "      <th>title</th>\n",
       "      <th>author</th>\n",
       "      <th>year_of_publication</th>\n",
       "      <th>publisher</th>\n",
       "      <th>uid</th>\n",
       "      <th>location</th>\n",
       "      <th>age</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>18880</th>\n",
       "      <td>4385</td>\n",
       "      <td>051506162X</td>\n",
       "      <td>10</td>\n",
       "      <td>18173</td>\n",
       "      <td>Lured into Dawn</td>\n",
       "      <td>Catherine Mills</td>\n",
       "      <td>1982</td>\n",
       "      <td>Jove</td>\n",
       "      <td>4384</td>\n",
       "      <td>albq, new mexico, usa</td>\n",
       "      <td>33.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>655475</th>\n",
       "      <td>177233</td>\n",
       "      <td>0070064512</td>\n",
       "      <td>7</td>\n",
       "      <td>19438</td>\n",
       "      <td>If Life Is a Bowl of Cherries, What Am I Doing...</td>\n",
       "      <td>Erma Bombeck</td>\n",
       "      <td>1978</td>\n",
       "      <td>McGraw-Hill</td>\n",
       "      <td>177232</td>\n",
       "      <td>austin, texas, usa</td>\n",
       "      <td>23.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>685379</th>\n",
       "      <td>185233</td>\n",
       "      <td>0590455419</td>\n",
       "      <td>5</td>\n",
       "      <td>69539</td>\n",
       "      <td>The Addams Family</td>\n",
       "      <td>Elizabeth Faucher</td>\n",
       "      <td>1991</td>\n",
       "      <td>Scholastic Paperbacks (Mm)</td>\n",
       "      <td>185232</td>\n",
       "      <td>winnemucca, nevada, usa</td>\n",
       "      <td>31.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>828636</th>\n",
       "      <td>225199</td>\n",
       "      <td>0192833545</td>\n",
       "      <td>10</td>\n",
       "      <td>55888</td>\n",
       "      <td>Wuthering Heights (Oxford World's Classics)</td>\n",
       "      <td>Emily Bronte</td>\n",
       "      <td>1998</td>\n",
       "      <td>Oxford University Press</td>\n",
       "      <td>225198</td>\n",
       "      <td>toronto, ontario, canada</td>\n",
       "      <td>54.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>842004</th>\n",
       "      <td>227702</td>\n",
       "      <td>0671019872</td>\n",
       "      <td>5</td>\n",
       "      <td>94612</td>\n",
       "      <td>MY SECRET GARDEN</td>\n",
       "      <td>Nancy Friday</td>\n",
       "      <td>1998</td>\n",
       "      <td>Pocket</td>\n",
       "      <td>227701</td>\n",
       "      <td>league city, texas, usa</td>\n",
       "      <td>42.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>931132</th>\n",
       "      <td>248325</td>\n",
       "      <td>0393323366</td>\n",
       "      <td>5</td>\n",
       "      <td>43842</td>\n",
       "      <td>A Dog's Ransom</td>\n",
       "      <td>Patricia Highsmith</td>\n",
       "      <td>2002</td>\n",
       "      <td>W. W. Norton &amp;amp; Company</td>\n",
       "      <td>248324</td>\n",
       "      <td>zaragoza, dc, spain</td>\n",
       "      <td>33.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>946984</th>\n",
       "      <td>251975</td>\n",
       "      <td>3442722497</td>\n",
       "      <td>8</td>\n",
       "      <td>6492</td>\n",
       "      <td>Schnee, der auf Zedern fÃ?ÃÂ¤llt.</td>\n",
       "      <td>David Guterson</td>\n",
       "      <td>1998</td>\n",
       "      <td>Btb Bei Goldmann</td>\n",
       "      <td>251974</td>\n",
       "      <td>eppstein, hessen, germany</td>\n",
       "      <td>30.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>966866</th>\n",
       "      <td>257700</td>\n",
       "      <td>0373711301</td>\n",
       "      <td>7</td>\n",
       "      <td>47571</td>\n",
       "      <td>A Husband Of Her Own</td>\n",
       "      <td>Brenda Novak</td>\n",
       "      <td>2003</td>\n",
       "      <td>Harlequin</td>\n",
       "      <td>257699</td>\n",
       "      <td>slippery rock, pennsylvania, usa</td>\n",
       "      <td>22.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1029736</th>\n",
       "      <td>276165</td>\n",
       "      <td>0312291639</td>\n",
       "      <td>9</td>\n",
       "      <td>2849</td>\n",
       "      <td>The Nanny Diaries: A Novel</td>\n",
       "      <td>Emma McLaughlin</td>\n",
       "      <td>2003</td>\n",
       "      <td>St. Martin's Griffin</td>\n",
       "      <td>276164</td>\n",
       "      <td>las vegas, nevada, usa</td>\n",
       "      <td>20.0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "         user_id        isbn  rating    bid  \\\n",
       "18880       4385  051506162X      10  18173   \n",
       "655475    177233  0070064512       7  19438   \n",
       "685379    185233  0590455419       5  69539   \n",
       "828636    225199  0192833545      10  55888   \n",
       "842004    227702  0671019872       5  94612   \n",
       "931132    248325  0393323366       5  43842   \n",
       "946984    251975  3442722497       8   6492   \n",
       "966866    257700  0373711301       7  47571   \n",
       "1029736   276165  0312291639       9   2849   \n",
       "\n",
       "                                                     title  \\\n",
       "18880                                      Lured into Dawn   \n",
       "655475   If Life Is a Bowl of Cherries, What Am I Doing...   \n",
       "685379                                   The Addams Family   \n",
       "828636         Wuthering Heights (Oxford World's Classics)   \n",
       "842004                                    MY SECRET GARDEN   \n",
       "931132                                      A Dog's Ransom   \n",
       "946984                 Schnee, der auf Zedern fÃ?ÃÂ¤llt.   \n",
       "966866                                A Husband Of Her Own   \n",
       "1029736                         The Nanny Diaries: A Novel   \n",
       "\n",
       "                     author year_of_publication                   publisher  \\\n",
       "18880       Catherine Mills                1982                        Jove   \n",
       "655475         Erma Bombeck                1978                 McGraw-Hill   \n",
       "685379    Elizabeth Faucher                1991  Scholastic Paperbacks (Mm)   \n",
       "828636         Emily Bronte                1998     Oxford University Press   \n",
       "842004         Nancy Friday                1998                      Pocket   \n",
       "931132   Patricia Highsmith                2002  W. W. Norton &amp; Company   \n",
       "946984       David Guterson                1998            Btb Bei Goldmann   \n",
       "966866         Brenda Novak                2003                   Harlequin   \n",
       "1029736     Emma McLaughlin                2003        St. Martin's Griffin   \n",
       "\n",
       "            uid                          location   age  \n",
       "18880      4384             albq, new mexico, usa  33.0  \n",
       "655475   177232                austin, texas, usa  23.0  \n",
       "685379   185232           winnemucca, nevada, usa  31.0  \n",
       "828636   225198          toronto, ontario, canada  54.0  \n",
       "842004   227701           league city, texas, usa  42.0  \n",
       "931132   248324               zaragoza, dc, spain  33.0  \n",
       "946984   251974         eppstein, hessen, germany  30.0  \n",
       "966866   257699  slippery rock, pennsylvania, usa  22.0  \n",
       "1029736  276164            las vegas, nevada, usa  20.0  "
      ]
     },
     "execution_count": 39,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# recommendations\n",
    "predictions = NeuralMF_model.predict([users_data, books_data])\n",
    "predictions = np.array([a[0] for a in predictions])\n",
    "recommended_book_ids = (-predictions).argsort()[:10]\n",
    "\n",
    "recommendations = ratings_clean_2[ratings_clean_2['bid'].isin(recommended_book_ids)]\n",
    "recommendations = recommendations.drop_duplicates(subset='title', keep=\"last\")\n",
    "recommendations.head(15)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
