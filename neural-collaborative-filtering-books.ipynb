{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### source: https://github.com/KevinLiao159/MyDataSciencePortfolio/blob/master/movie_recommender/movie_recommendation_using_NeuMF.ipynb"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 65,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "\n",
    "import pprint\n",
    "pp = pprint.PrettyPrinter(indent=2)\n",
    "\n",
    "# data science imports\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "\n",
    "import tensorflow as tf\n",
    "import tensorflow.keras.backend as K\n",
    "\n",
    "# sklearn imports\n",
    "from sklearn.model_selection import train_test_split\n",
    "\n",
    "# keras/tensorflow imports\n",
    "from tensorflow.keras.layers import Input, Embedding, Flatten, Dense, Multiply, Concatenate\n",
    "from tensorflow.keras.regularizers import l2\n",
    "from tensorflow.keras.models import Model\n",
    "\n",
    "# from tensorflow.keras.optimizers import Adagrad, Adam, SGD, RMSprop\n",
    "from tensorflow.keras.callbacks import EarlyStopping, ModelCheckpoint\n",
    "from tensorflow.keras.models import load_model\n",
    "\n",
    "# visualization imports\n",
    "import matplotlib.pyplot as plt\n",
    "%matplotlib inline"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 66,
   "metadata": {},
   "outputs": [],
   "source": [
    "def load_books():\n",
    "    df = pd.read_csv('data/book-books.dat', sep=';', header=1, encoding=\"latin-1\")\n",
    "    df.columns = ['isbn', 'title', 'author', 'year_of_publication', 'publisher', 'image_url_s', 'image_url_m', 'image_url_l']\n",
    "    \n",
    "    # insert custom index for word embedding training\n",
    "    df.insert(0, 'bid', range(1, len(df) + 1))\n",
    "    return df[['bid','isbn','title','author','year_of_publication','publisher']]\n",
    "\n",
    "def load_users():\n",
    "    df = pd.read_csv('data/book-users.dat', sep=';', header=1, encoding=\"latin-1\")\n",
    "    df.columns=['user_id', 'location', 'age']\n",
    "    \n",
    "    # insert custom index for word embedding training\n",
    "    df.insert(0, 'uid', range(1, len(df) + 1))\n",
    "    return df[['uid','user_id','location','age']]\n",
    "\n",
    "def load_ratings():\n",
    "    df = pd.read_csv('data/book-ratings.dat', sep=';', header=1, encoding=\"latin-1\")\n",
    "    df.columns=['user_id', 'isbn', 'rating']\n",
    "    return df[['user_id','isbn','rating']]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 69,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>bid</th>\n",
       "      <th>isbn</th>\n",
       "      <th>title</th>\n",
       "      <th>author</th>\n",
       "      <th>year_of_publication</th>\n",
       "      <th>publisher</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>1</td>\n",
       "      <td>0002005018</td>\n",
       "      <td>Clara Callan</td>\n",
       "      <td>Richard Bruce Wright</td>\n",
       "      <td>2001</td>\n",
       "      <td>HarperFlamingo Canada</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>2</td>\n",
       "      <td>0060973129</td>\n",
       "      <td>Decision in Normandy</td>\n",
       "      <td>Carlo D'Este</td>\n",
       "      <td>1991</td>\n",
       "      <td>HarperPerennial</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>3</td>\n",
       "      <td>0374157065</td>\n",
       "      <td>Flu: The Story of the Great Influenza Pandemic...</td>\n",
       "      <td>Gina Bari Kolata</td>\n",
       "      <td>1999</td>\n",
       "      <td>Farrar Straus Giroux</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>4</td>\n",
       "      <td>0393045218</td>\n",
       "      <td>The Mummies of Urumchi</td>\n",
       "      <td>E. J. W. Barber</td>\n",
       "      <td>1999</td>\n",
       "      <td>W. W. Norton &amp;amp; Company</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>5</td>\n",
       "      <td>0399135782</td>\n",
       "      <td>The Kitchen God's Wife</td>\n",
       "      <td>Amy Tan</td>\n",
       "      <td>1991</td>\n",
       "      <td>Putnam Pub Group</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>271354</th>\n",
       "      <td>271355</td>\n",
       "      <td>0440400988</td>\n",
       "      <td>There's a Bat in Bunk Five</td>\n",
       "      <td>Paula Danziger</td>\n",
       "      <td>1988</td>\n",
       "      <td>Random House Childrens Pub (Mm)</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>271355</th>\n",
       "      <td>271356</td>\n",
       "      <td>0525447644</td>\n",
       "      <td>From One to One Hundred</td>\n",
       "      <td>Teri Sloat</td>\n",
       "      <td>1991</td>\n",
       "      <td>Dutton Books</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>271356</th>\n",
       "      <td>271357</td>\n",
       "      <td>006008667X</td>\n",
       "      <td>Lily Dale : The True Story of the Town that Ta...</td>\n",
       "      <td>Christine Wicker</td>\n",
       "      <td>2004</td>\n",
       "      <td>HarperSanFrancisco</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>271357</th>\n",
       "      <td>271358</td>\n",
       "      <td>0192126040</td>\n",
       "      <td>Republic (World's Classics)</td>\n",
       "      <td>Plato</td>\n",
       "      <td>1996</td>\n",
       "      <td>Oxford University Press</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>271358</th>\n",
       "      <td>271359</td>\n",
       "      <td>0767409752</td>\n",
       "      <td>A Guided Tour of Rene Descartes' Meditations o...</td>\n",
       "      <td>Christopher  Biffle</td>\n",
       "      <td>2000</td>\n",
       "      <td>McGraw-Hill Humanities/Social Sciences/Languages</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>271359 rows Ã— 6 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "           bid        isbn                                              title  \\\n",
       "0            1  0002005018                                       Clara Callan   \n",
       "1            2  0060973129                               Decision in Normandy   \n",
       "2            3  0374157065  Flu: The Story of the Great Influenza Pandemic...   \n",
       "3            4  0393045218                             The Mummies of Urumchi   \n",
       "4            5  0399135782                             The Kitchen God's Wife   \n",
       "...        ...         ...                                                ...   \n",
       "271354  271355  0440400988                         There's a Bat in Bunk Five   \n",
       "271355  271356  0525447644                            From One to One Hundred   \n",
       "271356  271357  006008667X  Lily Dale : The True Story of the Town that Ta...   \n",
       "271357  271358  0192126040                        Republic (World's Classics)   \n",
       "271358  271359  0767409752  A Guided Tour of Rene Descartes' Meditations o...   \n",
       "\n",
       "                      author year_of_publication  \\\n",
       "0       Richard Bruce Wright                2001   \n",
       "1               Carlo D'Este                1991   \n",
       "2           Gina Bari Kolata                1999   \n",
       "3            E. J. W. Barber                1999   \n",
       "4                    Amy Tan                1991   \n",
       "...                      ...                 ...   \n",
       "271354        Paula Danziger                1988   \n",
       "271355            Teri Sloat                1991   \n",
       "271356      Christine Wicker                2004   \n",
       "271357                 Plato                1996   \n",
       "271358   Christopher  Biffle                2000   \n",
       "\n",
       "                                               publisher  \n",
       "0                                  HarperFlamingo Canada  \n",
       "1                                        HarperPerennial  \n",
       "2                                   Farrar Straus Giroux  \n",
       "3                             W. W. Norton &amp; Company  \n",
       "4                                       Putnam Pub Group  \n",
       "...                                                  ...  \n",
       "271354                   Random House Childrens Pub (Mm)  \n",
       "271355                                      Dutton Books  \n",
       "271356                                HarperSanFrancisco  \n",
       "271357                           Oxford University Press  \n",
       "271358  McGraw-Hill Humanities/Social Sciences/Languages  \n",
       "\n",
       "[271359 rows x 6 columns]"
      ]
     },
     "execution_count": 69,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "books = load_books()\n",
    "books"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 70,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>uid</th>\n",
       "      <th>user_id</th>\n",
       "      <th>location</th>\n",
       "      <th>age</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>1</td>\n",
       "      <td>2</td>\n",
       "      <td>stockton, california, usa</td>\n",
       "      <td>18.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>2</td>\n",
       "      <td>3</td>\n",
       "      <td>moscow, yukon territory, russia</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>3</td>\n",
       "      <td>4</td>\n",
       "      <td>porto, v.n.gaia, portugal</td>\n",
       "      <td>17.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>4</td>\n",
       "      <td>5</td>\n",
       "      <td>farnborough, hants, united kingdom</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>5</td>\n",
       "      <td>6</td>\n",
       "      <td>santa monica, california, usa</td>\n",
       "      <td>61.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>278852</th>\n",
       "      <td>278853</td>\n",
       "      <td>278854</td>\n",
       "      <td>portland, oregon, usa</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>278853</th>\n",
       "      <td>278854</td>\n",
       "      <td>278855</td>\n",
       "      <td>tacoma, washington, united kingdom</td>\n",
       "      <td>50.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>278854</th>\n",
       "      <td>278855</td>\n",
       "      <td>278856</td>\n",
       "      <td>brampton, ontario, canada</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>278855</th>\n",
       "      <td>278856</td>\n",
       "      <td>278857</td>\n",
       "      <td>knoxville, tennessee, usa</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>278856</th>\n",
       "      <td>278857</td>\n",
       "      <td>278858</td>\n",
       "      <td>dublin, n/a, ireland</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>278857 rows Ã— 4 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "           uid  user_id                            location   age\n",
       "0            1        2           stockton, california, usa  18.0\n",
       "1            2        3     moscow, yukon territory, russia   NaN\n",
       "2            3        4           porto, v.n.gaia, portugal  17.0\n",
       "3            4        5  farnborough, hants, united kingdom   NaN\n",
       "4            5        6       santa monica, california, usa  61.0\n",
       "...        ...      ...                                 ...   ...\n",
       "278852  278853   278854               portland, oregon, usa   NaN\n",
       "278853  278854   278855  tacoma, washington, united kingdom  50.0\n",
       "278854  278855   278856           brampton, ontario, canada   NaN\n",
       "278855  278856   278857           knoxville, tennessee, usa   NaN\n",
       "278856  278857   278858                dublin, n/a, ireland   NaN\n",
       "\n",
       "[278857 rows x 4 columns]"
      ]
     },
     "execution_count": 70,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "users = load_users()\n",
    "users"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 71,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>user_id</th>\n",
       "      <th>isbn</th>\n",
       "      <th>rating</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>276726</td>\n",
       "      <td>0155061224</td>\n",
       "      <td>5</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>276727</td>\n",
       "      <td>0446520802</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>276729</td>\n",
       "      <td>052165615X</td>\n",
       "      <td>3</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>276729</td>\n",
       "      <td>0521795028</td>\n",
       "      <td>6</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>276733</td>\n",
       "      <td>2080674722</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1149774</th>\n",
       "      <td>276704</td>\n",
       "      <td>1563526298</td>\n",
       "      <td>9</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1149775</th>\n",
       "      <td>276706</td>\n",
       "      <td>0679447156</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1149776</th>\n",
       "      <td>276709</td>\n",
       "      <td>0515107662</td>\n",
       "      <td>10</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1149777</th>\n",
       "      <td>276721</td>\n",
       "      <td>0590442449</td>\n",
       "      <td>10</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1149778</th>\n",
       "      <td>276723</td>\n",
       "      <td>05162443314</td>\n",
       "      <td>8</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>1149779 rows Ã— 3 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "         user_id         isbn  rating\n",
       "0         276726   0155061224       5\n",
       "1         276727   0446520802       0\n",
       "2         276729   052165615X       3\n",
       "3         276729   0521795028       6\n",
       "4         276733   2080674722       0\n",
       "...          ...          ...     ...\n",
       "1149774   276704   1563526298       9\n",
       "1149775   276706   0679447156       0\n",
       "1149776   276709   0515107662      10\n",
       "1149777   276721   0590442449      10\n",
       "1149778   276723  05162443314       8\n",
       "\n",
       "[1149779 rows x 3 columns]"
      ]
     },
     "execution_count": 71,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "ratings = load_ratings()\n",
    "ratings"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 72,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>user_id</th>\n",
       "      <th>isbn</th>\n",
       "      <th>rating</th>\n",
       "      <th>bid</th>\n",
       "      <th>title</th>\n",
       "      <th>author</th>\n",
       "      <th>year_of_publication</th>\n",
       "      <th>publisher</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>276726</td>\n",
       "      <td>0155061224</td>\n",
       "      <td>5</td>\n",
       "      <td>225816</td>\n",
       "      <td>Rites of Passage</td>\n",
       "      <td>Judith Rae</td>\n",
       "      <td>2001</td>\n",
       "      <td>Heinle</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>276727</td>\n",
       "      <td>0446520802</td>\n",
       "      <td>0</td>\n",
       "      <td>11053</td>\n",
       "      <td>The Notebook</td>\n",
       "      <td>Nicholas Sparks</td>\n",
       "      <td>1996</td>\n",
       "      <td>Warner Books</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>276729</td>\n",
       "      <td>052165615X</td>\n",
       "      <td>3</td>\n",
       "      <td>246838</td>\n",
       "      <td>Help!: Level 1</td>\n",
       "      <td>Philip Prowse</td>\n",
       "      <td>1999</td>\n",
       "      <td>Cambridge University Press</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>276729</td>\n",
       "      <td>0521795028</td>\n",
       "      <td>6</td>\n",
       "      <td>246839</td>\n",
       "      <td>The Amsterdam Connection : Level 4 (Cambridge ...</td>\n",
       "      <td>Sue Leather</td>\n",
       "      <td>2001</td>\n",
       "      <td>Cambridge University Press</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>276733</td>\n",
       "      <td>2080674722</td>\n",
       "      <td>0</td>\n",
       "      <td>123639</td>\n",
       "      <td>Les Particules Elementaires</td>\n",
       "      <td>Michel Houellebecq</td>\n",
       "      <td>1998</td>\n",
       "      <td>Flammarion</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1149773</th>\n",
       "      <td>276704</td>\n",
       "      <td>0876044011</td>\n",
       "      <td>0</td>\n",
       "      <td>69543</td>\n",
       "      <td>Edgar Cayce on the Akashic Records: The Book o...</td>\n",
       "      <td>Kevin J. Todeschi</td>\n",
       "      <td>1998</td>\n",
       "      <td>A.R.E. Press (Association of Research &amp;amp; Enlig</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1149774</th>\n",
       "      <td>276704</td>\n",
       "      <td>1563526298</td>\n",
       "      <td>9</td>\n",
       "      <td>69544</td>\n",
       "      <td>Get Clark Smart : The Ultimate Guide for the S...</td>\n",
       "      <td>Clark Howard</td>\n",
       "      <td>2000</td>\n",
       "      <td>Longstreet Press</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1149775</th>\n",
       "      <td>276706</td>\n",
       "      <td>0679447156</td>\n",
       "      <td>0</td>\n",
       "      <td>52540</td>\n",
       "      <td>Eight Weeks to Optimum Health: A Proven Progra...</td>\n",
       "      <td>Andrew Weil</td>\n",
       "      <td>1997</td>\n",
       "      <td>Alfred A. Knopf</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1149776</th>\n",
       "      <td>276709</td>\n",
       "      <td>0515107662</td>\n",
       "      <td>10</td>\n",
       "      <td>15978</td>\n",
       "      <td>The Sherbrooke Bride (Bride Trilogy (Paperback))</td>\n",
       "      <td>Catherine Coulter</td>\n",
       "      <td>1996</td>\n",
       "      <td>Jove Books</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1149777</th>\n",
       "      <td>276721</td>\n",
       "      <td>0590442449</td>\n",
       "      <td>10</td>\n",
       "      <td>56814</td>\n",
       "      <td>Fourth Grade Rats</td>\n",
       "      <td>Jerry Spinelli</td>\n",
       "      <td>1996</td>\n",
       "      <td>Scholastic</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>1031134 rows Ã— 8 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "         user_id        isbn  rating     bid  \\\n",
       "0         276726  0155061224       5  225816   \n",
       "1         276727  0446520802       0   11053   \n",
       "2         276729  052165615X       3  246838   \n",
       "3         276729  0521795028       6  246839   \n",
       "4         276733  2080674722       0  123639   \n",
       "...          ...         ...     ...     ...   \n",
       "1149773   276704  0876044011       0   69543   \n",
       "1149774   276704  1563526298       9   69544   \n",
       "1149775   276706  0679447156       0   52540   \n",
       "1149776   276709  0515107662      10   15978   \n",
       "1149777   276721  0590442449      10   56814   \n",
       "\n",
       "                                                     title  \\\n",
       "0                                         Rites of Passage   \n",
       "1                                             The Notebook   \n",
       "2                                           Help!: Level 1   \n",
       "3        The Amsterdam Connection : Level 4 (Cambridge ...   \n",
       "4                              Les Particules Elementaires   \n",
       "...                                                    ...   \n",
       "1149773  Edgar Cayce on the Akashic Records: The Book o...   \n",
       "1149774  Get Clark Smart : The Ultimate Guide for the S...   \n",
       "1149775  Eight Weeks to Optimum Health: A Proven Progra...   \n",
       "1149776   The Sherbrooke Bride (Bride Trilogy (Paperback))   \n",
       "1149777                                  Fourth Grade Rats   \n",
       "\n",
       "                     author year_of_publication  \\\n",
       "0                Judith Rae                2001   \n",
       "1           Nicholas Sparks                1996   \n",
       "2             Philip Prowse                1999   \n",
       "3               Sue Leather                2001   \n",
       "4        Michel Houellebecq                1998   \n",
       "...                     ...                 ...   \n",
       "1149773   Kevin J. Todeschi                1998   \n",
       "1149774        Clark Howard                2000   \n",
       "1149775         Andrew Weil                1997   \n",
       "1149776   Catherine Coulter                1996   \n",
       "1149777      Jerry Spinelli                1996   \n",
       "\n",
       "                                                 publisher  \n",
       "0                                                   Heinle  \n",
       "1                                             Warner Books  \n",
       "2                               Cambridge University Press  \n",
       "3                               Cambridge University Press  \n",
       "4                                               Flammarion  \n",
       "...                                                    ...  \n",
       "1149773  A.R.E. Press (Association of Research &amp; Enlig  \n",
       "1149774                                   Longstreet Press  \n",
       "1149775                                    Alfred A. Knopf  \n",
       "1149776                                         Jove Books  \n",
       "1149777                                         Scholastic  \n",
       "\n",
       "[1031134 rows x 8 columns]"
      ]
     },
     "execution_count": 72,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# do some preprocessing to make sure data quality\n",
    "ratings_clean_1 = ratings.merge(books, on='isbn', how='left', indicator=True)\n",
    "ratings_clean_1 = ratings_clean_1[ratings_clean_1._merge != 'left_only']\n",
    "ratings_clean_1 = ratings_clean_1.astype({'bid': 'int32'})\n",
    "ratings_clean_1 = ratings_clean_1.drop(['_merge'], axis=1)\n",
    "ratings_clean_1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 73,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>user_id</th>\n",
       "      <th>isbn</th>\n",
       "      <th>rating</th>\n",
       "      <th>bid</th>\n",
       "      <th>title</th>\n",
       "      <th>author</th>\n",
       "      <th>year_of_publication</th>\n",
       "      <th>publisher</th>\n",
       "      <th>uid</th>\n",
       "      <th>location</th>\n",
       "      <th>age</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>276726</td>\n",
       "      <td>0155061224</td>\n",
       "      <td>5</td>\n",
       "      <td>225816</td>\n",
       "      <td>Rites of Passage</td>\n",
       "      <td>Judith Rae</td>\n",
       "      <td>2001</td>\n",
       "      <td>Heinle</td>\n",
       "      <td>276725</td>\n",
       "      <td>seattle, washington, usa</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>276729</td>\n",
       "      <td>052165615X</td>\n",
       "      <td>3</td>\n",
       "      <td>246838</td>\n",
       "      <td>Help!: Level 1</td>\n",
       "      <td>Philip Prowse</td>\n",
       "      <td>1999</td>\n",
       "      <td>Cambridge University Press</td>\n",
       "      <td>276728</td>\n",
       "      <td>rijeka, n/a, croatia</td>\n",
       "      <td>16.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>276729</td>\n",
       "      <td>0521795028</td>\n",
       "      <td>6</td>\n",
       "      <td>246839</td>\n",
       "      <td>The Amsterdam Connection : Level 4 (Cambridge ...</td>\n",
       "      <td>Sue Leather</td>\n",
       "      <td>2001</td>\n",
       "      <td>Cambridge University Press</td>\n",
       "      <td>276728</td>\n",
       "      <td>rijeka, n/a, croatia</td>\n",
       "      <td>16.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>276744</td>\n",
       "      <td>038550120X</td>\n",
       "      <td>7</td>\n",
       "      <td>9294</td>\n",
       "      <td>A Painted House</td>\n",
       "      <td>JOHN GRISHAM</td>\n",
       "      <td>2001</td>\n",
       "      <td>Doubleday</td>\n",
       "      <td>276743</td>\n",
       "      <td>torrance, california, usa</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>12</th>\n",
       "      <td>276747</td>\n",
       "      <td>0060517794</td>\n",
       "      <td>9</td>\n",
       "      <td>4779</td>\n",
       "      <td>Little Altars Everywhere</td>\n",
       "      <td>Rebecca Wells</td>\n",
       "      <td>2003</td>\n",
       "      <td>HarperTorch</td>\n",
       "      <td>276746</td>\n",
       "      <td>iowa city, iowa, usa</td>\n",
       "      <td>25.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1031126</th>\n",
       "      <td>276704</td>\n",
       "      <td>0743211383</td>\n",
       "      <td>7</td>\n",
       "      <td>881</td>\n",
       "      <td>Dreamcatcher</td>\n",
       "      <td>Stephen King</td>\n",
       "      <td>2001</td>\n",
       "      <td>Scribner</td>\n",
       "      <td>276703</td>\n",
       "      <td>cedar park, texas, usa</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1031128</th>\n",
       "      <td>276704</td>\n",
       "      <td>0806917695</td>\n",
       "      <td>5</td>\n",
       "      <td>69541</td>\n",
       "      <td>Perplexing Lateral Thinking Puzzles: Scholasti...</td>\n",
       "      <td>Paul Sloane</td>\n",
       "      <td>1997</td>\n",
       "      <td>Sterling Publishing</td>\n",
       "      <td>276703</td>\n",
       "      <td>cedar park, texas, usa</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1031130</th>\n",
       "      <td>276704</td>\n",
       "      <td>1563526298</td>\n",
       "      <td>9</td>\n",
       "      <td>69544</td>\n",
       "      <td>Get Clark Smart : The Ultimate Guide for the S...</td>\n",
       "      <td>Clark Howard</td>\n",
       "      <td>2000</td>\n",
       "      <td>Longstreet Press</td>\n",
       "      <td>276703</td>\n",
       "      <td>cedar park, texas, usa</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1031132</th>\n",
       "      <td>276709</td>\n",
       "      <td>0515107662</td>\n",
       "      <td>10</td>\n",
       "      <td>15978</td>\n",
       "      <td>The Sherbrooke Bride (Bride Trilogy (Paperback))</td>\n",
       "      <td>Catherine Coulter</td>\n",
       "      <td>1996</td>\n",
       "      <td>Jove Books</td>\n",
       "      <td>276708</td>\n",
       "      <td>mannington, west virginia, usa</td>\n",
       "      <td>38.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1031133</th>\n",
       "      <td>276721</td>\n",
       "      <td>0590442449</td>\n",
       "      <td>10</td>\n",
       "      <td>56814</td>\n",
       "      <td>Fourth Grade Rats</td>\n",
       "      <td>Jerry Spinelli</td>\n",
       "      <td>1996</td>\n",
       "      <td>Scholastic</td>\n",
       "      <td>276720</td>\n",
       "      <td>providence, rhode island, usa</td>\n",
       "      <td>14.0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>383842 rows Ã— 11 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "         user_id        isbn  rating     bid  \\\n",
       "0         276726  0155061224       5  225816   \n",
       "2         276729  052165615X       3  246838   \n",
       "3         276729  0521795028       6  246839   \n",
       "5         276744  038550120X       7    9294   \n",
       "12        276747  0060517794       9    4779   \n",
       "...          ...         ...     ...     ...   \n",
       "1031126   276704  0743211383       7     881   \n",
       "1031128   276704  0806917695       5   69541   \n",
       "1031130   276704  1563526298       9   69544   \n",
       "1031132   276709  0515107662      10   15978   \n",
       "1031133   276721  0590442449      10   56814   \n",
       "\n",
       "                                                     title             author  \\\n",
       "0                                         Rites of Passage         Judith Rae   \n",
       "2                                           Help!: Level 1      Philip Prowse   \n",
       "3        The Amsterdam Connection : Level 4 (Cambridge ...        Sue Leather   \n",
       "5                                          A Painted House       JOHN GRISHAM   \n",
       "12                                Little Altars Everywhere      Rebecca Wells   \n",
       "...                                                    ...                ...   \n",
       "1031126                                       Dreamcatcher       Stephen King   \n",
       "1031128  Perplexing Lateral Thinking Puzzles: Scholasti...        Paul Sloane   \n",
       "1031130  Get Clark Smart : The Ultimate Guide for the S...       Clark Howard   \n",
       "1031132   The Sherbrooke Bride (Bride Trilogy (Paperback))  Catherine Coulter   \n",
       "1031133                                  Fourth Grade Rats     Jerry Spinelli   \n",
       "\n",
       "        year_of_publication                   publisher     uid  \\\n",
       "0                      2001                      Heinle  276725   \n",
       "2                      1999  Cambridge University Press  276728   \n",
       "3                      2001  Cambridge University Press  276728   \n",
       "5                      2001                   Doubleday  276743   \n",
       "12                     2003                 HarperTorch  276746   \n",
       "...                     ...                         ...     ...   \n",
       "1031126                2001                    Scribner  276703   \n",
       "1031128                1997         Sterling Publishing  276703   \n",
       "1031130                2000            Longstreet Press  276703   \n",
       "1031132                1996                  Jove Books  276708   \n",
       "1031133                1996                  Scholastic  276720   \n",
       "\n",
       "                               location   age  \n",
       "0              seattle, washington, usa   NaN  \n",
       "2                  rijeka, n/a, croatia  16.0  \n",
       "3                  rijeka, n/a, croatia  16.0  \n",
       "5             torrance, california, usa   NaN  \n",
       "12                 iowa city, iowa, usa  25.0  \n",
       "...                                 ...   ...  \n",
       "1031126          cedar park, texas, usa   NaN  \n",
       "1031128          cedar park, texas, usa   NaN  \n",
       "1031130          cedar park, texas, usa   NaN  \n",
       "1031132  mannington, west virginia, usa  38.0  \n",
       "1031133   providence, rhode island, usa  14.0  \n",
       "\n",
       "[383842 rows x 11 columns]"
      ]
     },
     "execution_count": 73,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# do some preprocessing to make sure data quality\n",
    "ratings_clean_2 = ratings_clean_1.merge(users, on='user_id', how='left', indicator=True)\n",
    "ratings_clean_2 = ratings_clean_2[ratings_clean_2.rating != 0]\n",
    "ratings_clean_2 = ratings_clean_2.drop(['_merge'], axis=1)\n",
    "ratings_clean_2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 74,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "There are 68091 unique users and 149836 unique books in this data set\n"
     ]
    }
   ],
   "source": [
    "num_users = len(ratings_clean_2.uid.unique())\n",
    "num_items = len(ratings_clean_2.bid.unique())\n",
    "print('There are {} unique users and {} unique books in this data set'.format(num_users, num_items))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 75,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "There are 68091 distinct users in ratings and the max of uid is 278857\n",
      "There are 149836 distinct books in ratings and the max of bid is 271359\n"
     ]
    }
   ],
   "source": [
    "user_max_id = users.uid.max()\n",
    "book_max_id = books.bid.max()\n",
    "print('There are {} distinct users in ratings and the max of uid is {}'.format(num_users, user_max_id))\n",
    "print('There are {} distinct books in ratings and the max of bid is {}'.format(num_items, book_max_id))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### Split Data Into Train/Test"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 76,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "shape of training data set:\n",
      "(307073, 11)\n",
      "shape of test data set:\n",
      "(76769, 11)\n"
     ]
    }
   ],
   "source": [
    "train, test = train_test_split(ratings_clean_2, test_size=0.2, shuffle=True, random_state=99)\n",
    "print('shape of training data set:')\n",
    "print(train.shape)\n",
    "print('shape of test data set:')\n",
    "print(test.shape)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### Train Generalized Matrix Factorization and Test Model"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### define GMF model architeture and train routine"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 81,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_GMF_model(num_users, num_items, latent_dim, vu_reg, vi_reg):\n",
    "    \"\"\"\n",
    "    Build Generalized Matrix Factorization Model Topology\n",
    "    \n",
    "    Parameters\n",
    "    ----------\n",
    "    num_users: int, total number of users\n",
    "    num_iterms: int, total number of items\n",
    "    latent_dim: int, embedded dimension for user vector and item vector\n",
    "    vu_reg: float, L2 regularization of user embedded layer\n",
    "    vi_reg: float, L2 regularization of item embedded layer\n",
    "\n",
    "    Return\n",
    "    ------\n",
    "    A Keras Model with GMF model architeture\n",
    "    \"\"\"\n",
    "    # Input variables\n",
    "    user_input = Input(shape=(1,), dtype='int32', name='user_input')\n",
    "    item_input = Input(shape=(1,), dtype='int32', name='item_input')\n",
    "\n",
    "    mf_embedding_user = Embedding(\n",
    "        input_dim = num_users + 1,\n",
    "        output_dim = latent_dim,\n",
    "        embeddings_initializer = 'uniform',\n",
    "        name = 'user_embedding',\n",
    "        embeddings_regularizer = l2(vu_reg),\n",
    "        input_length = 1\n",
    "    )\n",
    "    \n",
    "    mf_embedding_item = Embedding(\n",
    "        input_dim = num_items + 1,\n",
    "        output_dim = latent_dim,\n",
    "        embeddings_initializer = 'uniform',\n",
    "        name = 'item_embedding',\n",
    "        embeddings_regularizer = l2(vi_reg),\n",
    "        input_length = 1\n",
    "    ) \n",
    "    \n",
    "    # Crucial to flatten an embedding vector!\n",
    "    user_latent = Flatten()(mf_embedding_user(user_input))\n",
    "    item_latent = Flatten()(mf_embedding_item(item_input))\n",
    "\n",
    "    # Element-wise product of user and item embeddings \n",
    "    predict_vector = Multiply()([user_latent, item_latent])\n",
    "    \n",
    "    # Final prediction layer\n",
    "    prediction = Dense(1, kernel_initializer='glorot_uniform', name='prediction')(predict_vector)\n",
    "    \n",
    "    # Stitch input and output\n",
    "    model = Model([user_input, item_input], prediction)\n",
    "    \n",
    "    return model\n",
    "\n",
    "def train_model(model, learner, batch_size, epochs, val_split, inputs, outputs, filepath):\n",
    "    \"\"\"\n",
    "    define training routine, train models and save best model\n",
    "    \n",
    "    Parameters\n",
    "    ----------\n",
    "    model: a Keras model\n",
    "    learner: str, one of ['sgd', 'adam', 'rmsprop', 'adagrad']\n",
    "    batch_size: num samples per update\n",
    "    epochs: num iterations\n",
    "    val_split: split ratio for validation data\n",
    "    inputs: inputs data\n",
    "    outputs: outputs data\n",
    "    \"\"\"\n",
    "    # add customized metric\n",
    "    def rmse(y_true, y_pred):\n",
    "        return K.sqrt(K.mean(K.square(y_true - y_pred)))\n",
    "    \n",
    "    # compile model\n",
    "    model.compile(optimizer=learner, loss='mean_squared_error', metrics=['mean_squared_error', rmse])\n",
    "    \n",
    "    # add call backs\n",
    "    early_stopper = EarlyStopping(monitor='val_rmse', patience=10, verbose=1)\n",
    "    model_saver = ModelCheckpoint(filepath=filepath, monitor='val_rmse', save_best_only=True, save_weights_only=True)\n",
    "    \n",
    "    # train model\n",
    "    history = model.fit(inputs, outputs, batch_size=batch_size, epochs=epochs, validation_split=val_split, callbacks=[early_stopper, model_saver])\n",
    "    \n",
    "    return history\n",
    "\n",
    "def load_trained_model(model, weights_path):\n",
    "    model.load_weights(weights_path)\n",
    "    return model"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### create GMF model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 82,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"model_11\"\n",
      "__________________________________________________________________________________________________\n",
      "Layer (type)                    Output Shape         Param #     Connected to                     \n",
      "==================================================================================================\n",
      "user_input (InputLayer)         [(None, 1)]          0                                            \n",
      "__________________________________________________________________________________________________\n",
      "item_input (InputLayer)         [(None, 1)]          0                                            \n",
      "__________________________________________________________________________________________________\n",
      "user_embedding (Embedding)      (None, 1, 10)        2788580     user_input[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "item_embedding (Embedding)      (None, 1, 10)        2713600     item_input[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "flatten_30 (Flatten)            (None, 10)           0           user_embedding[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "flatten_31 (Flatten)            (None, 10)           0           item_embedding[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "multiply_6 (Multiply)           (None, 10)           0           flatten_30[0][0]                 \n",
      "                                                                 flatten_31[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "prediction (Dense)              (None, 1)            11          multiply_6[0][0]                 \n",
      "==================================================================================================\n",
      "Total params: 5,502,191\n",
      "Trainable params: 5,502,191\n",
      "Non-trainable params: 0\n",
      "__________________________________________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "GMF_model = get_GMF_model(user_max_id, book_max_id, 10, 0, 0)\n",
    "GMF_model.summary()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### train GMF model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 83,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train on 230304 samples, validate on 76769 samples\n",
      "Epoch 1/10000\n",
      "230304/230304 [==============================] - 3s 12us/sample - loss: 30.7825 - mean_squared_error: 30.7825 - rmse: 5.3473 - val_loss: 9.9407 - val_mean_squared_error: 9.9407 - val_rmse: 3.1530\n",
      "Epoch 2/10000\n",
      "230304/230304 [==============================] - 2s 10us/sample - loss: 4.1983 - mean_squared_error: 4.1983 - rmse: 2.0348 - val_loss: 4.8340 - val_mean_squared_error: 4.8340 - val_rmse: 2.1985\n",
      "Epoch 3/10000\n",
      "230304/230304 [==============================] - 2s 10us/sample - loss: 1.3393 - mean_squared_error: 1.3393 - rmse: 1.1579 - val_loss: 4.5734 - val_mean_squared_error: 4.5734 - val_rmse: 2.1386\n",
      "Epoch 4/10000\n",
      "230304/230304 [==============================] - 2s 10us/sample - loss: 0.7129 - mean_squared_error: 0.7129 - rmse: 0.8443 - val_loss: 4.4436 - val_mean_squared_error: 4.4436 - val_rmse: 2.1080\n",
      "Epoch 5/10000\n",
      "230304/230304 [==============================] - 2s 10us/sample - loss: 0.4852 - mean_squared_error: 0.4852 - rmse: 0.6964 - val_loss: 4.5602 - val_mean_squared_error: 4.5602 - val_rmse: 2.1356\n",
      "Epoch 6/10000\n",
      "230304/230304 [==============================] - 2s 10us/sample - loss: 0.3737 - mean_squared_error: 0.3737 - rmse: 0.6109 - val_loss: 4.5069 - val_mean_squared_error: 4.5069 - val_rmse: 2.1230\n",
      "Epoch 7/10000\n",
      "230304/230304 [==============================] - 2s 10us/sample - loss: 0.3188 - mean_squared_error: 0.3188 - rmse: 0.5639 - val_loss: 4.4973 - val_mean_squared_error: 4.4973 - val_rmse: 2.1207\n",
      "Epoch 8/10000\n",
      "230304/230304 [==============================] - 2s 10us/sample - loss: 0.2880 - mean_squared_error: 0.2880 - rmse: 0.5364 - val_loss: 4.4826 - val_mean_squared_error: 4.4826 - val_rmse: 2.1173\n",
      "Epoch 9/10000\n",
      "230304/230304 [==============================] - 2s 10us/sample - loss: 0.2599 - mean_squared_error: 0.2599 - rmse: 0.5092 - val_loss: 4.5069 - val_mean_squared_error: 4.5069 - val_rmse: 2.1230\n",
      "Epoch 10/10000\n",
      "230304/230304 [==============================] - 2s 10us/sample - loss: 0.2374 - mean_squared_error: 0.2374 - rmse: 0.4869 - val_loss: 4.4207 - val_mean_squared_error: 4.4207 - val_rmse: 2.1026\n",
      "Epoch 11/10000\n",
      "230304/230304 [==============================] - 2s 10us/sample - loss: 0.2178 - mean_squared_error: 0.2178 - rmse: 0.4660 - val_loss: 4.5319 - val_mean_squared_error: 4.5319 - val_rmse: 2.1290\n",
      "Epoch 12/10000\n",
      "230304/230304 [==============================] - 2s 10us/sample - loss: 0.2002 - mean_squared_error: 0.2002 - rmse: 0.4472 - val_loss: 4.4143 - val_mean_squared_error: 4.4143 - val_rmse: 2.1011\n",
      "Epoch 13/10000\n",
      "230304/230304 [==============================] - 2s 10us/sample - loss: 0.1843 - mean_squared_error: 0.1843 - rmse: 0.4291 - val_loss: 4.4088 - val_mean_squared_error: 4.4088 - val_rmse: 2.0998\n",
      "Epoch 14/10000\n",
      "230304/230304 [==============================] - 2s 10us/sample - loss: 0.1696 - mean_squared_error: 0.1696 - rmse: 0.4119 - val_loss: 4.2827 - val_mean_squared_error: 4.2827 - val_rmse: 2.0696\n",
      "Epoch 15/10000\n",
      "230304/230304 [==============================] - 2s 10us/sample - loss: 0.1584 - mean_squared_error: 0.1584 - rmse: 0.3980 - val_loss: 4.3193 - val_mean_squared_error: 4.3193 - val_rmse: 2.0783\n",
      "Epoch 16/10000\n",
      "230304/230304 [==============================] - 3s 11us/sample - loss: 0.1521 - mean_squared_error: 0.1521 - rmse: 0.3893 - val_loss: 4.3408 - val_mean_squared_error: 4.3408 - val_rmse: 2.0836\n",
      "Epoch 17/10000\n",
      "230304/230304 [==============================] - 2s 10us/sample - loss: 0.1404 - mean_squared_error: 0.1404 - rmse: 0.3750 - val_loss: 4.3101 - val_mean_squared_error: 4.3101 - val_rmse: 2.0761\n",
      "Epoch 18/10000\n",
      "230304/230304 [==============================] - 2s 11us/sample - loss: 0.1398 - mean_squared_error: 0.1398 - rmse: 0.3737 - val_loss: 4.2412 - val_mean_squared_error: 4.2412 - val_rmse: 2.0595\n",
      "Epoch 19/10000\n",
      "230304/230304 [==============================] - 3s 11us/sample - loss: 0.1454 - mean_squared_error: 0.1454 - rmse: 0.3808 - val_loss: 4.2945 - val_mean_squared_error: 4.2945 - val_rmse: 2.0724\n",
      "Epoch 20/10000\n",
      "230304/230304 [==============================] - 2s 10us/sample - loss: 0.1360 - mean_squared_error: 0.1360 - rmse: 0.3687 - val_loss: 4.3782 - val_mean_squared_error: 4.3782 - val_rmse: 2.0925\n",
      "Epoch 21/10000\n",
      "230304/230304 [==============================] - 2s 10us/sample - loss: 0.1269 - mean_squared_error: 0.1269 - rmse: 0.3561 - val_loss: 4.2569 - val_mean_squared_error: 4.2569 - val_rmse: 2.0633\n",
      "Epoch 22/10000\n",
      "230304/230304 [==============================] - 2s 11us/sample - loss: 0.1192 - mean_squared_error: 0.1192 - rmse: 0.3452 - val_loss: 4.2150 - val_mean_squared_error: 4.2150 - val_rmse: 2.0531\n",
      "Epoch 23/10000\n",
      "230304/230304 [==============================] - 2s 10us/sample - loss: 0.1163 - mean_squared_error: 0.1163 - rmse: 0.3408 - val_loss: 4.2555 - val_mean_squared_error: 4.2555 - val_rmse: 2.0630\n",
      "Epoch 24/10000\n",
      "230304/230304 [==============================] - 2s 10us/sample - loss: 0.1138 - mean_squared_error: 0.1138 - rmse: 0.3370 - val_loss: 4.2160 - val_mean_squared_error: 4.2160 - val_rmse: 2.0533\n",
      "Epoch 25/10000\n",
      "230304/230304 [==============================] - 2s 10us/sample - loss: 0.1123 - mean_squared_error: 0.1123 - rmse: 0.3344 - val_loss: 4.2287 - val_mean_squared_error: 4.2287 - val_rmse: 2.0565\n",
      "Epoch 26/10000\n",
      "230304/230304 [==============================] - 2s 10us/sample - loss: 0.1187 - mean_squared_error: 0.1187 - rmse: 0.3441 - val_loss: 4.2823 - val_mean_squared_error: 4.2823 - val_rmse: 2.0695\n",
      "Epoch 27/10000\n",
      "230304/230304 [==============================] - 2s 11us/sample - loss: 0.1116 - mean_squared_error: 0.1116 - rmse: 0.3334 - val_loss: 4.2653 - val_mean_squared_error: 4.2653 - val_rmse: 2.0654\n",
      "Epoch 28/10000\n",
      "230304/230304 [==============================] - 3s 12us/sample - loss: 0.1093 - mean_squared_error: 0.1093 - rmse: 0.3303 - val_loss: 4.1856 - val_mean_squared_error: 4.1856 - val_rmse: 2.0460\n",
      "Epoch 29/10000\n",
      "230304/230304 [==============================] - 2s 10us/sample - loss: 0.1223 - mean_squared_error: 0.1223 - rmse: 0.3485 - val_loss: 4.1993 - val_mean_squared_error: 4.1993 - val_rmse: 2.0493\n",
      "Epoch 30/10000\n",
      "230304/230304 [==============================] - 2s 11us/sample - loss: 0.1301 - mean_squared_error: 0.1301 - rmse: 0.3605 - val_loss: 4.1535 - val_mean_squared_error: 4.1535 - val_rmse: 2.0381\n",
      "Epoch 31/10000\n",
      "230304/230304 [==============================] - 2s 10us/sample - loss: 0.1090 - mean_squared_error: 0.1090 - rmse: 0.3293 - val_loss: 4.2644 - val_mean_squared_error: 4.2644 - val_rmse: 2.0652\n",
      "Epoch 32/10000\n",
      "230304/230304 [==============================] - 2s 10us/sample - loss: 0.1030 - mean_squared_error: 0.1030 - rmse: 0.3208 - val_loss: 4.2436 - val_mean_squared_error: 4.2436 - val_rmse: 2.0602\n",
      "Epoch 33/10000\n",
      "230304/230304 [==============================] - 2s 11us/sample - loss: 0.0960 - mean_squared_error: 0.0960 - rmse: 0.3099 - val_loss: 4.1631 - val_mean_squared_error: 4.1631 - val_rmse: 2.0405\n",
      "Epoch 34/10000\n",
      "230304/230304 [==============================] - 2s 11us/sample - loss: 0.0873 - mean_squared_error: 0.0873 - rmse: 0.2952 - val_loss: 4.1426 - val_mean_squared_error: 4.1425 - val_rmse: 2.0354\n",
      "Epoch 35/10000\n",
      "230304/230304 [==============================] - 3s 11us/sample - loss: 0.0997 - mean_squared_error: 0.0997 - rmse: 0.3127 - val_loss: 4.2499 - val_mean_squared_error: 4.2499 - val_rmse: 2.0617\n",
      "Epoch 36/10000\n",
      "230304/230304 [==============================] - 2s 11us/sample - loss: 0.1239 - mean_squared_error: 0.1239 - rmse: 0.3520 - val_loss: 4.1845 - val_mean_squared_error: 4.1845 - val_rmse: 2.0457\n",
      "Epoch 37/10000\n",
      "230304/230304 [==============================] - 2s 11us/sample - loss: 0.1181 - mean_squared_error: 0.1181 - rmse: 0.3431 - val_loss: 4.1626 - val_mean_squared_error: 4.1626 - val_rmse: 2.0404\n",
      "Epoch 38/10000\n",
      "230304/230304 [==============================] - 2s 11us/sample - loss: 0.1056 - mean_squared_error: 0.1056 - rmse: 0.3245 - val_loss: 4.0932 - val_mean_squared_error: 4.0932 - val_rmse: 2.0233\n",
      "Epoch 39/10000\n",
      "230304/230304 [==============================] - 2s 11us/sample - loss: 0.0944 - mean_squared_error: 0.0944 - rmse: 0.3062 - val_loss: 4.0976 - val_mean_squared_error: 4.0976 - val_rmse: 2.0244\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 40/10000\n",
      "230304/230304 [==============================] - 2s 10us/sample - loss: 0.0966 - mean_squared_error: 0.0966 - rmse: 0.3099 - val_loss: 4.1752 - val_mean_squared_error: 4.1752 - val_rmse: 2.0434\n",
      "Epoch 41/10000\n",
      "230304/230304 [==============================] - 2s 10us/sample - loss: 0.0964 - mean_squared_error: 0.0964 - rmse: 0.3101 - val_loss: 4.2355 - val_mean_squared_error: 4.2355 - val_rmse: 2.0582\n",
      "Epoch 42/10000\n",
      "230304/230304 [==============================] - 2s 11us/sample - loss: 0.1035 - mean_squared_error: 0.1035 - rmse: 0.3199 - val_loss: 4.1792 - val_mean_squared_error: 4.1792 - val_rmse: 2.0444\n",
      "Epoch 43/10000\n",
      "230304/230304 [==============================] - 2s 10us/sample - loss: 0.1125 - mean_squared_error: 0.1125 - rmse: 0.3349 - val_loss: 4.1719 - val_mean_squared_error: 4.1719 - val_rmse: 2.0426\n",
      "Epoch 44/10000\n",
      "230304/230304 [==============================] - 2s 10us/sample - loss: 0.1078 - mean_squared_error: 0.1078 - rmse: 0.3272 - val_loss: 4.0514 - val_mean_squared_error: 4.0514 - val_rmse: 2.0129\n",
      "Epoch 45/10000\n",
      "230304/230304 [==============================] - 2s 10us/sample - loss: 0.1109 - mean_squared_error: 0.1109 - rmse: 0.3325 - val_loss: 4.1527 - val_mean_squared_error: 4.1527 - val_rmse: 2.0379\n",
      "Epoch 46/10000\n",
      "230304/230304 [==============================] - 2s 10us/sample - loss: 0.1172 - mean_squared_error: 0.1172 - rmse: 0.3399 - val_loss: 4.1516 - val_mean_squared_error: 4.1516 - val_rmse: 2.0377\n",
      "Epoch 47/10000\n",
      "230304/230304 [==============================] - 2s 10us/sample - loss: 0.1340 - mean_squared_error: 0.1340 - rmse: 0.3650 - val_loss: 4.1962 - val_mean_squared_error: 4.1962 - val_rmse: 2.0486\n",
      "Epoch 48/10000\n",
      "230304/230304 [==============================] - 2s 10us/sample - loss: 0.1132 - mean_squared_error: 0.1132 - rmse: 0.3357 - val_loss: 4.0491 - val_mean_squared_error: 4.0491 - val_rmse: 2.0124\n",
      "Epoch 49/10000\n",
      "230304/230304 [==============================] - 2s 10us/sample - loss: 0.0989 - mean_squared_error: 0.0989 - rmse: 0.3135 - val_loss: 3.9756 - val_mean_squared_error: 3.9756 - val_rmse: 1.9939\n",
      "Epoch 50/10000\n",
      "230304/230304 [==============================] - 2s 10us/sample - loss: 0.1117 - mean_squared_error: 0.1117 - rmse: 0.3319 - val_loss: 4.0583 - val_mean_squared_error: 4.0583 - val_rmse: 2.0146\n",
      "Epoch 51/10000\n",
      "230304/230304 [==============================] - 2s 10us/sample - loss: 0.1157 - mean_squared_error: 0.1157 - rmse: 0.3398 - val_loss: 4.0839 - val_mean_squared_error: 4.0839 - val_rmse: 2.0210\n",
      "Epoch 52/10000\n",
      "230304/230304 [==============================] - 3s 11us/sample - loss: 0.0876 - mean_squared_error: 0.0876 - rmse: 0.2956 - val_loss: 4.2639 - val_mean_squared_error: 4.2639 - val_rmse: 2.0651\n",
      "Epoch 53/10000\n",
      "230304/230304 [==============================] - 2s 10us/sample - loss: 0.1039 - mean_squared_error: 0.1039 - rmse: 0.3189 - val_loss: 4.0597 - val_mean_squared_error: 4.0597 - val_rmse: 2.0149\n",
      "Epoch 54/10000\n",
      "230304/230304 [==============================] - 2s 10us/sample - loss: 0.1107 - mean_squared_error: 0.1107 - rmse: 0.3317 - val_loss: 3.9434 - val_mean_squared_error: 3.9434 - val_rmse: 1.9858\n",
      "Epoch 55/10000\n",
      "230304/230304 [==============================] - 2s 10us/sample - loss: 0.0968 - mean_squared_error: 0.0968 - rmse: 0.3107 - val_loss: 3.9312 - val_mean_squared_error: 3.9312 - val_rmse: 1.9827\n",
      "Epoch 56/10000\n",
      "230304/230304 [==============================] - 2s 10us/sample - loss: 0.1032 - mean_squared_error: 0.1032 - rmse: 0.3194 - val_loss: 4.1243 - val_mean_squared_error: 4.1243 - val_rmse: 2.0309\n",
      "Epoch 57/10000\n",
      "230304/230304 [==============================] - 2s 10us/sample - loss: 0.1115 - mean_squared_error: 0.1115 - rmse: 0.3328 - val_loss: 4.1321 - val_mean_squared_error: 4.1321 - val_rmse: 2.0329\n",
      "Epoch 58/10000\n",
      "230304/230304 [==============================] - 2s 10us/sample - loss: 0.1166 - mean_squared_error: 0.1166 - rmse: 0.3392 - val_loss: 4.0983 - val_mean_squared_error: 4.0983 - val_rmse: 2.0245\n",
      "Epoch 59/10000\n",
      "230304/230304 [==============================] - 2s 11us/sample - loss: 0.1339 - mean_squared_error: 0.1339 - rmse: 0.3614 - val_loss: 3.9891 - val_mean_squared_error: 3.9891 - val_rmse: 1.9974\n",
      "Epoch 60/10000\n",
      "230304/230304 [==============================] - 2s 11us/sample - loss: 0.1279 - mean_squared_error: 0.1279 - rmse: 0.3582 - val_loss: 3.7958 - val_mean_squared_error: 3.7958 - val_rmse: 1.9483\n",
      "Epoch 61/10000\n",
      "230304/230304 [==============================] - 2s 10us/sample - loss: 0.1077 - mean_squared_error: 0.1077 - rmse: 0.3267 - val_loss: 4.0719 - val_mean_squared_error: 4.0719 - val_rmse: 2.0180\n",
      "Epoch 62/10000\n",
      "230304/230304 [==============================] - 3s 11us/sample - loss: 0.1048 - mean_squared_error: 0.1048 - rmse: 0.3233 - val_loss: 3.9693 - val_mean_squared_error: 3.9693 - val_rmse: 1.9924\n",
      "Epoch 63/10000\n",
      "230304/230304 [==============================] - 2s 10us/sample - loss: 0.0907 - mean_squared_error: 0.0907 - rmse: 0.2994 - val_loss: 3.9409 - val_mean_squared_error: 3.9409 - val_rmse: 1.9852\n",
      "Epoch 64/10000\n",
      "230304/230304 [==============================] - 3s 11us/sample - loss: 0.1049 - mean_squared_error: 0.1049 - rmse: 0.3204 - val_loss: 3.9747 - val_mean_squared_error: 3.9747 - val_rmse: 1.9937\n",
      "Epoch 65/10000\n",
      "230304/230304 [==============================] - 2s 10us/sample - loss: 0.1119 - mean_squared_error: 0.1119 - rmse: 0.3335 - val_loss: 4.4178 - val_mean_squared_error: 4.4178 - val_rmse: 2.1021\n",
      "Epoch 66/10000\n",
      "230304/230304 [==============================] - 2s 10us/sample - loss: 0.1313 - mean_squared_error: 0.1313 - rmse: 0.3568 - val_loss: 3.9802 - val_mean_squared_error: 3.9802 - val_rmse: 1.9951\n",
      "Epoch 67/10000\n",
      "230304/230304 [==============================] - 2s 10us/sample - loss: 0.1312 - mean_squared_error: 0.1312 - rmse: 0.3614 - val_loss: 4.0589 - val_mean_squared_error: 4.0589 - val_rmse: 2.0148\n",
      "Epoch 68/10000\n",
      "230304/230304 [==============================] - 2s 10us/sample - loss: 0.1131 - mean_squared_error: 0.1131 - rmse: 0.3337 - val_loss: 4.1587 - val_mean_squared_error: 4.1587 - val_rmse: 2.0394\n",
      "Epoch 69/10000\n",
      "230304/230304 [==============================] - 2s 11us/sample - loss: 0.1179 - mean_squared_error: 0.1179 - rmse: 0.3422 - val_loss: 4.0540 - val_mean_squared_error: 4.0540 - val_rmse: 2.0135\n",
      "Epoch 70/10000\n",
      "230304/230304 [==============================] - 2s 10us/sample - loss: 0.1043 - mean_squared_error: 0.1043 - rmse: 0.3213 - val_loss: 3.9708 - val_mean_squared_error: 3.9708 - val_rmse: 1.9927\n",
      "Epoch 00070: early stopping\n"
     ]
    }
   ],
   "source": [
    "# model config\n",
    "BATCH_SIZE = 4096\n",
    "EPOCHS = 10000\n",
    "VAL_SPLIT = 0.25\n",
    "\n",
    "# train model\n",
    "history = train_model(\n",
    "    GMF_model,\n",
    "    tf.keras.optimizers.Adam(0.1),\n",
    "    BATCH_SIZE,\n",
    "    EPOCHS,\n",
    "    VAL_SPLIT,\n",
    "    inputs=[train.uid.values, train.bid.values],\n",
    "    outputs=train.rating.values,\n",
    "    filepath='model/neural-gmf-weights.hdf5')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 84,
   "metadata": {},
   "outputs": [],
   "source": [
    "def plot_learning_curve(history, metric):\n",
    "    \"\"\"\n",
    "    Plot learning curve to compare training error vs. validation error\n",
    "    \"\"\"\n",
    "    # get training error\n",
    "    errors = history.history[metric]\n",
    "    \n",
    "    # get validation error\n",
    "    val_errors = history.history['val_{}'.format(metric)]\n",
    "    \n",
    "    # get epochs\n",
    "    epochs = range(1, len(errors) + 1)\n",
    "\n",
    "    # plot\n",
    "    plt.figure(figsize=(12, 7))\n",
    "    plt.plot(epochs, errors, 'bo', label='training {}'.format(metric))\n",
    "    plt.plot(epochs, val_errors, 'b', label='validation {}'.format(metric))\n",
    "    plt.xlabel('number of epochs')\n",
    "    plt.ylabel(metric)\n",
    "    plt.title('Model Learning Curve')\n",
    "    plt.grid(True)\n",
    "    plt.legend()\n",
    "    plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 85,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 864x504 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "plot_learning_curve(history, 'rmse')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### GMF model testing"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 86,
   "metadata": {},
   "outputs": [],
   "source": [
    "# define rmse function\n",
    "rmse = lambda true, pred: np.sqrt(np.mean(np.square(np.squeeze(predictions) - np.squeeze(test.rating.values))))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 87,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The out-of-sample RMSE of rating predictions is 1.9443\n"
     ]
    }
   ],
   "source": [
    "# load best model\n",
    "GMF_model = get_GMF_model(user_max_id, book_max_id, 10, 0, 0)\n",
    "GMF_model = load_trained_model(GMF_model, 'model/neural-gmf-weights.hdf5')\n",
    "\n",
    "# make prediction using test data\n",
    "predictions = GMF_model.predict([test.uid.values, test.bid.values])\n",
    "\n",
    "# get the RMSE\n",
    "error = rmse(test.rating.values, predictions)\n",
    "print('The out-of-sample RMSE of rating predictions is', round(error, 4))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Train Multi-Layer Perceptron Model and Test Model"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### define MLP model architeture"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 88,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_MLP_model(num_users, num_items, layers, reg_layers):\n",
    "    \"\"\"\n",
    "    Build Multi-Layer Perceptron Model Topology\n",
    "    \n",
    "    Parameters\n",
    "    ----------\n",
    "    num_users: int, total number of users\n",
    "    num_iterms: int, total number of items\n",
    "    layers: list of int, each element is the number of hidden units for each layer,\n",
    "        with the exception of first element. First element is the sum of dims of\n",
    "        user latent vector and item latent vector\n",
    "    reg_layers: list of int, each element is the L2 regularization parameter for\n",
    "        each layer in MLP\n",
    "\n",
    "    Return\n",
    "    ------\n",
    "    A Keras Model with MLP model architeture\n",
    "    \"\"\"\n",
    "    assert len(layers) == len(reg_layers)\n",
    "    num_layer = len(layers) # Number of layers in the MLP\n",
    "    \n",
    "    # Input variables\n",
    "    user_input = Input(shape=(1,), dtype='int32', name='user_input')\n",
    "    item_input = Input(shape=(1,), dtype='int32', name='item_input')\n",
    "\n",
    "    mlp_embedding_user = Embedding(\n",
    "        input_dim=num_users + 1,\n",
    "        output_dim=layers[0] // 2,\n",
    "        embeddings_initializer='uniform',\n",
    "        name='user_embedding',\n",
    "        embeddings_regularizer=l2(reg_layers[0]),\n",
    "        input_length=1)\n",
    "    \n",
    "    mlp_embedding_item = Embedding(\n",
    "        input_dim=num_items + 1,\n",
    "        output_dim=layers[0] // 2,\n",
    "        embeddings_initializer='uniform',\n",
    "        name='item_embedding',\n",
    "        embeddings_regularizer=l2(reg_layers[0]),\n",
    "        input_length=1) \n",
    "    \n",
    "    # Crucial to flatten an embedding vector!\n",
    "    user_latent = Flatten()(mlp_embedding_user(user_input))\n",
    "    item_latent = Flatten()(mlp_embedding_item(item_input))\n",
    "\n",
    "    # The 0-th layer is the concatenation of embedding layers\n",
    "    vector = Concatenate(axis=-1)([user_latent, item_latent])\n",
    "\n",
    "    # MLP layers\n",
    "    for idx in range(1, num_layer):\n",
    "        layer = Dense(\n",
    "            units=layers[idx],\n",
    "            activation='relu',\n",
    "            kernel_initializer='glorot_uniform',\n",
    "            kernel_regularizer=l2(reg_layers[idx]),\n",
    "            name = 'layer%d' %idx)\n",
    "        vector = layer(vector)\n",
    "    \n",
    "    # Final prediction layer\n",
    "    prediction = Dense(1, kernel_initializer='glorot_uniform', name='prediction')(vector)\n",
    "    \n",
    "    # Stitch input and output\n",
    "    model = Model([user_input, item_input], prediction)\n",
    "    \n",
    "    return model"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### create MLP model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 89,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"model_13\"\n",
      "__________________________________________________________________________________________________\n",
      "Layer (type)                    Output Shape         Param #     Connected to                     \n",
      "==================================================================================================\n",
      "user_input (InputLayer)         [(None, 1)]          0                                            \n",
      "__________________________________________________________________________________________________\n",
      "item_input (InputLayer)         [(None, 1)]          0                                            \n",
      "__________________________________________________________________________________________________\n",
      "user_embedding (Embedding)      (None, 1, 32)        8923456     user_input[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "item_embedding (Embedding)      (None, 1, 32)        8683520     item_input[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "flatten_34 (Flatten)            (None, 32)           0           user_embedding[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "flatten_35 (Flatten)            (None, 32)           0           item_embedding[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "concatenate_13 (Concatenate)    (None, 64)           0           flatten_34[0][0]                 \n",
      "                                                                 flatten_35[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "layer1 (Dense)                  (None, 32)           2080        concatenate_13[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "layer2 (Dense)                  (None, 16)           528         layer1[0][0]                     \n",
      "__________________________________________________________________________________________________\n",
      "layer3 (Dense)                  (None, 8)            136         layer2[0][0]                     \n",
      "__________________________________________________________________________________________________\n",
      "prediction (Dense)              (None, 1)            9           layer3[0][0]                     \n",
      "==================================================================================================\n",
      "Total params: 17,609,729\n",
      "Trainable params: 17,609,729\n",
      "Non-trainable params: 0\n",
      "__________________________________________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "MLP_model = get_MLP_model(user_max_id, book_max_id, [64, 32, 16, 8], [0, 0, 0, 0])\n",
    "MLP_model.summary()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### train MLP model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 90,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train on 230304 samples, validate on 76769 samples\n",
      "Epoch 1/10000\n",
      "230304/230304 [==============================] - 8s 36us/sample - loss: 6.0629 - mean_squared_error: 6.0629 - rmse: 2.1930 - val_loss: 2.8667 - val_mean_squared_error: 2.8667 - val_rmse: 1.6928\n",
      "Epoch 2/10000\n",
      "230304/230304 [==============================] - 8s 35us/sample - loss: 1.9785 - mean_squared_error: 1.9785 - rmse: 1.4060 - val_loss: 2.9245 - val_mean_squared_error: 2.9245 - val_rmse: 1.7100\n",
      "Epoch 3/10000\n",
      "230304/230304 [==============================] - 8s 34us/sample - loss: 1.3093 - mean_squared_error: 1.3093 - rmse: 1.1437 - val_loss: 2.9438 - val_mean_squared_error: 2.9438 - val_rmse: 1.7155\n",
      "Epoch 4/10000\n",
      "230304/230304 [==============================] - 8s 33us/sample - loss: 0.9902 - mean_squared_error: 0.9902 - rmse: 0.9949 - val_loss: 3.0902 - val_mean_squared_error: 3.0902 - val_rmse: 1.7579\n",
      "Epoch 5/10000\n",
      "230304/230304 [==============================] - 8s 34us/sample - loss: 0.8236 - mean_squared_error: 0.8236 - rmse: 0.9079 - val_loss: 3.1758 - val_mean_squared_error: 3.1758 - val_rmse: 1.7819\n",
      "Epoch 6/10000\n",
      "230304/230304 [==============================] - 8s 33us/sample - loss: 0.7264 - mean_squared_error: 0.7264 - rmse: 0.8513 - val_loss: 3.1459 - val_mean_squared_error: 3.1459 - val_rmse: 1.7736\n",
      "Epoch 7/10000\n",
      "230304/230304 [==============================] - 8s 34us/sample - loss: 0.6822 - mean_squared_error: 0.6822 - rmse: 0.8245 - val_loss: 3.1682 - val_mean_squared_error: 3.1682 - val_rmse: 1.7798\n",
      "Epoch 8/10000\n",
      "230304/230304 [==============================] - 8s 34us/sample - loss: 0.5902 - mean_squared_error: 0.5902 - rmse: 0.7681 - val_loss: 3.1333 - val_mean_squared_error: 3.1333 - val_rmse: 1.7699\n",
      "Epoch 9/10000\n",
      "230304/230304 [==============================] - 8s 33us/sample - loss: 0.5338 - mean_squared_error: 0.5338 - rmse: 0.7299 - val_loss: 3.1953 - val_mean_squared_error: 3.1953 - val_rmse: 1.7873\n",
      "Epoch 10/10000\n",
      "230304/230304 [==============================] - 8s 34us/sample - loss: 0.5189 - mean_squared_error: 0.5189 - rmse: 0.7194 - val_loss: 3.2044 - val_mean_squared_error: 3.2044 - val_rmse: 1.7899\n",
      "Epoch 11/10000\n",
      "230304/230304 [==============================] - 8s 34us/sample - loss: 0.4931 - mean_squared_error: 0.4931 - rmse: 0.6993 - val_loss: 3.5829 - val_mean_squared_error: 3.5829 - val_rmse: 1.8927\n",
      "Epoch 00011: early stopping\n"
     ]
    }
   ],
   "source": [
    "# model config\n",
    "BATCH_SIZE = 4096\n",
    "EPOCHS = 10000\n",
    "VAL_SPLIT = 0.25\n",
    "\n",
    "# train model\n",
    "history = train_model(\n",
    "    MLP_model,\n",
    "    tf.keras.optimizers.Adam(0.1),\n",
    "    BATCH_SIZE,\n",
    "    EPOCHS,\n",
    "    VAL_SPLIT,\n",
    "    inputs=[train.uid.values, train.bid.values],\n",
    "    outputs=train.rating.values,\n",
    "    filepath='model/neural-mlp-weights.hdf5')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### MLP learning curve"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 91,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 864x504 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "plot_learning_curve(history, 'rmse')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### MLP model testing"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### And finally, make a prediction and check the testing error using out-of-sample data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 92,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The out-of-sample RMSE of rating predictions is 1.684\n"
     ]
    }
   ],
   "source": [
    "# load best model\n",
    "MLP_model = get_MLP_model(user_max_id, book_max_id, [64, 32, 16, 8], [0, 0, 0, 0])\n",
    "MLP_model = load_trained_model(MLP_model, 'model/neural-mlp-weights.hdf5')\n",
    "\n",
    "# make prediction using test data\n",
    "predictions = MLP_model.predict([test.uid.values, test.bid.values])\n",
    "\n",
    "# get the RMSE\n",
    "error = rmse(test.rating.values, predictions)\n",
    "print('The out-of-sample RMSE of rating predictions is', round(error, 4))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Train Neural Matrix Factorization (NeuralMF) and Test Model"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### define NeuralMF model architeture"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 93,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_NeuralMF_model(num_users, num_items, MF_dim, MF_reg, MLP_layers, MLP_regs):\n",
    "    \"\"\"\n",
    "    Build Neural Matrix Factorization (NeuralMF) Model Topology.\n",
    "    This is stack version of both GMF and MLP\n",
    "    \n",
    "    Parameters\n",
    "    ----------\n",
    "    num_users: int, total number of users\n",
    "    num_iterms: int, total number of items\n",
    "    MF_dim: int, embedded dimension for user vector and item vector in MF\n",
    "    MF_reg: tuple of float, L2 regularization of MF embedded layer\n",
    "    MLP_layers: list of int, each element is the number of hidden units for each MLP layer,\n",
    "        with the exception of first element. First element is the sum of dims of\n",
    "        user latent vector and item latent vector\n",
    "    MLP_regs: list of int, each element is the L2 regularization parameter for\n",
    "        each layer in MLP\n",
    "\n",
    "    Return\n",
    "    ------\n",
    "    A Keras Model with MLP model architeture\n",
    "    \"\"\"\n",
    "    assert len(MLP_layers) == len(MLP_regs)\n",
    "    num_MLP_layer = len(MLP_layers) # Number of layers in the MLP\n",
    "    \n",
    "    # Input variables\n",
    "    user_input = Input(shape=(1,), dtype='int32', name='user_input')\n",
    "    item_input = Input(shape=(1,), dtype='int32', name='item_input')\n",
    "\n",
    "    # MF Embedding layer\n",
    "    mf_embedding_user = Embedding(\n",
    "        input_dim=num_users + 1,\n",
    "        output_dim=MF_dim,\n",
    "        embeddings_initializer='uniform',\n",
    "        name='mf_user_embedding',\n",
    "        embeddings_regularizer=l2(MF_reg[0]),\n",
    "        input_length=1)\n",
    "    \n",
    "    mf_embedding_item = Embedding(\n",
    "        input_dim=num_items + 1,\n",
    "        output_dim=MF_dim,\n",
    "        embeddings_initializer='uniform',\n",
    "        name='mf_item_embedding',\n",
    "        embeddings_regularizer=l2(MF_reg[1]),\n",
    "        input_length=1)\n",
    "    \n",
    "    # MLP\n",
    "    mlp_embedding_user = Embedding(\n",
    "        input_dim=num_users + 1,\n",
    "        output_dim=MLP_layers[0] // 2,\n",
    "        embeddings_initializer='uniform',\n",
    "        name='mlp_user_embedding',\n",
    "        embeddings_regularizer=l2(MLP_regs[0]),\n",
    "        input_length=1)\n",
    "    \n",
    "    mlp_embedding_Item = Embedding(\n",
    "        input_dim=num_items + 1,\n",
    "        output_dim=MLP_layers[0] // 2,\n",
    "        embeddings_initializer='uniform',\n",
    "        name='mlp_item_embedding',\n",
    "        embeddings_regularizer=l2(MLP_regs[0]),\n",
    "        input_length=1) \n",
    "    \n",
    "    # MF part\n",
    "    mf_user_latent = Flatten()(mf_embedding_user(user_input))\n",
    "    mf_item_latent = Flatten()(mf_embedding_item(item_input))\n",
    "    mf_vector = Multiply()([mf_user_latent, mf_item_latent])\n",
    "\n",
    "    # MLP part\n",
    "    mlp_user_latent = Flatten()(mlp_embedding_user(user_input))\n",
    "    mlp_item_latent = Flatten()(mlp_embedding_Item(item_input))\n",
    "    mlp_vector = Concatenate(axis=-1)([mlp_user_latent, mlp_item_latent])\n",
    "\n",
    "    for idx in range(1, num_MLP_layer):\n",
    "        layer = Dense(\n",
    "            units=MLP_layers[idx],\n",
    "            activation='relu',\n",
    "            kernel_initializer='glorot_uniform',\n",
    "            kernel_regularizer=l2(MLP_regs[idx]),\n",
    "            name = 'layer%d' %idx)\n",
    "        mlp_vector = layer(mlp_vector)\n",
    "    \n",
    "    # Concatenate MF and MLP parts\n",
    "    predict_vector = Concatenate(axis=-1)([mf_vector, mlp_vector])\n",
    "\n",
    "    # Final prediction layer\n",
    "    prediction = Dense(1, kernel_initializer='glorot_uniform', name='prediction')(predict_vector)\n",
    "    \n",
    "    # Stitch input and output\n",
    "    model = Model([user_input, item_input], prediction)\n",
    "    \n",
    "    return model"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### create NeuralMF model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 94,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"model_15\"\n",
      "__________________________________________________________________________________________________\n",
      "Layer (type)                    Output Shape         Param #     Connected to                     \n",
      "==================================================================================================\n",
      "user_input (InputLayer)         [(None, 1)]          0                                            \n",
      "__________________________________________________________________________________________________\n",
      "item_input (InputLayer)         [(None, 1)]          0                                            \n",
      "__________________________________________________________________________________________________\n",
      "mlp_user_embedding (Embedding)  (None, 1, 32)        8923456     user_input[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "mlp_item_embedding (Embedding)  (None, 1, 32)        8683520     item_input[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "flatten_40 (Flatten)            (None, 32)           0           mlp_user_embedding[0][0]         \n",
      "__________________________________________________________________________________________________\n",
      "flatten_41 (Flatten)            (None, 32)           0           mlp_item_embedding[0][0]         \n",
      "__________________________________________________________________________________________________\n",
      "concatenate_15 (Concatenate)    (None, 64)           0           flatten_40[0][0]                 \n",
      "                                                                 flatten_41[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "mf_user_embedding (Embedding)   (None, 1, 10)        2788580     user_input[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "mf_item_embedding (Embedding)   (None, 1, 10)        2713600     item_input[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "layer1 (Dense)                  (None, 32)           2080        concatenate_15[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "flatten_38 (Flatten)            (None, 10)           0           mf_user_embedding[0][0]          \n",
      "__________________________________________________________________________________________________\n",
      "flatten_39 (Flatten)            (None, 10)           0           mf_item_embedding[0][0]          \n",
      "__________________________________________________________________________________________________\n",
      "layer2 (Dense)                  (None, 16)           528         layer1[0][0]                     \n",
      "__________________________________________________________________________________________________\n",
      "multiply_8 (Multiply)           (None, 10)           0           flatten_38[0][0]                 \n",
      "                                                                 flatten_39[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "layer3 (Dense)                  (None, 8)            136         layer2[0][0]                     \n",
      "__________________________________________________________________________________________________\n",
      "concatenate_16 (Concatenate)    (None, 18)           0           multiply_8[0][0]                 \n",
      "                                                                 layer3[0][0]                     \n",
      "__________________________________________________________________________________________________\n",
      "prediction (Dense)              (None, 1)            19          concatenate_16[0][0]             \n",
      "==================================================================================================\n",
      "Total params: 23,111,919\n",
      "Trainable params: 23,111,919\n",
      "Non-trainable params: 0\n",
      "__________________________________________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "NeuralMF_model = get_NeuralMF_model(\n",
    "    num_users=user_max_id,\n",
    "    num_items=book_max_id,\n",
    "    MF_dim=10,\n",
    "    MF_reg=(0, 0),\n",
    "    MLP_layers=[64, 32, 16, 8],\n",
    "    MLP_regs=[0, 0, 0, 0])\n",
    "NeuralMF_model.summary()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### train NeuralMF model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 95,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train on 230304 samples, validate on 76769 samples\n",
      "Epoch 1/100000\n",
      "230304/230304 [==============================] - 10s 45us/sample - loss: 11.4757 - mean_squared_error: 11.4757 - rmse: 2.9196 - val_loss: 2.9213 - val_mean_squared_error: 2.9213 - val_rmse: 1.7086\n",
      "Epoch 2/100000\n",
      "230304/230304 [==============================] - 10s 42us/sample - loss: 2.0950 - mean_squared_error: 2.0950 - rmse: 1.4474 - val_loss: 3.0419 - val_mean_squared_error: 3.0419 - val_rmse: 1.7437\n",
      "Epoch 3/100000\n",
      "230304/230304 [==============================] - 11s 49us/sample - loss: 1.0724 - mean_squared_error: 1.0724 - rmse: 1.0361 - val_loss: 3.0557 - val_mean_squared_error: 3.0557 - val_rmse: 1.7477\n",
      "Epoch 4/100000\n",
      "230304/230304 [==============================] - 11s 50us/sample - loss: 0.6946 - mean_squared_error: 0.6946 - rmse: 0.8327 - val_loss: 3.1831 - val_mean_squared_error: 3.1831 - val_rmse: 1.7836\n",
      "Epoch 5/100000\n",
      "230304/230304 [==============================] - 11s 46us/sample - loss: 0.5206 - mean_squared_error: 0.5206 - rmse: 0.7211 - val_loss: 3.1146 - val_mean_squared_error: 3.1146 - val_rmse: 1.7643\n",
      "Epoch 6/100000\n",
      "230304/230304 [==============================] - 10s 42us/sample - loss: 0.4041 - mean_squared_error: 0.4041 - rmse: 0.6357 - val_loss: 3.1935 - val_mean_squared_error: 3.1935 - val_rmse: 1.7866\n",
      "Epoch 7/100000\n",
      "230304/230304 [==============================] - 10s 42us/sample - loss: 0.3205 - mean_squared_error: 0.3205 - rmse: 0.5658 - val_loss: 3.1323 - val_mean_squared_error: 3.1323 - val_rmse: 1.7693\n",
      "Epoch 8/100000\n",
      "230304/230304 [==============================] - 10s 42us/sample - loss: 0.2629 - mean_squared_error: 0.2629 - rmse: 0.5127 - val_loss: 3.1768 - val_mean_squared_error: 3.1768 - val_rmse: 1.7819\n",
      "Epoch 9/100000\n",
      "230304/230304 [==============================] - 10s 42us/sample - loss: 0.2153 - mean_squared_error: 0.2153 - rmse: 0.4639 - val_loss: 3.1672 - val_mean_squared_error: 3.1672 - val_rmse: 1.7792\n",
      "Epoch 10/100000\n",
      "230304/230304 [==============================] - 10s 44us/sample - loss: 0.1915 - mean_squared_error: 0.1915 - rmse: 0.4375 - val_loss: 3.2150 - val_mean_squared_error: 3.2150 - val_rmse: 1.7925\n",
      "Epoch 11/100000\n",
      "230304/230304 [==============================] - 10s 43us/sample - loss: 0.1734 - mean_squared_error: 0.1734 - rmse: 0.4165 - val_loss: 3.2581 - val_mean_squared_error: 3.2581 - val_rmse: 1.8047\n",
      "Epoch 00011: early stopping\n"
     ]
    }
   ],
   "source": [
    "# model config\n",
    "BATCH_SIZE = 4096\n",
    "EPOCHS = 100000\n",
    "VAL_SPLIT = 0.25\n",
    "\n",
    "# train model\n",
    "history = train_model(\n",
    "    NeuralMF_model,\n",
    "    tf.keras.optimizers.Adam(0.1),\n",
    "    BATCH_SIZE,\n",
    "    EPOCHS,\n",
    "    VAL_SPLIT,\n",
    "    inputs=[train.uid.values, train.bid.values],\n",
    "    outputs=train.rating.values,\n",
    "    filepath='model/neural-nmf-weights.hdf5')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### Neural Matrix Factorization (NeuralMF) learning curve"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 96,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 864x504 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "plot_learning_curve(history, 'rmse')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### Neural Matrix Factorization (NeuralMF) model testing"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### And finally, make a prediction and check the testing error using out-of-sample data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 97,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The out-of-sample RMSE of rating predictions is 1.7018\n"
     ]
    }
   ],
   "source": [
    "# load best model\n",
    "NeuralMF_model = get_NeuralMF_model(\n",
    "    num_users=user_max_id,\n",
    "    num_items=book_max_id,\n",
    "    MF_dim=10,\n",
    "    MF_reg=(0, 0),\n",
    "    MLP_layers=[64, 32, 16, 8],\n",
    "    MLP_regs=[0, 0, 0, 0])\n",
    "NeuralMF_model = load_trained_model(NeuralMF_model, 'model/neural-nmf-weights.hdf5')\n",
    "\n",
    "# make prediction using test data\n",
    "predictions = NeuralMF_model.predict([test.uid.values, test.bid.values])\n",
    "\n",
    "# get the RMSE\n",
    "error = rmse(test.rating.values, predictions)\n",
    "print('The out-of-sample RMSE of rating predictions is', round(error, 4))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### Recommendation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 98,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>user_id</th>\n",
       "      <th>isbn</th>\n",
       "      <th>rating</th>\n",
       "      <th>bid</th>\n",
       "      <th>title</th>\n",
       "      <th>author</th>\n",
       "      <th>year_of_publication</th>\n",
       "      <th>publisher</th>\n",
       "      <th>uid</th>\n",
       "      <th>location</th>\n",
       "      <th>age</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>276726</td>\n",
       "      <td>0155061224</td>\n",
       "      <td>5</td>\n",
       "      <td>225816</td>\n",
       "      <td>Rites of Passage</td>\n",
       "      <td>Judith Rae</td>\n",
       "      <td>2001</td>\n",
       "      <td>Heinle</td>\n",
       "      <td>276725</td>\n",
       "      <td>seattle, washington, usa</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>276729</td>\n",
       "      <td>052165615X</td>\n",
       "      <td>3</td>\n",
       "      <td>246838</td>\n",
       "      <td>Help!: Level 1</td>\n",
       "      <td>Philip Prowse</td>\n",
       "      <td>1999</td>\n",
       "      <td>Cambridge University Press</td>\n",
       "      <td>276728</td>\n",
       "      <td>rijeka, n/a, croatia</td>\n",
       "      <td>16.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>276729</td>\n",
       "      <td>0521795028</td>\n",
       "      <td>6</td>\n",
       "      <td>246839</td>\n",
       "      <td>The Amsterdam Connection : Level 4 (Cambridge ...</td>\n",
       "      <td>Sue Leather</td>\n",
       "      <td>2001</td>\n",
       "      <td>Cambridge University Press</td>\n",
       "      <td>276728</td>\n",
       "      <td>rijeka, n/a, croatia</td>\n",
       "      <td>16.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>276744</td>\n",
       "      <td>038550120X</td>\n",
       "      <td>7</td>\n",
       "      <td>9294</td>\n",
       "      <td>A Painted House</td>\n",
       "      <td>JOHN GRISHAM</td>\n",
       "      <td>2001</td>\n",
       "      <td>Doubleday</td>\n",
       "      <td>276743</td>\n",
       "      <td>torrance, california, usa</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>12</th>\n",
       "      <td>276747</td>\n",
       "      <td>0060517794</td>\n",
       "      <td>9</td>\n",
       "      <td>4779</td>\n",
       "      <td>Little Altars Everywhere</td>\n",
       "      <td>Rebecca Wells</td>\n",
       "      <td>2003</td>\n",
       "      <td>HarperTorch</td>\n",
       "      <td>276746</td>\n",
       "      <td>iowa city, iowa, usa</td>\n",
       "      <td>25.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1031126</th>\n",
       "      <td>276704</td>\n",
       "      <td>0743211383</td>\n",
       "      <td>7</td>\n",
       "      <td>881</td>\n",
       "      <td>Dreamcatcher</td>\n",
       "      <td>Stephen King</td>\n",
       "      <td>2001</td>\n",
       "      <td>Scribner</td>\n",
       "      <td>276703</td>\n",
       "      <td>cedar park, texas, usa</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1031128</th>\n",
       "      <td>276704</td>\n",
       "      <td>0806917695</td>\n",
       "      <td>5</td>\n",
       "      <td>69541</td>\n",
       "      <td>Perplexing Lateral Thinking Puzzles: Scholasti...</td>\n",
       "      <td>Paul Sloane</td>\n",
       "      <td>1997</td>\n",
       "      <td>Sterling Publishing</td>\n",
       "      <td>276703</td>\n",
       "      <td>cedar park, texas, usa</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1031130</th>\n",
       "      <td>276704</td>\n",
       "      <td>1563526298</td>\n",
       "      <td>9</td>\n",
       "      <td>69544</td>\n",
       "      <td>Get Clark Smart : The Ultimate Guide for the S...</td>\n",
       "      <td>Clark Howard</td>\n",
       "      <td>2000</td>\n",
       "      <td>Longstreet Press</td>\n",
       "      <td>276703</td>\n",
       "      <td>cedar park, texas, usa</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1031132</th>\n",
       "      <td>276709</td>\n",
       "      <td>0515107662</td>\n",
       "      <td>10</td>\n",
       "      <td>15978</td>\n",
       "      <td>The Sherbrooke Bride (Bride Trilogy (Paperback))</td>\n",
       "      <td>Catherine Coulter</td>\n",
       "      <td>1996</td>\n",
       "      <td>Jove Books</td>\n",
       "      <td>276708</td>\n",
       "      <td>mannington, west virginia, usa</td>\n",
       "      <td>38.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1031133</th>\n",
       "      <td>276721</td>\n",
       "      <td>0590442449</td>\n",
       "      <td>10</td>\n",
       "      <td>56814</td>\n",
       "      <td>Fourth Grade Rats</td>\n",
       "      <td>Jerry Spinelli</td>\n",
       "      <td>1996</td>\n",
       "      <td>Scholastic</td>\n",
       "      <td>276720</td>\n",
       "      <td>providence, rhode island, usa</td>\n",
       "      <td>14.0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>383842 rows Ã— 11 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "         user_id        isbn  rating     bid  \\\n",
       "0         276726  0155061224       5  225816   \n",
       "2         276729  052165615X       3  246838   \n",
       "3         276729  0521795028       6  246839   \n",
       "5         276744  038550120X       7    9294   \n",
       "12        276747  0060517794       9    4779   \n",
       "...          ...         ...     ...     ...   \n",
       "1031126   276704  0743211383       7     881   \n",
       "1031128   276704  0806917695       5   69541   \n",
       "1031130   276704  1563526298       9   69544   \n",
       "1031132   276709  0515107662      10   15978   \n",
       "1031133   276721  0590442449      10   56814   \n",
       "\n",
       "                                                     title             author  \\\n",
       "0                                         Rites of Passage         Judith Rae   \n",
       "2                                           Help!: Level 1      Philip Prowse   \n",
       "3        The Amsterdam Connection : Level 4 (Cambridge ...        Sue Leather   \n",
       "5                                          A Painted House       JOHN GRISHAM   \n",
       "12                                Little Altars Everywhere      Rebecca Wells   \n",
       "...                                                    ...                ...   \n",
       "1031126                                       Dreamcatcher       Stephen King   \n",
       "1031128  Perplexing Lateral Thinking Puzzles: Scholasti...        Paul Sloane   \n",
       "1031130  Get Clark Smart : The Ultimate Guide for the S...       Clark Howard   \n",
       "1031132   The Sherbrooke Bride (Bride Trilogy (Paperback))  Catherine Coulter   \n",
       "1031133                                  Fourth Grade Rats     Jerry Spinelli   \n",
       "\n",
       "        year_of_publication                   publisher     uid  \\\n",
       "0                      2001                      Heinle  276725   \n",
       "2                      1999  Cambridge University Press  276728   \n",
       "3                      2001  Cambridge University Press  276728   \n",
       "5                      2001                   Doubleday  276743   \n",
       "12                     2003                 HarperTorch  276746   \n",
       "...                     ...                         ...     ...   \n",
       "1031126                2001                    Scribner  276703   \n",
       "1031128                1997         Sterling Publishing  276703   \n",
       "1031130                2000            Longstreet Press  276703   \n",
       "1031132                1996                  Jove Books  276708   \n",
       "1031133                1996                  Scholastic  276720   \n",
       "\n",
       "                               location   age  \n",
       "0              seattle, washington, usa   NaN  \n",
       "2                  rijeka, n/a, croatia  16.0  \n",
       "3                  rijeka, n/a, croatia  16.0  \n",
       "5             torrance, california, usa   NaN  \n",
       "12                 iowa city, iowa, usa  25.0  \n",
       "...                                 ...   ...  \n",
       "1031126          cedar park, texas, usa   NaN  \n",
       "1031128          cedar park, texas, usa   NaN  \n",
       "1031130          cedar park, texas, usa   NaN  \n",
       "1031132  mannington, west virginia, usa  38.0  \n",
       "1031133   providence, rhode island, usa  14.0  \n",
       "\n",
       "[383842 rows x 11 columns]"
      ]
     },
     "execution_count": 98,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Creating dataset for making recommendations for the user\n",
    "uid = 439\n",
    "books_data = np.array(list(set(ratings_clean_2.bid)))\n",
    "users_data = np.array([uid for i in range(len(books_data))])\n",
    "ratings_clean_2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 99,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>user_id</th>\n",
       "      <th>isbn</th>\n",
       "      <th>rating</th>\n",
       "      <th>bid</th>\n",
       "      <th>title</th>\n",
       "      <th>author</th>\n",
       "      <th>year_of_publication</th>\n",
       "      <th>publisher</th>\n",
       "      <th>uid</th>\n",
       "      <th>location</th>\n",
       "      <th>age</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>9253</th>\n",
       "      <td>440</td>\n",
       "      <td>0743424425</td>\n",
       "      <td>10</td>\n",
       "      <td>502</td>\n",
       "      <td>The Shining</td>\n",
       "      <td>Stephen King</td>\n",
       "      <td>2001</td>\n",
       "      <td>Pocket</td>\n",
       "      <td>439</td>\n",
       "      <td>brookfield, wisconsin, usa</td>\n",
       "      <td>16.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9252</th>\n",
       "      <td>440</td>\n",
       "      <td>0393321576</td>\n",
       "      <td>8</td>\n",
       "      <td>501</td>\n",
       "      <td>Karl Marx: A Life</td>\n",
       "      <td>Francis Wheen</td>\n",
       "      <td>2001</td>\n",
       "      <td>W.W. Norton &amp;amp; Company</td>\n",
       "      <td>439</td>\n",
       "      <td>brookfield, wisconsin, usa</td>\n",
       "      <td>16.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9254</th>\n",
       "      <td>440</td>\n",
       "      <td>0786868015</td>\n",
       "      <td>7</td>\n",
       "      <td>503</td>\n",
       "      <td>The Diary of Ellen Rimbauer: My Life at Rose Red</td>\n",
       "      <td>Joyce Reardon</td>\n",
       "      <td>2001</td>\n",
       "      <td>Hyperion</td>\n",
       "      <td>439</td>\n",
       "      <td>brookfield, wisconsin, usa</td>\n",
       "      <td>16.0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "      user_id        isbn  rating  bid  \\\n",
       "9253      440  0743424425      10  502   \n",
       "9252      440  0393321576       8  501   \n",
       "9254      440  0786868015       7  503   \n",
       "\n",
       "                                                 title         author  \\\n",
       "9253                                       The Shining   Stephen King   \n",
       "9252                                 Karl Marx: A Life  Francis Wheen   \n",
       "9254  The Diary of Ellen Rimbauer: My Life at Rose Red  Joyce Reardon   \n",
       "\n",
       "     year_of_publication                  publisher  uid  \\\n",
       "9253                2001                     Pocket  439   \n",
       "9252                2001  W.W. Norton &amp; Company  439   \n",
       "9254                2001                   Hyperion  439   \n",
       "\n",
       "                        location   age  \n",
       "9253  brookfield, wisconsin, usa  16.0  \n",
       "9252  brookfield, wisconsin, usa  16.0  \n",
       "9254  brookfield, wisconsin, usa  16.0  "
      ]
     },
     "execution_count": 99,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# user ratings\n",
    "ratings_clean_2[ratings_clean_2.uid == uid].sort_values(['rating'], ascending=[0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 100,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>user_id</th>\n",
       "      <th>isbn</th>\n",
       "      <th>rating</th>\n",
       "      <th>bid</th>\n",
       "      <th>title</th>\n",
       "      <th>author</th>\n",
       "      <th>year_of_publication</th>\n",
       "      <th>publisher</th>\n",
       "      <th>uid</th>\n",
       "      <th>location</th>\n",
       "      <th>age</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>32453</th>\n",
       "      <td>8890</td>\n",
       "      <td>2070388638</td>\n",
       "      <td>9</td>\n",
       "      <td>21854</td>\n",
       "      <td>La MÃƒÂƒ?ÃƒÂ‚Ã‚Â©canique des femmes</td>\n",
       "      <td>Louis Calaferte</td>\n",
       "      <td>1994</td>\n",
       "      <td>Gallimard</td>\n",
       "      <td>8889</td>\n",
       "      <td>paris, ile-de-france, france</td>\n",
       "      <td>47.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>335934</th>\n",
       "      <td>90232</td>\n",
       "      <td>2264030542</td>\n",
       "      <td>9</td>\n",
       "      <td>1286</td>\n",
       "      <td>Retour ÃƒÂƒ?ÃƒÂ‚Ã‚Â  Brooklyn</td>\n",
       "      <td>Hubert Selby</td>\n",
       "      <td>1999</td>\n",
       "      <td>Editions 10/18</td>\n",
       "      <td>90231</td>\n",
       "      <td>strasbourg, alsace, france</td>\n",
       "      <td>23.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>923465</th>\n",
       "      <td>246216</td>\n",
       "      <td>0312983379</td>\n",
       "      <td>6</td>\n",
       "      <td>10732</td>\n",
       "      <td>In Harm's Way: The Sinking of the Uss Indianap...</td>\n",
       "      <td>Doug Stanton</td>\n",
       "      <td>2002</td>\n",
       "      <td>St. Martin's Press</td>\n",
       "      <td>246215</td>\n",
       "      <td>holland, michigan, usa</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>954902</th>\n",
       "      <td>254405</td>\n",
       "      <td>0440222842</td>\n",
       "      <td>10</td>\n",
       "      <td>9500</td>\n",
       "      <td>Five Days in Paris</td>\n",
       "      <td>DANIELLE STEEL</td>\n",
       "      <td>1997</td>\n",
       "      <td>Dell</td>\n",
       "      <td>254404</td>\n",
       "      <td>nanticoke, pennsylvania, usa</td>\n",
       "      <td>33.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1012552</th>\n",
       "      <td>270820</td>\n",
       "      <td>0671695185</td>\n",
       "      <td>8</td>\n",
       "      <td>30475</td>\n",
       "      <td>BLUE WORLD : BLUE WORLD</td>\n",
       "      <td>Robert McCammon</td>\n",
       "      <td>1990</td>\n",
       "      <td>Pocket</td>\n",
       "      <td>270819</td>\n",
       "      <td>west bend, wisconsin, usa</td>\n",
       "      <td>52.0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "         user_id        isbn  rating    bid  \\\n",
       "32453       8890  2070388638       9  21854   \n",
       "335934     90232  2264030542       9   1286   \n",
       "923465    246216  0312983379       6  10732   \n",
       "954902    254405  0440222842      10   9500   \n",
       "1012552   270820  0671695185       8  30475   \n",
       "\n",
       "                                                     title           author  \\\n",
       "32453                        La MÃƒÂƒ?ÃƒÂ‚Ã‚Â©canique des femmes  Louis Calaferte   \n",
       "335934                             Retour ÃƒÂƒ?ÃƒÂ‚Ã‚Â  Brooklyn     Hubert Selby   \n",
       "923465   In Harm's Way: The Sinking of the Uss Indianap...     Doug Stanton   \n",
       "954902                                  Five Days in Paris   DANIELLE STEEL   \n",
       "1012552                            BLUE WORLD : BLUE WORLD  Robert McCammon   \n",
       "\n",
       "        year_of_publication           publisher     uid  \\\n",
       "32453                  1994           Gallimard    8889   \n",
       "335934                 1999      Editions 10/18   90231   \n",
       "923465                 2002  St. Martin's Press  246215   \n",
       "954902                 1997                Dell  254404   \n",
       "1012552                1990              Pocket  270819   \n",
       "\n",
       "                             location   age  \n",
       "32453    paris, ile-de-france, france  47.0  \n",
       "335934     strasbourg, alsace, france  23.0  \n",
       "923465         holland, michigan, usa   NaN  \n",
       "954902   nanticoke, pennsylvania, usa  33.0  \n",
       "1012552     west bend, wisconsin, usa  52.0  "
      ]
     },
     "execution_count": 100,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# recommendations\n",
    "predictions = NeuralMF_model.predict([users_data, books_data])\n",
    "predictions = np.array([a[0] for a in predictions])\n",
    "recommended_book_ids = (-predictions).argsort()[:10]\n",
    "\n",
    "recommendations = ratings_clean_2[ratings_clean_2['bid'].isin(recommended_book_ids)]\n",
    "recommendations = recommendations.drop_duplicates(subset='title', keep=\"last\")\n",
    "recommendations.head(15)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
